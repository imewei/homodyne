# Migration Guide: Homodyne v2.0 → v2.1

**Version**: 2.1.0
**Release Date**: October 31, 2025
**Migration Complexity**: Medium (Breaking changes in CLI and YAML)

## Overview

Homodyne v2.1.0 simplifies the MCMC workflow by removing confusing CLI method flags (`--method nuts`, `--method cmc`) and automatic NLSQ/SVI initialization. This results in a **75% reduction in CLI complexity** while maintaining full functionality through automatic NUTS/CMC selection.

### What Changed

**Breaking Changes:**
- ❌ Removed `--method nuts` and `--method cmc` CLI flags
- ❌ Removed entire `mcmc.initialization` section from YAML templates
- ❌ Removed automatic NLSQ/SVI initialization from MCMC

**New Features:**
- ✅ Automatic NUTS/CMC selection: `(num_samples >= 15) OR (memory > 30%)` → CMC
- ✅ Configurable thresholds in YAML: `min_samples_for_cmc: 15`, `memory_threshold_pct: 0.30`
- ✅ Auto-retry mechanism with convergence failures (max 3 retries)
- ✅ Manual NLSQ → MCMC workflow with transparency

**Backward Compatible:**
- ✅ `initial_parameters.values` structure unchanged
- ✅ `--method nlsq` unchanged
- ✅ `--method mcmc` unchanged (now triggers automatic selection)
- ✅ All NLSQ functionality untouched

---

## Quick Migration Checklist

- [ ] Update CLI scripts: replace `--method nuts` or `--method cmc` with `--method mcmc`
- [ ] Update YAML config files: remove `mcmc.initialization` section
- [ ] Add new thresholds to YAML: `min_samples_for_cmc: 15`, `memory_threshold_pct: 0.30`
- [ ] Update workflow: separate NLSQ and MCMC runs with manual parameter copying
- [ ] Test automatic NUTS/CMC selection with your datasets
- [ ] Review convergence diagnostics in MCMC output

---

## CLI Migration

### Before (v2.0.0)

```bash
# Explicit method selection (confusing, removed in v2.1)
homodyne --config config.yaml --method nuts      # Force NUTS
homodyne --config config.yaml --method cmc       # Force CMC
homodyne --config config.yaml --method auto      # Automatic (same as mcmc)
```

### After (v2.1.0)

```bash
# Simplified automatic selection (only option in v2.1)
homodyne --config config.yaml --method mcmc      # Automatic NUTS/CMC selection

# Decision logic:
# - (num_samples >= 15) OR (memory > 30%) → CMC
# - Otherwise → NUTS
```

### Migration Steps

1. **Search and replace** in all scripts:
   ```bash
   # Find all references
   grep -r "--method nuts" .
   grep -r "--method cmc" .

   # Replace with
   --method mcmc
   ```

2. **Update documentation** that mentions `nuts` or `cmc` methods

3. **Test** automatic selection works as expected for your datasets

---

## YAML Configuration Migration

### Before (v2.0.0)

```yaml
optimization:
  mcmc:
    num_warmup: 1000
    num_samples: 2000
    num_chains: 4

    cmc:
      initialization:
        run_nlsq_init: true      # REMOVED in v2.1
        use_svi: true            # REMOVED in v2.1
        svi_steps: 5000          # REMOVED in v2.1
        svi_timeout: null        # REMOVED in v2.1
        samples_per_shard: 200   # REMOVED in v2.1
        svi_learning_rate: 0.001 # REMOVED in v2.1
        svi_rank: 5              # REMOVED in v2.1
        fallback_to_identity: true  # REMOVED in v2.1

      sharding:
        mode: auto
        # ... other sharding options
```

### After (v2.1.0)

```yaml
optimization:
  mcmc:
    num_warmup: 1000
    num_samples: 2000
    num_chains: 4

    # NEW: Automatic NUTS/CMC selection thresholds
    min_samples_for_cmc: 15              # Parallelism threshold
    memory_threshold_pct: 0.30           # Memory management threshold (30%)
    dense_mass_matrix: false             # Diagonal (fast) vs full (accurate)

    cmc:
      sharding:
        mode: auto
        # ... other sharding options remain unchanged
```

### Configuration Option Details

**`min_samples_for_cmc` (Default: 15)**
- Controls parallelism threshold for CMC selection
- Use CMC when number of samples (e.g., phi angles) >= this value
- **Typical values**:
  - `15` (default): Balances parallelism efficiency vs overhead
  - `10`: More aggressive parallelism (smaller datasets trigger CMC)
  - `25`: Conservative parallelism (only large datasets use CMC)
- **When to adjust**: For very small datasets (< 10 angles), increase to 20+

**`memory_threshold_pct` (Default: 0.30)**
- Controls memory-based CMC trigger (prevents OOM errors)
- Use CMC when estimated memory exceeds this % of system RAM
- **Typical values**:
  - `0.30` (default): Conservative (triggers CMC at 30% system RAM)
  - `0.20`: Very conservative (for 16GB systems or large datasets)
  - `0.40`: Aggressive (tolerates higher memory usage)
- **When to adjust**: For memory-constrained systems, decrease to 0.20-0.25

**`dense_mass_matrix` (Default: false)**
- Controls mass matrix type in NUTS sampler
- `false`: Diagonal mass matrix (faster, lower overhead, ~90% of accuracy)
- `true`: Full covariance mass matrix (slower, better sampling, publication-quality)
- **When to use**:
  - `false` (default): Standard analyses, tight deadlines
  - `true`: Publication-quality results, uncertain priors, publication submission

### Migration Steps

1. **Remove entire `initialization` block** under `cmc:`
   ```bash
   # Automated removal (use with caution)
   sed -i '/initialization:/,/fallback_to_identity:/d' config.yaml
   ```

2. **Add new threshold parameters** at `optimization.mcmc` level:
   ```yaml
   min_samples_for_cmc: 15
   memory_threshold_pct: 0.30
   ```

3. **Keep `initial_parameters`** structure unchanged:
   ```yaml
   initial_parameters:
     parameter_names: [D0, alpha, D_offset]
     values: null  # Set manually from NLSQ if desired
   ```

4. **Validate** config file:
   ```bash
   homodyne-config --validate config.yaml
   ```

---

## Python API Migration

### Before (v2.0.0): Method Parameter in fit_mcmc_jax()

```python
from homodyne.optimization import fit_mcmc_jax
import jax.numpy as jnp

# v2.0.0 usage (NO LONGER SUPPORTED)
result = fit_mcmc_jax(
    method="nuts",  # REMOVED: explicit method selection
    initial_params={"D0": 1000.0, "alpha": 0.5, "D_offset": 10.0},  # REMOVED
    phi=phi_array,
    g2=g2_data,
    g2_err=g2_err_data,
    num_warmup=1000,
    num_samples=2000,
)
```

**Issues with v2.0 approach:**
- ❌ Users must manually choose NUTS vs CMC
- ❌ No hardware awareness (can cause OOM errors)
- ❌ Hidden complexity in parameter passing
- ❌ Difficult to integrate with YAML config

### After (v2.1.0): Config-Driven API

**Recommended: Use CLI instead of direct Python API**

```python
# v2.1.0: Let Homodyne handle automatic selection via CLI
# In your shell:
# $ homodyne --config config.yaml --method mcmc

# If you must use Python API (advanced users):
from homodyne.config.manager import ConfigManager
from homodyne.config.parameter_space import ParameterSpace
from homodyne.optimization import fit_mcmc_jax
import jax.numpy as jnp

# Load configuration from YAML
config = ConfigManager.load("config.yaml")

# Extract parameter bounds and priors
parameter_space = ParameterSpace.from_config(config.get("parameter_space"))

# Get initial values (e.g., from NLSQ results)
initial_values = config.get("initial_parameters", {}).get("values")

# Call updated API (automatic NUTS/CMC selection)
result = fit_mcmc_jax(
    parameter_space=parameter_space,  # NEW: replaces method parameter
    initial_values=initial_values,    # NEW: replaces initial_params
    phi=phi_array,
    g2=g2_data,
    g2_err=g2_err_data,
    num_warmup=1000,
    num_samples=2000,
    # Automatic selection happens here:
    # - CMC if (num_samples >= 15) OR (memory > 30%)
    # - NUTS otherwise
    # - Decision logged to stdout
)

# Result structure unchanged
print(f"Posterior samples shape: {result['posterior']['D0'].shape}")
print(f"R-hat (convergence): {result['diagnostics']['r_hat']}")
print(f"Method used: {result['method']}")  # 'nuts' or 'cmc'
```

### Python API Changes Summary

| Aspect | v2.0.0 | v2.1.0 | Migration |
|--------|--------|--------|-----------|
| **Method selection** | `method="nuts"` param | Automatic (removed param) | Remove param, let system decide |
| **Parameter passing** | `initial_params=dict` | `initial_values=list` | Load from config instead |
| **Bounds/priors** | Manual dict construction | `ParameterSpace` object | Use `ParameterSpace.from_config()` |
| **Decision logic** | User responsibility | Dual-criteria OR logic | No code change needed |
| **Result format** | `(popt, samples, ...)` | Unified dict with metadata | Update result parsing code |

### Migration Steps for Python Code

**Step 1: Remove method parameter**
```python
# OLD
result = fit_mcmc_jax(method="cmc", ...)

# NEW
result = fit_mcmc_jax(...)  # Automatic selection
```

**Step 2: Load config instead of manual dicts**
```python
# OLD
initial_params = {"D0": 1234.5, "alpha": 0.567}

# NEW
config = ConfigManager.load("config.yaml")
initial_values = config.get("initial_parameters", {}).get("values")
```

**Step 3: Use ParameterSpace for bounds**
```python
# OLD
bounds = {"D0": (100, 5000), "alpha": (0.1, 2.0)}

# NEW
parameter_space = ParameterSpace.from_config(config.get("parameter_space"))
```

**Step 4: Update result parsing (optional)**
```python
# OLD: Tuple unpacking
popt, samples, info = result

# NEW: Dict access (backward compatible)
popt = result['fitted_parameters']
samples = result['posterior']
method = result['method']  # 'nuts' or 'cmc'
converged = result['diagnostics']['converged']
```

---

## Workflow Migration

### Before (v2.0.0): Automatic Initialization

```bash
# Old workflow: MCMC automatically ran NLSQ/SVI first
homodyne --config config.yaml --method mcmc

# Behind the scenes (automatic, invisible to user):
# 1. Run NLSQ to get initial estimates
# 2. Optionally run SVI for better initialization
# 3. Use those results to start MCMC
# 4. Run MCMC sampling
```

**Problems with old approach:**
- ❌ Hidden complexity (users didn't know NLSQ was running)
- ❌ Confusing when initialization failed but MCMC continued
- ❌ Hard to debug initialization vs sampling issues
- ❌ No control over initialization process

### After (v2.1.0): Manual Workflow

```bash
# New workflow: Explicit, transparent, user-controlled

# Step 1: Run NLSQ analysis (separate, explicit step)
homodyne --config config.yaml --method nlsq

# Output example:
# Best-fit parameters:
#   D0: 1234.5 ± 45.6
#   alpha: 0.567 ± 0.012
#   D_offset: 12.34 ± 1.23

# Step 2: Manually copy NLSQ results to config.yaml
# Edit config.yaml:
#   initial_parameters:
#     values: [1234.5, 0.567, 12.34]

# Step 3: Run MCMC with initialized parameters
homodyne --config config.yaml --method mcmc

# Step 4: Automatic selection decides NUTS vs CMC
# - (num_samples >= 15) OR (memory > 30%) → CMC
# - Otherwise → NUTS
```

**Benefits of new approach:**
- ✅ Transparent: users see exactly what's happening
- ✅ Debuggable: separate NLSQ and MCMC logs
- ✅ Flexible: skip NLSQ if you have good priors
- ✅ Reproducible: clear record of initialization values

### Migration Steps

1. **Update scripts** to separate NLSQ and MCMC runs

2. **Create parameter extraction script** (optional):
   ```python
   # extract_nlsq_params.py
   import yaml

   # Read NLSQ result file
   with open("nlsq_results.txt") as f:
       lines = f.readlines()

   # Parse parameters (example)
   params = {}
   for line in lines:
       if "D0:" in line:
           params["D0"] = float(line.split()[1])
       # ... parse other params

   # Update config.yaml
   with open("config.yaml") as f:
       config = yaml.safe_load(f)

   config["initial_parameters"]["values"] = [
       params["D0"], params["alpha"], params["D_offset"]
   ]

   with open("config.yaml", "w") as f:
       yaml.dump(config, f)
   ```

3. **Update documentation** for your analysis pipeline

---

## Shell Aliases Migration

Shell aliases provide convenient shortcuts for common commands. In v2.1.0, we've removed aliases for `nuts` and `cmc` methods since they no longer exist.

### Before (v2.0.0)

```bash
# Convenience aliases (these NO LONGER WORK in v2.1)
hm-nuts --config config.yaml           # Force NUTS (REMOVED)
hm-cmc --config config.yaml            # Force CMC (REMOVED)
hm-auto --config config.yaml           # Automatic (REMOVED, same as mcmc)

# Other aliases (still work)
hm-nlsq --config config.yaml           # NLSQ optimization (unchanged)
hc-stat --output static.yaml           # Static mode config (unchanged)
hc-flow --output flow.yaml             # Laminar flow config (unchanged)
```

### After (v2.1.0)

```bash
# Use these aliases instead:
hm-mcmc --config config.yaml           # MCMC with automatic NUTS/CMC selection (NEW)
hm-nlsq --config config.yaml           # NLSQ optimization (unchanged)
hc-stat --output static.yaml           # Static mode config (unchanged)
hc-flow --output flow.yaml             # Laminar flow config (unchanged)
```

### Practical Examples

```bash
# Fast optimization workflow (typical use case)
hm-nlsq --config analysis/config.yaml --verbose

# Publication-quality analysis with uncertainty quantification
hm-mcmc --config analysis/config.yaml --verbose

# Manual NLSQ → MCMC workflow
# Step 1: Get point estimates
hm-nlsq --config analysis/config.yaml > nlsq_results.txt

# Step 2: Extract and update config (manually copy values)
grep "D0:" nlsq_results.txt
grep "alpha:" nlsq_results.txt

# Step 3: Run MCMC with initialization
hm-mcmc --config analysis/config.yaml --verbose

# Create new configuration from template
hc-stat --output analysis/static_config.yaml
hc-flow --output analysis/flow_config.yaml
```

### Updating Your Scripts

If you have shell scripts using old aliases:

```bash
# Before (v2.0)
#!/bin/bash
for config in configs/*.yaml; do
    hm-nuts $config  # REMOVED
done

# After (v2.1)
#!/bin/bash
for config in configs/*.yaml; do
    hm-mcmc $config  # Updated
done
```

### Verifying Alias Installation

```bash
# Check installed aliases
type hm-nlsq
type hm-mcmc
type hc-stat
type hc-flow

# If not found, reinstall completion/aliases:
homodyne-post-install --interactive
```

---

## Automatic NUTS/CMC Selection

### Decision Logic (v2.1.0)

The system automatically decides between NUTS and CMC using **dual-criteria OR logic**:

```
IF (num_samples >= 15) OR (memory > 30%):
    USE CMC
ELSE:
    USE NUTS
```

### Use Case 1: Parallelism Mode

**Trigger**: `num_samples >= 15`

**Example**: 20 phi angles × 10M points each
- `num_samples = 20 >= 15` → **CMC selected**
- Sharding: 20 phi → 4 shards × 5 phi each
- Benefit: Parallel MCMC chains on 14-core CPU → ~1.4x speedup

### Use Case 2: Memory Management Mode

**Trigger**: `estimated_memory > 30%`

**Example**: 5 phi angles × 50M points each
- `num_samples = 5 < 15` (parallelism fails)
- `estimated_memory = 12 GB / 32 GB = 37.5% > 30%` → **CMC selected**
- Benefit: Avoid OOM errors, enable large dataset analysis

### Use Case 3: Standard NUTS

**Example**: 10 phi angles × 5M points each
- `num_samples = 10 < 15` (parallelism fails)
- `estimated_memory = 1.2 GB / 32 GB = 3.75% < 30%` (memory fails)
- → **NUTS selected** (both conditions fail)
- Benefit: Faster sampling for small datasets

### Configuring Thresholds

Customize selection logic in `config.yaml`:

```yaml
optimization:
  mcmc:
    # Default: 15 samples, 30% memory
    min_samples_for_cmc: 15
    memory_threshold_pct: 0.30

    # Stricter (more CMC):
    # min_samples_for_cmc: 10
    # memory_threshold_pct: 0.20

    # More aggressive (less CMC):
    # min_samples_for_cmc: 25
    # memory_threshold_pct: 0.40
```

---

## Troubleshooting

### Error: "Unknown method: nuts"

**Problem**: Using `--method nuts` from v2.0

**Solution**: Replace with `--method mcmc`
```bash
# Before
homodyne --config config.yaml --method nuts

# After
homodyne --config config.yaml --method mcmc
```

### Error: "Unknown config key: mcmc.initialization"

**Problem**: Old `initialization` section in YAML config

**Solution**: Remove entire `initialization` block:
```yaml
# Remove this entire section:
cmc:
  initialization:
    run_nlsq_init: true
    use_svi: true
    # ... all initialization fields
```

### MCMC Fails to Converge

**Problem**: Poor convergence (R-hat > 1.1, ESS < 100)

**Solution**: Use manual NLSQ → MCMC workflow
```bash
# 1. Run NLSQ first to get good initial estimates
homodyne --config config.yaml --method nlsq

# 2. Copy best-fit parameters to config.yaml
# initial_parameters.values: [...]

# 3. Run MCMC with initialization
homodyne --config config.yaml --method mcmc

# 4. Auto-retry will attempt up to 3 times with different seeds
```

### Unexpected CMC Instead of NUTS

**Problem**: Dataset triggers CMC when you expected NUTS

**Check**:
```bash
# Review logs for decision rationale
# Look for messages like:
# "Sample count 20 >= min_samples_for_cmc (15). Using CMC for parallelism."
# "Dataset requires ~12 GB (37.5% of 32 GB). Using CMC for memory."
```

**Solution**: Adjust thresholds if needed
```yaml
mcmc:
  min_samples_for_cmc: 25        # Higher → less CMC
  memory_threshold_pct: 0.40     # Higher → less CMC
```

### How to Force NUTS or CMC?

**Answer**: Not supported in v2.1.0 (breaking change)

**Rationale**: Automatic selection ensures optimal performance and prevents user errors (e.g., NUTS on 100 samples causing OOM)

**Workaround**: Adjust thresholds to influence selection
```yaml
# To strongly prefer NUTS:
min_samples_for_cmc: 1000         # Very high threshold
memory_threshold_pct: 0.90        # Very high threshold

# To strongly prefer CMC:
min_samples_for_cmc: 5            # Very low threshold
memory_threshold_pct: 0.10        # Very low threshold
```

### TypeError: fit_mcmc_jax() got unexpected keyword 'method'

**Problem**: Code using v2.0 `method` parameter fails

**Symptom**: `TypeError: fit_mcmc_jax() got unexpected keyword argument 'method'`

**Solution**: Remove `method` parameter entirely
```python
# OLD (v2.0)
result = fit_mcmc_jax(method="nuts", ...)

# NEW (v2.1)
result = fit_mcmc_jax(...)  # Automatic selection, no method param
```

### TypeError: fit_mcmc_jax() got unexpected keyword 'initial_params'

**Problem**: Code using v2.0 parameter name fails

**Symptom**: `TypeError: fit_mcmc_jax() got unexpected keyword argument 'initial_params'`

**Solution**: Rename to `initial_values` and load from config
```python
# OLD
result = fit_mcmc_jax(initial_params={"D0": 1000}, ...)

# NEW
config = ConfigManager.load("config.yaml")
initial_values = config.get("initial_parameters", {}).get("values")
result = fit_mcmc_jax(initial_values=initial_values, ...)
```

### Config shows 'Removed field' warning during validation

**Problem**: YAML file contains deprecated `initialization` section

**Symptom**: `ConfigError: Unknown field: initialization`

**Solution**: Remove the entire `mcmc.cmc.initialization` section:
```yaml
# Remove this entire block:
optimization:
  mcmc:
    cmc:
      initialization:  # DELETE THIS SECTION
        run_nlsq_init: true
        use_svi: true
        # ... all fields
```

Use config validator to check:
```bash
homodyne-config --validate config.yaml
```

### ValueError: Cannot set 'run_nlsq_init' in YAML

**Problem**: Attempting to use removed v2.0 configuration option

**Symptom**: `ValueError: Unknown configuration key 'run_nlsq_init'`

**Solution**: These options no longer exist in v2.1.0
- Use manual NLSQ → MCMC workflow instead
- Copy NLSQ results to `initial_parameters.values` section
- Delete all `initialization` subsections

### Memory threshold adjustment resulted in opposite behavior

**Problem**: Lowering `memory_threshold_pct` triggered CMC instead of preventing it

**Symptom**: Decreased `memory_threshold_pct` from 0.30 to 0.20, but more datasets now use CMC

**Explanation**: Lower threshold = CMC triggers earlier (at lower memory %), not later
- `0.30` (30%): CMC when using > 30% of RAM
- `0.20` (20%): CMC when using > 20% of RAM (triggers more often)

**Solution**: Increase if you want fewer CMC selections
```yaml
# To use CMC less often (prefer NUTS):
memory_threshold_pct: 0.40  # or higher
```

---

## Testing Your Migration

### Validation Checklist

1. **CLI tests**:
   ```bash
   # Should work (v2.1.0)
   homodyne --config config.yaml --method nlsq
   homodyne --config config.yaml --method mcmc

   # Should fail with clear error (v2.1.0)
   homodyne --config config.yaml --method nuts
   homodyne --config config.yaml --method cmc
   ```

2. **YAML validation**:
   ```bash
   homodyne-config --validate config.yaml
   # Should pass without warnings about initialization section
   ```

3. **Automatic selection test**:
   ```bash
   # Small dataset → should use NUTS
   # (Watch logs for "Using single-chain NUTS")

   # Large dataset (20+ samples) → should use CMC
   # (Watch logs for "Using CMC for sample-level parallelization")
   ```

4. **Manual workflow test**:
   ```bash
   # 1. Run NLSQ
   homodyne --config config.yaml --method nlsq > nlsq_output.txt

   # 2. Extract parameters manually
   grep "D0:" nlsq_output.txt
   grep "alpha:" nlsq_output.txt

   # 3. Update config.yaml
   # 4. Run MCMC
   homodyne --config config.yaml --method mcmc
   ```

5. **Convergence test**:
   ```bash
   # Check MCMC diagnostics in output
   # R-hat should be < 1.1
   # ESS should be > 100
   # Auto-retry should kick in if convergence fails
   ```

---

## FAQ

### Q: Why remove `--method nuts` and `--method cmc`?

**A**: These flags added unnecessary complexity and confusion:
- Users didn't know when to use nuts vs cmc
- Manual selection often led to poor performance (e.g., NUTS on 100 samples → OOM)
- Automatic selection is always optimal based on hardware and data

### Q: Can I still initialize MCMC with NLSQ results?

**A**: Yes! Use the manual workflow:
1. Run NLSQ separately
2. Copy results to `initial_parameters.values` in YAML
3. Run MCMC

This is more transparent than automatic initialization.

### Q: What if automatic selection chooses the wrong method?

**A**: You can influence selection by adjusting thresholds in config.yaml:
```yaml
mcmc:
  min_samples_for_cmc: 20    # Adjust based on your hardware
  memory_threshold_pct: 0.35 # Adjust based on your system
```

### Q: Will my old v2.0 config files work?

**A**: Partially. You must:
1. Remove `mcmc.initialization` section (breaking change)
2. Add new threshold parameters (optional but recommended)
3. Update any scripts using `--method nuts` or `--method cmc`

### Q: What happens if MCMC doesn't converge?

**A**: New in v2.1.0, automatic retry:
1. First attempt fails (R-hat > 1.1 or ESS < 100)
2. Retry with different random seed (max 3 attempts)
3. If all fail, return result with `converged=False`
4. User should try manual NLSQ → MCMC workflow

### Q: How do I know if CMC or NUTS was used?

**A**: Check log messages:
```
INFO: Sample count 20 >= min_samples_for_cmc (15). Using CMC for parallelism.
```
or
```
INFO: Sample count 10 within standard NUTS capacity. Using single-chain NUTS.
```

---

## Backward Compatibility

### What Remains Compatible

**✅ Fully Backward Compatible:**
- All NLSQ optimization features (no changes to `--method nlsq`)
- Data pipeline components (loading, preprocessing, phi filtering)
- `initial_parameters.values` structure (parameter passing mechanism)
- Result file format (HDF5 with posterior samples and diagnostics)
- Physical models (static isotropic, laminar flow)
- Device management (CPU/GPU auto-detection)
- `parameter_space` structure for bounds and priors
- Core JAX backend functions

**⚠️ Partially Compatible:**
- MCMC results from v2.0 can be visualized in v2.1 (format unchanged)
- Old YAML config files require manual updates (see YAML Migration section)
- Python scripts using MCMC need API updates (see Python API Migration section)

**❌ Breaking Changes:**
- CLI flags: `--method nuts`, `--method cmc`, `--method auto`
- YAML section: `mcmc.cmc.initialization` (entire section removed)
- Python API: `method` parameter in `fit_mcmc_jax()`
- Python API: `initial_params` parameter (renamed to `initial_values`)
- Shell aliases: `hm-nuts`, `hm-cmc`, `hm-auto`

### Testing Backward Compatibility

**Can I use v2.0 result files in v2.1?**
```bash
# Yes! Results are HDF5 format, format unchanged
python -c "
import h5py
with h5py.File('v2_0_mcmc_results.hdf5', 'r') as f:
    print('Posterior samples:', f['posterior/D0'].shape)
    print('R-hat:', f['diagnostics/r_hat'][()])
"
```

**Can I restore old CLI flags for backward compatibility?**
No. v2.1.0 does not support deprecation warnings or compatibility layers for old flags. This is an acknowledged hard breaking change. You must update your workflows.

**Will old configuration files still work?**
Partially. You must:
1. Remove `mcmc.initialization` section
2. Add new parameters (optional but recommended)
3. Update any shell scripts using old method flags

---

## Detailed Migration Checklist

Use this comprehensive checklist when migrating your v2.0 projects:

### Phase 1: Preparation (Review)
- [ ] Review current CLI scripts for `--method nuts`, `--method cmc`
- [ ] Check YAML config files for `mcmc.initialization` section
- [ ] Identify Python scripts directly calling `fit_mcmc_jax()`
- [ ] Document current performance (NLSQ runtime, MCMC convergence)
- [ ] Backup current YAML configs and results

### Phase 2: YAML Configuration (Update)
- [ ] Remove entire `mcmc.cmc.initialization` section from config
- [ ] Add `min_samples_for_cmc: 15` to `optimization.mcmc`
- [ ] Add `memory_threshold_pct: 0.30` to `optimization.mcmc`
- [ ] Add `dense_mass_matrix: false` to `optimization.mcmc` (optional)
- [ ] Verify with `homodyne-config --validate config.yaml`
- [ ] Test with small dataset: `homodyne --config config.yaml --method nlsq`

### Phase 3: CLI Scripts (Update)
- [ ] Search all scripts for `--method nuts` occurrences
- [ ] Replace with `--method mcmc`
- [ ] Search for `--method cmc` occurrences
- [ ] Replace with `--method mcmc`
- [ ] Search for `--method auto` occurrences
- [ ] Replace with `--method mcmc`
- [ ] Test script with small dataset
- [ ] Update documentation that mentions removed methods

### Phase 4: Python Code (Update)
- [ ] Identify all calls to `fit_mcmc_jax()` with `method` param
- [ ] Remove `method` parameter
- [ ] Replace `initial_params=dict` with `initial_values=list`
- [ ] Load config using `ConfigManager.load()`
- [ ] Create `ParameterSpace` using `from_config()`
- [ ] Update result parsing (if using tuple unpacking)
- [ ] Run unit tests: `make test-mcmc`

### Phase 5: Shell Aliases (Update)
- [ ] Test each alias: `type hm-nlsq`, `type hm-mcmc`, etc.
- [ ] Update any shell profiles that reference removed aliases
- [ ] Run `homodyne-post-install --interactive` if needed
- [ ] Update shell initialization files (.bashrc, .zshrc, etc.)

### Phase 6: Testing (Validate)
- [ ] Run NLSQ test: `homodyne --config test.yaml --method nlsq`
- [ ] Run MCMC test: `homodyne --config test.yaml --method mcmc`
- [ ] Verify automatic selection decision in logs
- [ ] Check result files are valid: `homodyne-config --validate`
- [ ] Run comprehensive test suite: `make test-all`

### Phase 7: Verification (Final Check)
- [ ] Old method flags properly fail: `--method nuts` → error
- [ ] Config validation passes without warnings
- [ ] MCMC converges with new initialization
- [ ] Performance is comparable to v2.0
- [ ] Documentation updated with v2.1 examples
- [ ] Team trained on manual NLSQ → MCMC workflow

### Phase 8: Production (Deploy)
- [ ] Create release branch: `git checkout -b migrate-v2.1`
- [ ] Commit all changes with clear messages
- [ ] Create pull request with migration summary
- [ ] Run CI/CD tests (should pass on updated code)
- [ ] Merge to main after review
- [ ] Update project README with v2.1 examples
- [ ] Announce to team/users with migration guide link

---

## Performance Impact and Optimization

### Expected Performance Changes

**NLSQ (unchanged)**
- No performance change from v2.0 to v2.1
- Same algorithm, same speed
- Use for initial parameter estimation

**MCMC Selection Impact**
- Small datasets (< 15 samples): NUTS (v2.0 single-chain) → NUTS (v2.1) = No change
- Medium datasets (15-50 samples): NUTS → CMC (v2.1 parallelized) = ~1.4x speedup
- Large datasets (> 50 samples, high memory): NUTS → CMC (v2.1 parallelized) = ~2-3x speedup

### Optimization Tips

**To maximize NLSQ performance:**
```bash
# Use streaming mode for very large datasets
homodyne --config config.yaml --method nlsq --verbose
# Look for "Strategy: STREAMING" in logs
```

**To optimize MCMC selection:**
```yaml
# For 14-core CPU, 32GB RAM:
optimization:
  mcmc:
    min_samples_for_cmc: 12      # Lower = more parallelism
    memory_threshold_pct: 0.30   # Keep conservative
```

**For publication-quality results:**
```yaml
optimization:
  mcmc:
    dense_mass_matrix: true      # Better sampling (slower)
    num_warmup: 2000             # Longer warmup (more accurate)
    num_samples: 4000            # More samples (better posteriors)
```

---

## Summary

**v2.1.0 Key Changes:**
- ✅ Simplified CLI: only `nlsq` and `mcmc` methods
- ✅ Automatic NUTS/CMC selection (dual-criteria OR logic)
- ✅ Manual NLSQ → MCMC workflow (transparent, debuggable)
- ✅ Configurable thresholds (15 samples, 30% memory)
- ✅ Auto-retry on convergence failure (max 3 attempts)

**Migration Effort:** Medium (2-4 hours for typical project)

**Benefits:**
- 75% reduction in CLI complexity
- Better performance through automatic selection
- More transparent and debuggable workflow
- Fewer user errors and OOM failures

**Support:** See [CLAUDE.md](../../CLAUDE.md) for detailed documentation or open an issue on GitHub.
