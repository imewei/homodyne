{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start: Homodyne XPCS Analysis\n",
    "\n",
    "This notebook demonstrates the complete homodyne workflow in 10 minutes:\n",
    "\n",
    "1. Load an XPCS dataset from an HDF5 file\n",
    "2. Configure and run NLSQ static-mode fitting\n",
    "3. Visualize the results\n",
    "4. Interpret the fitted parameters\n",
    "\n",
    "**Requirements:** homodyne installed (`uv sync`), an HDF5 data file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Homodyne imports\n",
    "import homodyne\n",
    "from homodyne.config import ConfigManager\n",
    "from homodyne.data import load_xpcs_data\n",
    "from homodyne.optimization.nlsq import fit_nlsq_jax\n",
    "from homodyne.utils.logging import get_logger\n",
    "\n",
    "print(f\"Homodyne version: {homodyne.__version__}\")\n",
    "\n",
    "# Check optimization backend availability\n",
    "from homodyne.optimization import OPTIMIZATION_STATUS\n",
    "print(f\"NLSQ available: {OPTIMIZATION_STATUS['nlsq_available']}\")\n",
    "print(f\"CMC available:  {OPTIMIZATION_STATUS['cmc_available']}\")\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "Homodyne is driven by a YAML configuration file. You can generate a template\n",
    "with the CLI:\n",
    "\n",
    "```bash\n",
    "homodyne-config --mode static --output config_quickstart.yaml\n",
    "```\n",
    "\n",
    "Here we create a minimal configuration programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a minimal YAML configuration string\n",
    "config_yaml = \"\"\"\n",
    "data:\n",
    "  file_path: \"sample_data.h5\"       # Replace with your HDF5 file path\n",
    "  dataset_path: \"/exchange/data\"    # Internal HDF5 path to C2 array\n",
    "  q_value: 0.054                    # Scattering vector in Å⁻¹\n",
    "  dt: 0.1                           # Frame interval in seconds\n",
    "\n",
    "analysis:\n",
    "  mode: \"static\"                    # Static mode: 3 parameters\n",
    "\n",
    "optimization:\n",
    "  method: \"nlsq\"\n",
    "  nlsq:\n",
    "    anti_degeneracy:\n",
    "      per_angle_mode: \"auto\"        # Recommended: prevents parameter absorption\n",
    "\n",
    "parameter_space:\n",
    "  D0:\n",
    "    initial: 1000.0\n",
    "    bounds: [0.1, 1.0e6]\n",
    "  alpha:\n",
    "    initial: -0.5\n",
    "    bounds: [-2.0, 1.0]\n",
    "  D_offset:\n",
    "    initial: 0.01\n",
    "    bounds: [0.0, 1.0e4]\n",
    "\"\"\"\n",
    "\n",
    "# Save the config to a temporary file\n",
    "import tempfile, os\n",
    "config_file = tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False)\n",
    "config_file.write(config_yaml)\n",
    "config_file.close()\n",
    "print(f\"Config written to: {config_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration\n",
    "config = ConfigManager.from_yaml(config_file.name)\n",
    "\n",
    "print(f\"Analysis mode: {config.analysis_mode}\")\n",
    "print(f\"Initial parameters: {config.get_initial_parameters()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Data\n",
    "\n",
    "The `load_xpcs_data` function reads an HDF5 file and returns a standardized\n",
    "dictionary. We create synthetic data here for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic XPCS data for demonstration\n",
    "# In a real analysis, use: data = load_xpcs_data(config_file.name)\n",
    "\n",
    "def generate_synthetic_c2(\n",
    "    q=0.054,          # Å⁻¹\n",
    "    D0=1200.0,        # Å²/s\n",
    "    alpha=-0.5,       # sub-diffusion\n",
    "    D_offset=0.05,    # Å²/s\n",
    "    beta=0.12,        # speckle contrast\n",
    "    offset=1.0,       # background\n",
    "    n_phi=5,          # number of angles\n",
    "    n_t=40,           # time points\n",
    "    dt=0.1,           # s\n",
    "    noise_level=0.005,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"Generate synthetic two-time correlation data.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    t = dt * np.arange(n_t)\n",
    "    phi = np.linspace(0, 180, n_phi)\n",
    "\n",
    "    # Build C2 matrix for each angle\n",
    "    c2 = np.zeros((n_phi, n_t, n_t))\n",
    "    for i_phi in range(n_phi):\n",
    "        for i_t1, t1 in enumerate(t):\n",
    "            for i_t2, t2 in enumerate(t):\n",
    "                if t2 < t1:\n",
    "                    continue\n",
    "                dt_lag = t2 - t1\n",
    "                # Diffusion kernel\n",
    "                J = (D0 * (t2**(alpha+1) - t1**(alpha+1)) / (alpha+1)\n",
    "                     + D_offset * dt_lag)\n",
    "                g1_sq = np.exp(-2 * q**2 * J)\n",
    "                c2_val = offset + beta * g1_sq\n",
    "                c2[i_phi, i_t1, i_t2] = c2_val\n",
    "                c2[i_phi, i_t2, i_t1] = c2_val  # symmetrize\n",
    "\n",
    "    # Add noise\n",
    "    c2 += noise_level * rng.standard_normal(c2.shape)\n",
    "\n",
    "    return {\n",
    "        'c2_exp': c2,\n",
    "        't1': t,\n",
    "        't2': t,\n",
    "        'phi_angles_list': phi,\n",
    "        'wavevector_q_list': np.array([q]),\n",
    "        'sigma': noise_level * np.ones_like(c2),\n",
    "        'L': 5.0e6,    # 500 µm in Å\n",
    "        'dt': dt,\n",
    "    }\n",
    "\n",
    "\n",
    "# Generate data with known parameters\n",
    "TRUE_PARAMS = {'D0': 1200.0, 'alpha': -0.5, 'D_offset': 0.05}\n",
    "data = generate_synthetic_c2(**TRUE_PARAMS)\n",
    "\n",
    "print(f\"C2 shape: {data['c2_exp'].shape}  # (n_phi, n_t1, n_t2)\")\n",
    "print(f\"Time points: {len(data['t1'])}\")\n",
    "print(f\"Angles: {data['phi_angles_list']}\")\n",
    "print(f\"q = {data['wavevector_q_list'][0]:.4f} Å⁻¹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the Raw Data\n",
    "\n",
    "Before fitting, always inspect the raw C2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, data['c2_exp'].shape[0], figsize=(3 * data['c2_exp'].shape[0], 3))\n",
    "if data['c2_exp'].shape[0] == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "phi = data['phi_angles_list']\n",
    "t = data['t1']\n",
    "c2 = data['c2_exp']\n",
    "\n",
    "for i_phi, ax in enumerate(axes):\n",
    "    im = ax.pcolormesh(t, t, c2[i_phi].T, cmap='hot', vmin=0.98, vmax=1.12, shading='auto')\n",
    "    ax.set_xlabel('t1 (s)')\n",
    "    ax.set_ylabel('t2 (s)')\n",
    "    ax.set_title(f'φ = {phi[i_phi]:.0f}°')\n",
    "    plt.colorbar(im, ax=ax, label='C2')\n",
    "\n",
    "plt.suptitle('Two-Time Correlation Matrix', y=1.02, fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation:\")\n",
    "print(\"  - Bright region near diagonal = fast dynamics (short lag)\")\n",
    "print(\"  - Uniform off-diagonal = long-time background (offset)\")\n",
    "print(\"  - Similar patterns for all angles = static mode appropriate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run NLSQ Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homodyne.utils.logging import log_phase\n",
    "\n",
    "print(\"Running NLSQ optimization...\")\n",
    "with log_phase(\"NLSQ\"):\n",
    "    result = fit_nlsq_jax(data, config)\n",
    "\n",
    "print(f\"\\nConvergence: {result.convergence_status}\")\n",
    "print(f\"Reduced chi-squared: {result.reduced_chi_squared:.4f}\")\n",
    "print(f\"Iterations: {result.iterations}\")\n",
    "print(f\"Time: {result.execution_time:.2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inspect Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display fitted vs true parameters\n",
    "print(f\"{'Parameter':<20} {'True':>12} {'Fitted':>12} {'Error':>12} {'Rel. Error':>12}\")\n",
    "print('-' * 70)\n",
    "\n",
    "param_names = ['D0', 'alpha', 'D_offset']\n",
    "for i, name in enumerate(param_names):\n",
    "    true_val = TRUE_PARAMS.get(name, float('nan'))\n",
    "    fitted_val = result.parameters[i]\n",
    "    fitted_err = result.uncertainties[i]\n",
    "\n",
    "    if true_val != 0 and not np.isnan(true_val):\n",
    "        rel_err = abs(fitted_val - true_val) / abs(true_val) * 100\n",
    "        rel_str = f\"{rel_err:.1f}%\"\n",
    "    else:\n",
    "        rel_str = \"N/A\"\n",
    "\n",
    "    print(f\"{name:<20} {true_val:>12.4g} {fitted_val:>12.4g} {fitted_err:>12.4g} {rel_str:>12}\")\n",
    "\n",
    "print(f\"\\nFit quality: {result.quality_flag}\")\n",
    "print(f\"chi^2 / dof: {result.reduced_chi_squared:.4f}  (ideal: ~1.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Fit Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract anti-diagonal cuts (fixed lag time)\n",
    "def get_lag_cut(c2, t, lag_idx):\n",
    "    \"\"\"Get C2 values along anti-diagonal at given lag index.\"\"\"\n",
    "    n = c2.shape[0] - lag_idx\n",
    "    c2_vals = np.array([c2[k, k + lag_idx] for k in range(n)])\n",
    "    t_vals = t[:n]\n",
    "    return t_vals, c2_vals\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "# Left: experimental data at several lag times\n",
    "ax = axes[0]\n",
    "lags = [1, 5, 15, 30]\n",
    "colors = plt.cm.plasma(np.linspace(0.1, 0.9, len(lags)))\n",
    "for lag, color in zip(lags, colors):\n",
    "    t_vals, c2_vals = get_lag_cut(c2[0], t, lag)\n",
    "    lag_time = t[lag] - t[0]\n",
    "    ax.plot(t_vals, c2_vals, 'o-', color=color, markersize=3,\n",
    "            alpha=0.8, label=f'lag = {lag_time:.2f} s')\n",
    "ax.set_xlabel('t1 (s)')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title('Experimental C2 (angle 0°)')\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_ylim(0.98, 1.15)\n",
    "\n",
    "# Right: C2 vs lag time (anti-diagonal)\n",
    "ax = axes[1]\n",
    "lag_indices = range(1, len(t) - 1)\n",
    "lag_times = [t[k] - t[0] for k in lag_indices]\n",
    "c2_mean_lag = []\n",
    "for lag_idx in lag_indices:\n",
    "    _, c2_vals = get_lag_cut(c2[0], t, lag_idx)\n",
    "    c2_mean_lag.append(np.mean(c2_vals))\n",
    "\n",
    "ax.semilogx(lag_times, c2_mean_lag, 'ko', markersize=4, label='Experiment')\n",
    "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.5, label='Baseline')\n",
    "ax.set_xlabel('Lag time (s)')\n",
    "ax.set_ylabel('⟨C2⟩ (averaged over t1)')\n",
    "ax.set_title(f'Decorrelation curve  (chi²_nu = {result.reduced_chi_squared:.3f})')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Physical Interpretation\n",
    "\n",
    "Let's interpret the fitted parameters in physical terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D0_fitted = result.parameters[0]\n",
    "alpha_fitted = result.parameters[1]\n",
    "D0_err = result.uncertainties[0]\n",
    "\n",
    "q = data['wavevector_q_list'][0]  # Å⁻¹\n",
    "\n",
    "# Estimate relaxation time\n",
    "# For anomalous diffusion: tau ~ (q^2 D0)^(-1/alpha)\n",
    "tau_q = (q**2 * D0_fitted) ** (-1 / alpha_fitted) if alpha_fitted != 0 else float('inf')\n",
    "\n",
    "# Estimate particle size from Stokes-Einstein (water at 25°C)\n",
    "kT = 4.11e-21        # J (at 25°C)\n",
    "eta_water = 8.9e-4   # Pa·s\n",
    "D0_m2s = D0_fitted * 1e-20  # Å²/s → m²/s\n",
    "Rh_nm = kT / (6 * np.pi * eta_water * D0_m2s) * 1e9  # Rh in nm\n",
    "\n",
    "print(\"Physical Interpretation\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"D0 = {D0_fitted:.0f} ± {D0_err:.0f} Å²/s\")\n",
    "\n",
    "if alpha_fitted < 0:\n",
    "    print(f\"alpha = {alpha_fitted:.3f} → sub-diffusion (caged/gel-like motion)\")\n",
    "elif alpha_fitted > 0:\n",
    "    print(f\"alpha = {alpha_fitted:.3f} → super-diffusion\")\n",
    "else:\n",
    "    print(f\"alpha = {alpha_fitted:.3f} → normal Brownian diffusion\")\n",
    "\n",
    "print(f\"\\nEstimated particle radius (Stokes-Einstein, water 25°C):\")\n",
    "print(f\"  Rh = {Rh_nm:.1f} nm\")\n",
    "print(f\"\\nCharacteristic relaxation time at q = {q:.4f} Å⁻¹:\")\n",
    "print(f\"  tau_q ~ {tau_q:.3f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"quickstart_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "result_dict = {\n",
    "    \"analysis_mode\": config.analysis_mode,\n",
    "    \"convergence_status\": result.convergence_status,\n",
    "    \"reduced_chi_squared\": float(result.reduced_chi_squared),\n",
    "    \"parameters\": {\n",
    "        \"D0\":       {\"value\": float(result.parameters[0]), \"uncertainty\": float(result.uncertainties[0])},\n",
    "        \"alpha\":    {\"value\": float(result.parameters[1]), \"uncertainty\": float(result.uncertainties[1])},\n",
    "        \"D_offset\": {\"value\": float(result.parameters[2]), \"uncertainty\": float(result.uncertainties[2])},\n",
    "    },\n",
    "    \"execution_time_s\": float(result.execution_time),\n",
    "}\n",
    "\n",
    "with open(output_dir / \"nlsq_result.json\", \"w\") as f:\n",
    "    json.dump(result_dict, f, indent=2)\n",
    "\n",
    "import numpy as np\n",
    "np.savez(\n",
    "    output_dir / \"nlsq_arrays.npz\",\n",
    "    parameters=result.parameters,\n",
    "    uncertainties=result.uncertainties,\n",
    "    covariance=result.covariance,\n",
    ")\n",
    "\n",
    "print(f\"Results saved to {output_dir}/\")\n",
    "print(f\"  nlsq_result.json  — parameter estimates and quality metrics\")\n",
    "print(f\"  nlsq_arrays.npz   — numerical arrays (covariance matrix, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "You have completed the quickstart! From here you can:\n",
    "\n",
    "- **Replace the synthetic data** with your real HDF5 file by setting `file_path` in the config\n",
    "- **Try laminar flow mode** if your sample is in a shear cell: `mode: \"laminar_flow\"`\n",
    "- **Run Bayesian analysis** for publication-quality uncertainties: see `02_static_analysis.ipynb`\n",
    "- **Explore the full config** with `homodyne-config --mode static --output my_config.yaml`\n",
    "\n",
    "### Quick reference\n",
    "\n",
    "| Command | Purpose |\n",
    "|---------|----------|\n",
    "| `homodyne --config config.yaml` | Run full analysis |\n",
    "| `homodyne-config --mode static` | Generate config template |\n",
    "| `homodyne-config --validate --input config.yaml` | Check config |\n",
    "| `homodyne-config-xla --show` | Show CPU tuning recommendations |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary config file\n",
    "os.unlink(config_file.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
