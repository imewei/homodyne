{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Mode Analysis: Complete Workflow\n",
    "\n",
    "This notebook covers the complete static-mode analysis workflow:\n",
    "\n",
    "1. Loading and validating experimental data\n",
    "2. Parameter exploration and initial value selection\n",
    "3. NLSQ fitting with diagnostics\n",
    "4. Multi-start optimization for robustness\n",
    "5. Result visualization and physical interpretation\n",
    "\n",
    "**Use static mode when:** your sample is in equilibrium (no shear/flow) and\n",
    "you see no angular dependence in C2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from homodyne.config import ConfigManager\n",
    "from homodyne.data import validate_xpcs_data\n",
    "from homodyne.optimization.nlsq import fit_nlsq_jax\n",
    "from homodyne.utils.logging import get_logger, log_phase\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate synthetic static-mode data\n# (Replace with: data = load_xpcs_data(\"your_config.yaml\"))\n\nrng = np.random.default_rng(seed=123)\n\n# True parameters for validation\nTRUE = {\n    \"D0\": 850.0,  # Å²/s\n    \"alpha\": -0.35,  # Mild sub-diffusion\n    \"D_offset\": 0.08,  # Å²/s\n    \"beta_contrast\": 0.15,\n    \"offset\": 1.0,\n}\n\nq = 0.054  # Å⁻¹\nn_t = 50\nn_phi = 8\ndt = 0.1\nt = dt * np.arange(n_t)\nphi_angles = np.linspace(0, 315, n_phi)  # 0° to 315° in steps of 45°\n\n# Precompute D(t) on the time grid and its cumulative trapezoid\nD_t = TRUE[\"D0\"] * t ** TRUE[\"alpha\"] + TRUE[\"D_offset\"]\ntrap_avg = 0.5 * (D_t[:-1] + D_t[1:])\nD_cumsum = np.concatenate([[0.0], np.cumsum(trap_avg)])\n\nc2 = np.zeros((n_phi, n_t, n_t))\nfor i_phi in range(n_phi):\n    for i_t1 in range(n_t):\n        for i_t2 in range(i_t1, n_t):\n            # Diffusion integral (cumulative trapezoid)\n            D_integral = abs(D_cumsum[i_t2] - D_cumsum[i_t1]) * dt\n            g1_sq = np.exp(-2 * q**2 * D_integral)\n            val = TRUE[\"offset\"] + TRUE[\"beta_contrast\"] * g1_sq\n            noise = 0.003 * rng.standard_normal()\n            c2[i_phi, i_t1, i_t2] = val + noise\n            c2[i_phi, i_t2, i_t1] = val + noise  # symmetric\n\ndata = {\n    \"c2_exp\": c2,\n    \"t1\": t,\n    \"t2\": t,\n    \"phi_angles_list\": phi_angles,\n    \"wavevector_q_list\": np.array([q]),\n    \"sigma\": 0.003 * np.ones_like(c2),\n    \"L\": 5.0e6,\n    \"dt\": dt,\n}\n\nprint(f\"Data shape: {c2.shape}  # (n_phi={n_phi}, n_t1={n_t}, n_t2={n_t})\")\nprint(f\"q = {q} Å⁻¹,  {n_phi} angles,  dt = {dt} s\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the loaded data\n",
    "report = validate_xpcs_data(data)\n",
    "\n",
    "print(f\"Data valid: {report.is_valid}\")\n",
    "if report.warnings:\n",
    "    print(f\"Warnings:   {[w.message for w in report.warnings]}\")\n",
    "if report.errors:\n",
    "    print(f\"Errors:     {[e.message for e in report.errors]}\")\n",
    "\n",
    "# Check angular dependence (should be minimal for static mode)\n",
    "lag_idx = 3\n",
    "c2_at_lag = np.array([c2[i_phi, 0, lag_idx] for i_phi in range(n_phi)])\n",
    "angular_var_ratio = c2_at_lag.std() / c2_at_lag.mean()\n",
    "print(f\"\\nAngular variance ratio at lag={lag_idx}: {angular_var_ratio:.4f}\")\n",
    "if angular_var_ratio < 0.02:\n",
    "    print(\"→ No significant angular dependence → static mode is appropriate\")\n",
    "else:\n",
    "    print(\"→ Angular dependence detected → consider laminar_flow mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Space Exploration\n",
    "\n",
    "Before fitting, it's useful to understand the parameter landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Explore how D0 affects the decorrelation curve\ndef model_c2_1d(t_arr, D0, alpha, D_offset, contrast, offset, q):\n    \"\"\"Simple 1D C2 model (time-averaged, no angle dependence).\"\"\"\n    dt_grid = t_arr[1] - t_arr[0] if len(t_arr) > 1 else 1.0\n    # Precompute D(t) on the time grid and its cumulative trapezoid\n    D_t = D0 * t_arr**alpha + D_offset\n    trap_avg = 0.5 * (D_t[:-1] + D_t[1:])\n    D_cumsum = np.concatenate([[0.0], np.cumsum(trap_avg)])\n    c2_vals = []\n    for i_t2 in range(len(t_arr)):\n        # Diffusion integral (cumulative trapezoid)\n        D_integral = abs(D_cumsum[i_t2] - D_cumsum[0]) * dt_grid\n        g1_sq = np.exp(-2 * q**2 * D_integral)\n        c2_vals.append(offset + contrast * g1_sq)\n    return np.array(c2_vals)\n\n\nfig, axes = plt.subplots(1, 3, figsize=(13, 4))\n\n# Vary D0\nax = axes[0]\nfor D0_test in [200, 500, 850, 2000, 5000]:\n    c2_model = model_c2_1d(\n        t,\n        D0_test,\n        TRUE[\"alpha\"],\n        TRUE[\"D_offset\"],\n        TRUE[\"beta_contrast\"],\n        TRUE[\"offset\"],\n        q,\n    )\n    ax.semilogx(t, c2_model, label=f\"D0={D0_test}\")\nax.set_xlabel(\"t (s)\")\nax.set_ylabel(\"C2\")\nax.set_title(\"Effect of D0\")\nax.legend(fontsize=8)\n\n# Vary alpha\nax = axes[1]\nfor alpha_test in [-1.5, -1.0, -0.5, 0.0, 0.5]:\n    c2_model = model_c2_1d(\n        t,\n        TRUE[\"D0\"],\n        alpha_test,\n        TRUE[\"D_offset\"],\n        TRUE[\"beta_contrast\"],\n        TRUE[\"offset\"],\n        q,\n    )\n    ax.semilogx(t, c2_model, label=f\"α={alpha_test}\")\nax.set_xlabel(\"t (s)\")\nax.set_title(\"Effect of alpha\")\nax.legend(fontsize=8)\n\n# Vary contrast\nax = axes[2]\nfor beta_test in [0.05, 0.10, 0.15, 0.25, 0.40]:\n    c2_model = model_c2_1d(\n        t, TRUE[\"D0\"], TRUE[\"alpha\"], TRUE[\"D_offset\"], beta_test, TRUE[\"offset\"], q\n    )\n    ax.semilogx(t, c2_model, label=f\"β={beta_test}\")\nax.set_xlabel(\"t (s)\")\nax.set_title(\"Effect of contrast (β)\")\nax.legend(fontsize=8)\n\nplt.suptitle(\"Parameter Sensitivity Analysis\", fontsize=12)\nplt.tight_layout()\ndisplay(fig)\nplt.close(fig)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single-Start NLSQ Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "config_yaml = \"\"\"\n",
    "analysis_mode: \"static\"\n",
    "\n",
    "analyzer_parameters:\n",
    "  dt: 0.1\n",
    "\n",
    "optimization:\n",
    "  method: \"nlsq\"\n",
    "  nlsq:\n",
    "    anti_degeneracy:\n",
    "      per_angle_mode: \"auto\"\n",
    "\n",
    "initial_parameters:\n",
    "  parameter_names: [D0, alpha, D_offset]\n",
    "  values: [500.0, -0.5, 0.1]\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".yaml\", delete=False) as f:\n",
    "    f.write(config_yaml)\n",
    "    config_path = f.name\n",
    "\n",
    "config = ConfigManager(config_path)\n",
    "\n",
    "with log_phase(\"NLSQ Single-Start\"):\n",
    "    result_single = fit_nlsq_jax(data, config)\n",
    "\n",
    "# Physical parameters come after per-angle scaling\n",
    "phys_offset = 2 * n_phi\n",
    "\n",
    "print(f\"Status:      {result_single.convergence_status}\")\n",
    "print(f\"chi^2_nu:    {result_single.reduced_chi_squared:.4f}\")\n",
    "print(f\"Time:        {result_single.execution_time:.2f} s\")\n",
    "print()\n",
    "print(f\"{'Param':<12} {'True':>10} {'Fitted':>10} {'Err':>10}\")\n",
    "print(\"-\" * 46)\n",
    "for i, name in enumerate([\"D0\", \"alpha\", \"D_offset\"]):\n",
    "    tv = TRUE[name]\n",
    "    fv = result_single.parameters[phys_offset + i]\n",
    "    fe = result_single.uncertainties[phys_offset + i]\n",
    "    print(f\"{name:<12} {tv:>10.4g} {fv:>10.4g} {fe:>10.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Multi-Start Optimization\n\nFor robust results, run multiple starts and take the best. Multi-start\nexplores the parameter space using Latin Hypercube Sampling to avoid\nlocal minima."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-start with Latin Hypercube Sampling\n",
    "# Multi-start is configured via the YAML config\n",
    "from homodyne.optimization.nlsq import fit_nlsq_multistart\n",
    "\n",
    "ms_config_yaml = \"\"\"\n",
    "analysis_mode: \"static\"\n",
    "\n",
    "analyzer_parameters:\n",
    "  dt: 0.1\n",
    "\n",
    "optimization:\n",
    "  method: \"nlsq\"\n",
    "  nlsq:\n",
    "    anti_degeneracy:\n",
    "      per_angle_mode: \"auto\"\n",
    "    multi_start:\n",
    "      enable: true\n",
    "      n_starts: 10\n",
    "      sampling_strategy: \"latin_hypercube\"\n",
    "\n",
    "initial_parameters:\n",
    "  parameter_names: [D0, alpha, D_offset]\n",
    "  values: [500.0, -0.5, 0.1]\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".yaml\", delete=False) as f:\n",
    "    f.write(ms_config_yaml)\n",
    "    ms_config_path = f.name\n",
    "\n",
    "config_ms = ConfigManager(ms_config_path)\n",
    "\n",
    "with log_phase(\"NLSQ Multi-Start\"):\n",
    "    result_multi = fit_nlsq_multistart(data, config_ms)\n",
    "\n",
    "print(f\"Best chi^2_nu:        {result_multi.best.reduced_chi_squared:.4f}\")\n",
    "print(\n",
    "    f\"Starts converged:     {result_multi.n_successful}/{len(result_multi.all_results)}\"\n",
    ")\n",
    "print(f\"Unique basins:        {result_multi.n_unique_basins}\")\n",
    "print()\n",
    "\n",
    "# Show spread of D0 estimates across starts to assess uniqueness\n",
    "D0_estimates = [\n",
    "    s.final_params[phys_offset] for s in result_multi.all_results if s.success\n",
    "]\n",
    "if D0_estimates:\n",
    "    print(\n",
    "        f\"D0 across converged starts: mean={np.mean(D0_estimates):.1f},\"\n",
    "        f\" std={np.std(D0_estimates):.1f} Å²/s\"\n",
    "    )\n",
    "    print(\"(Small std → unique global minimum; large std → multi-modal)\")\n",
    "\n",
    "import os\n",
    "\n",
    "os.unlink(ms_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Starting Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sensitivity to initial parameters\n",
    "# Note: initial_params must include contrast and offset alongside physical parameters\n",
    "initial_conditions = [\n",
    "    {\"D0\": 100, \"alpha\": -1.0, \"D_offset\": 0.01, \"label\": \"Far below\"},\n",
    "    {\"D0\": 500, \"alpha\": -0.5, \"D_offset\": 0.1, \"label\": \"Near true\"},\n",
    "    {\"D0\": 5000, \"alpha\": 0.5, \"D_offset\": 1.0, \"label\": \"Far above\"},\n",
    "    {\"D0\": 850, \"alpha\": -0.3, \"D_offset\": 0.05, \"label\": \"Very close\"},\n",
    "]\n",
    "\n",
    "results_ic = []\n",
    "for ic in initial_conditions:\n",
    "    init = {\n",
    "        \"contrast\": 0.15,  # Estimated speckle contrast\n",
    "        \"offset\": 1.0,  # Baseline offset\n",
    "        \"D0\": ic[\"D0\"],\n",
    "        \"alpha\": ic[\"alpha\"],\n",
    "        \"D_offset\": ic[\"D_offset\"],\n",
    "    }\n",
    "    r = fit_nlsq_jax(data, config, initial_params=init)\n",
    "    results_ic.append({\"label\": ic[\"label\"], \"result\": r})\n",
    "\n",
    "print(\n",
    "    f\"{'Starting point':<18} {'D0 fitted':>12} {'alpha':>10} {'chi2_nu':>10} {'status':>12}\"\n",
    ")\n",
    "print(\"-\" * 66)\n",
    "for entry in results_ic:\n",
    "    r = entry[\"result\"]\n",
    "    print(\n",
    "        f\"{entry['label']:<18} {r.parameters[phys_offset]:>12.1f} {r.parameters[phys_offset + 1]:>10.3f}\"\n",
    "        f\" {r.reduced_chi_squared:>10.4f} {r.convergence_status:>12}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "best_result = result_multi.best\nD0_fit = best_result.final_params[phys_offset]\nalpha_fit = best_result.final_params[phys_offset + 1]\nD_offset_fit = best_result.final_params[phys_offset + 2]\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Plot 1: C2 lag-time curve with model overlay\nax = axes[0]\n# Experimental: average over all angles\nlag_indices = range(1, n_t - 1)\nlag_times = [t[k] for k in lag_indices]\nc2_exp_avg = []\nfor lag_idx in lag_indices:\n    n = n_t - lag_idx\n    vals = np.array(\n        [c2[i_phi, k, k + lag_idx] for i_phi in range(n_phi) for k in range(n)]\n    )\n    c2_exp_avg.append(np.mean(vals))\n\n# Precompute D(t) on the time grid and its cumulative trapezoid (fitted params)\nD_t_fit = D0_fit * t**alpha_fit + D_offset_fit\ntrap_avg_fit = 0.5 * (D_t_fit[:-1] + D_t_fit[1:])\nD_cumsum_fit = np.concatenate([[0.0], np.cumsum(trap_avg_fit)])\n\n# Model (from fitted params)\nc2_model_avg = []\nfor lag_idx in lag_indices:\n    # Diffusion integral (cumulative trapezoid)\n    D_integral = abs(D_cumsum_fit[lag_idx] - D_cumsum_fit[0]) * dt\n    g1_sq = np.exp(-2 * q**2 * D_integral)\n    c2_model_avg.append(1.0 + 0.15 * g1_sq)  # using estimated contrast\n\nax.semilogx(lag_times, c2_exp_avg, \"ko\", markersize=3, label=\"Experiment\")\nax.semilogx(lag_times, c2_model_avg, \"r-\", linewidth=2, label=\"Model fit\")\nax.set_xlabel(\"Lag time (s)\")\nax.set_ylabel(\"⟨C2⟩\")\nax.set_title(f\"Fit quality: chi²_nu = {best_result.reduced_chi_squared:.3f}\")\nax.legend()\n\n# Plot 2: Parameter comparison\nax = axes[1]\nparam_names_plot = [\"D0\", \"alpha\", \"D_offset\"]\ntrue_vals = [TRUE[\"D0\"], TRUE[\"alpha\"], TRUE[\"D_offset\"]]\nfitted_vals = [best_result.final_params[phys_offset + i] for i in range(3)]\n# Uncertainties from covariance if available\nif best_result.covariance is not None:\n    fitted_errs = [\n        np.sqrt(best_result.covariance[phys_offset + i, phys_offset + i])\n        for i in range(3)\n    ]\nelse:\n    fitted_errs = [0.0, 0.0, 0.0]\n\nx = np.arange(3)\nwidth = 0.35\nbars = ax.bar(\n    x, [abs(tv) for tv in true_vals], width, label=\"True\", alpha=0.6, color=\"steelblue\"\n)\nax.bar(\n    x + width,\n    [abs(fv) for fv in fitted_vals],\n    width,\n    yerr=[abs(e) for e in fitted_errs],\n    capsize=5,\n    label=\"Fitted\",\n    alpha=0.8,\n    color=\"orange\",\n)\nax.set_xticks(x + width / 2)\nax.set_xticklabels(param_names_plot)\nax.set_yscale(\"log\")\nax.set_ylabel(\"|Parameter value|\")\nax.set_title(\"True vs Fitted Parameters (absolute value)\")\nax.legend()\n\nplt.tight_layout()\ndisplay(fig)\nplt.close(fig)\n\nprint(\"\\nFitted parameters:\")\nfor name, tv, fv, fe in zip(param_names_plot, true_vals, fitted_vals, fitted_errs):\n    rel = abs(fv - tv) / abs(tv) * 100 if tv != 0 else float(\"nan\")\n    print(f\"  {name}: true={tv:.4g}, fitted={fv:.4g} ± {fe:.4g}  ({rel:.1f}% error)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "Key takeaways from static mode analysis:\n",
    "\n",
    "- **D₀** characterizes particle dynamics; compare to Stokes-Einstein for size\n",
    "- **alpha** reveals diffusion regime (< 0: sub, 0: normal, > 0: super)\n",
    "- **Anti-degeneracy** (`per_angle_mode: \"auto\"`) protects physical parameters\n",
    "- **Multi-start** provides confidence that the global minimum was found\n",
    "- **chi²_nu ~ 1** indicates a good fit with well-estimated uncertainties\n",
    "\n",
    "For rigorous uncertainty quantification, proceed to `04_bayesian_inference.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.unlink(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}