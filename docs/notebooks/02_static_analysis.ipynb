{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Mode Analysis: Complete Workflow\n",
    "\n",
    "This notebook covers the complete static-mode analysis workflow:\n",
    "\n",
    "1. Loading and validating experimental data\n",
    "2. Parameter exploration and initial value selection\n",
    "3. NLSQ fitting with diagnostics\n",
    "4. Multi-start optimization for robustness\n",
    "5. Result visualization and physical interpretation\n",
    "\n",
    "**Use static mode when:** your sample is in equilibrium (no shear/flow) and\n",
    "you see no angular dependence in C2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from homodyne.config import ConfigManager\n",
    "from homodyne.data import load_xpcs_data, validate_xpcs_data\n",
    "from homodyne.optimization.nlsq import fit_nlsq_jax, fit_nlsq_multistart, MultiStartConfig\n",
    "from homodyne.utils.logging import get_logger, log_phase\n",
    "\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic static-mode data\n",
    "# (Replace with: data = load_xpcs_data(\"your_config.yaml\"))\n",
    "\n",
    "rng = np.random.default_rng(seed=123)\n",
    "\n",
    "# True parameters for validation\n",
    "TRUE = {\n",
    "    'D0': 850.0,       # Å²/s\n",
    "    'alpha': -0.35,    # Mild sub-diffusion\n",
    "    'D_offset': 0.08,  # Å²/s\n",
    "    'beta_contrast': 0.15,\n",
    "    'offset': 1.0,\n",
    "}\n",
    "\n",
    "q = 0.054   # Å⁻¹\n",
    "n_t = 50\n",
    "n_phi = 8\n",
    "dt = 0.1\n",
    "t = dt * np.arange(n_t)\n",
    "phi_angles = np.linspace(0, 315, n_phi)  # 0° to 315° in steps of 45°\n",
    "\n",
    "c2 = np.zeros((n_phi, n_t, n_t))\n",
    "for i_phi in range(n_phi):\n",
    "    for i_t1 in range(n_t):\n",
    "        for i_t2 in range(i_t1, n_t):\n",
    "            t1_val, t2_val = t[i_t1], t[i_t2]\n",
    "            J = (TRUE['D0'] * (t2_val**(TRUE['alpha']+1) - t1_val**(TRUE['alpha']+1)) / (TRUE['alpha']+1)\n",
    "                 + TRUE['D_offset'] * (t2_val - t1_val))\n",
    "            g1_sq = np.exp(-2 * q**2 * J)\n",
    "            val = TRUE['offset'] + TRUE['beta_contrast'] * g1_sq\n",
    "            noise = 0.003 * rng.standard_normal()\n",
    "            c2[i_phi, i_t1, i_t2] = val + noise\n",
    "            c2[i_phi, i_t2, i_t1] = val + noise  # symmetric\n",
    "\n",
    "data = {\n",
    "    'c2_exp': c2,\n",
    "    't1': t,\n",
    "    't2': t,\n",
    "    'phi_angles_list': phi_angles,\n",
    "    'wavevector_q_list': np.array([q]),\n",
    "    'sigma': 0.003 * np.ones_like(c2),\n",
    "    'L': 5.0e6,\n",
    "    'dt': dt,\n",
    "}\n",
    "\n",
    "print(f\"Data shape: {c2.shape}  # (n_phi={n_phi}, n_t1={n_t}, n_t2={n_t})\")\n",
    "print(f\"q = {q} Å⁻¹,  {n_phi} angles,  dt = {dt} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the loaded data\n",
    "report = validate_xpcs_data(data)\n",
    "\n",
    "print(f\"Data valid: {report.is_valid}\")\n",
    "if report.warnings:\n",
    "    print(f\"Warnings:   {report.warnings}\")\n",
    "if report.issues:\n",
    "    print(f\"Issues:     {report.issues}\")\n",
    "\n",
    "# Check angular dependence (should be minimal for static mode)\n",
    "lag_idx = 3\n",
    "c2_at_lag = np.array([c2[i_phi, 0, lag_idx] for i_phi in range(n_phi)])\n",
    "angular_var_ratio = c2_at_lag.std() / c2_at_lag.mean()\n",
    "print(f\"\\nAngular variance ratio at lag={lag_idx}: {angular_var_ratio:.4f}\")\n",
    "if angular_var_ratio < 0.02:\n",
    "    print(\"→ No significant angular dependence → static mode is appropriate\")\n",
    "else:\n",
    "    print(\"→ Angular dependence detected → consider laminar_flow mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parameter Space Exploration\n",
    "\n",
    "Before fitting, it's useful to understand the parameter landscape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore how D0 affects the decorrelation curve\n",
    "def model_c2_1d(t_arr, D0, alpha, D_offset, contrast, offset, q):\n",
    "    \"\"\"Simple 1D C2 model (time-averaged, no angle dependence).\"\"\"\n",
    "    c2_vals = []\n",
    "    t0 = t_arr[0]\n",
    "    for t2 in t_arr:\n",
    "        J = (D0 * (t2**(alpha+1) - t0**(alpha+1)) / (alpha+1) + D_offset * (t2 - t0))\n",
    "        g1_sq = np.exp(-2 * q**2 * J)\n",
    "        c2_vals.append(offset + contrast * g1_sq)\n",
    "    return np.array(c2_vals)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "# Vary D0\n",
    "ax = axes[0]\n",
    "for D0_test in [200, 500, 850, 2000, 5000]:\n",
    "    c2_model = model_c2_1d(t, D0_test, TRUE['alpha'], TRUE['D_offset'],\n",
    "                            TRUE['beta_contrast'], TRUE['offset'], q)\n",
    "    ax.semilogx(t, c2_model, label=f'D0={D0_test}')\n",
    "ax.set_xlabel('t (s)')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title('Effect of D0')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Vary alpha\n",
    "ax = axes[1]\n",
    "for alpha_test in [-1.5, -1.0, -0.5, 0.0, 0.5]:\n",
    "    c2_model = model_c2_1d(t, TRUE['D0'], alpha_test, TRUE['D_offset'],\n",
    "                            TRUE['beta_contrast'], TRUE['offset'], q)\n",
    "    ax.semilogx(t, c2_model, label=f'α={alpha_test}')\n",
    "ax.set_xlabel('t (s)')\n",
    "ax.set_title('Effect of alpha')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# Vary contrast\n",
    "ax = axes[2]\n",
    "for beta_test in [0.05, 0.10, 0.15, 0.25, 0.40]:\n",
    "    c2_model = model_c2_1d(t, TRUE['D0'], TRUE['alpha'], TRUE['D_offset'],\n",
    "                            beta_test, TRUE['offset'], q)\n",
    "    ax.semilogx(t, c2_model, label=f'β={beta_test}')\n",
    "ax.set_xlabel('t (s)')\n",
    "ax.set_title('Effect of contrast (β)')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle('Parameter Sensitivity Analysis', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Single-Start NLSQ Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "config_yaml = \"\"\"\n",
    "data:\n",
    "  file_path: \"dummy.h5\"\n",
    "  q_value: 0.054\n",
    "  dt: 0.1\n",
    "\n",
    "analysis:\n",
    "  mode: \"static\"\n",
    "\n",
    "optimization:\n",
    "  method: \"nlsq\"\n",
    "  nlsq:\n",
    "    anti_degeneracy:\n",
    "      per_angle_mode: \"auto\"\n",
    "\n",
    "parameter_space:\n",
    "  D0:\n",
    "    initial: 500.0\n",
    "    bounds: [0.1, 1.0e5]\n",
    "  alpha:\n",
    "    initial: -0.5\n",
    "    bounds: [-2.0, 1.0]\n",
    "  D_offset:\n",
    "    initial: 0.1\n",
    "    bounds: [0.0, 100.0]\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as f:\n",
    "    f.write(config_yaml)\n",
    "    config_path = f.name\n",
    "\n",
    "config = ConfigManager.from_yaml(config_path)\n",
    "\n",
    "with log_phase(\"NLSQ Single-Start\"):\n",
    "    result_single = fit_nlsq_jax(data, config)\n",
    "\n",
    "print(f\"Status:      {result_single.convergence_status}\")\n",
    "print(f\"chi^2_nu:    {result_single.reduced_chi_squared:.4f}\")\n",
    "print(f\"Time:        {result_single.execution_time:.2f} s\")\n",
    "print()\n",
    "print(f\"{'Param':<12} {'True':>10} {'Fitted':>10} {'Err':>10}\")\n",
    "print('-' * 46)\n",
    "for i, name in enumerate(['D0', 'alpha', 'D_offset']):\n",
    "    tv = TRUE[name]\n",
    "    fv = result_single.parameters[i]\n",
    "    fe = result_single.uncertainties[i]\n",
    "    print(f\"{name:<12} {tv:>10.4g} {fv:>10.4g} {fe:>10.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Start Optimization\n",
    "\n",
    "For robust results, run multiple starts and take the best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-start with Latin Hypercube Sampling\n",
    "ms_config = MultiStartConfig(\n",
    "    n_starts=10,       # Number of random starting points\n",
    "    use_lhs=True,      # Latin Hypercube Sampling for coverage\n",
    ")\n",
    "\n",
    "with log_phase(\"NLSQ Multi-Start\"):\n",
    "    result_multi = fit_nlsq_multistart(data, config, ms_config=ms_config)\n",
    "\n",
    "print(f\"Best chi^2_nu:        {result_multi.best_result.reduced_chi_squared:.4f}\")\n",
    "print(f\"Starts converged:     {result_multi.n_converged}/{result_multi.n_starts}\")\n",
    "print(f\"Best start index:     {result_multi.best_start_idx}\")\n",
    "print()\n",
    "\n",
    "# Show spread of D0 estimates across starts to assess uniqueness\n",
    "D0_estimates = [s.result.parameters[0] for s in result_multi.all_starts\n",
    "                if s.result.convergence_status == 'converged']\n",
    "print(f\"D0 across converged starts: mean={np.mean(D0_estimates):.1f},\"\n",
    "      f\" std={np.std(D0_estimates):.1f} Å²/s\")\n",
    "print(\"(Small std → unique global minimum; large std → multi-modal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparing Starting Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test sensitivity to initial parameters\n",
    "initial_conditions = [\n",
    "    {'D0': 100,  'alpha': -1.0, 'D_offset': 0.01,  'label': 'Far below'},\n",
    "    {'D0': 500,  'alpha': -0.5, 'D_offset': 0.1,   'label': 'Near true'},\n",
    "    {'D0': 5000, 'alpha':  0.5, 'D_offset': 1.0,   'label': 'Far above'},\n",
    "    {'D0': 850,  'alpha': -0.3, 'D_offset': 0.05,  'label': 'Very close'},\n",
    "]\n",
    "\n",
    "results_ic = []\n",
    "for ic in initial_conditions:\n",
    "    init = {k: ic[k] for k in ['D0', 'alpha', 'D_offset']}\n",
    "    r = fit_nlsq_jax(data, config, initial_params=init)\n",
    "    results_ic.append({'label': ic['label'], 'result': r})\n",
    "\n",
    "print(f\"{'Starting point':<18} {'D0 fitted':>12} {'alpha':>10} {'chi2_nu':>10} {'status':>12}\")\n",
    "print('-' * 66)\n",
    "for entry in results_ic:\n",
    "    r = entry['result']\n",
    "    print(f\"{entry['label']:<18} {r.parameters[0]:>12.1f} {r.parameters[1]:>10.3f}\"\n",
    "          f\" {r.reduced_chi_squared:>10.4f} {r.convergence_status:>12}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = result_multi.best_result\n",
    "D0_fit = best_result.parameters[0]\n",
    "alpha_fit = best_result.parameters[1]\n",
    "D_offset_fit = best_result.parameters[2]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot 1: C2 lag-time curve with model overlay\n",
    "ax = axes[0]\n",
    "# Experimental: average over all angles\n",
    "lag_indices = range(1, n_t - 1)\n",
    "lag_times = [t[k] for k in lag_indices]\n",
    "c2_exp_avg = []\n",
    "for lag_idx in lag_indices:\n",
    "    n = n_t - lag_idx\n",
    "    vals = np.array([c2[i_phi, k, k + lag_idx]\n",
    "                     for i_phi in range(n_phi) for k in range(n)])\n",
    "    c2_exp_avg.append(np.mean(vals))\n",
    "\n",
    "# Model (from fitted params)\n",
    "t0 = t[0]\n",
    "c2_model_avg = []\n",
    "for lag_idx in lag_indices:\n",
    "    t2 = t[lag_idx]\n",
    "    J = (D0_fit * (t2**(alpha_fit+1) - t0**(alpha_fit+1)) / (alpha_fit+1)\n",
    "         + D_offset_fit * (t2 - t0))\n",
    "    g1_sq = np.exp(-2 * q**2 * J)\n",
    "    c2_model_avg.append(1.0 + 0.15 * g1_sq)  # using estimated contrast\n",
    "\n",
    "ax.semilogx(lag_times, c2_exp_avg, 'ko', markersize=3, label='Experiment')\n",
    "ax.semilogx(lag_times, c2_model_avg, 'r-', linewidth=2, label='Model fit')\n",
    "ax.set_xlabel('Lag time (s)')\n",
    "ax.set_ylabel('⟨C2⟩')\n",
    "ax.set_title(f'Fit quality: chi²_nu = {best_result.reduced_chi_squared:.3f}')\n",
    "ax.legend()\n",
    "\n",
    "# Plot 2: Parameter comparison\n",
    "ax = axes[1]\n",
    "param_names_plot = ['D0', 'alpha', 'D_offset']\n",
    "true_vals = [TRUE['D0'], TRUE['alpha'], TRUE['D_offset']]\n",
    "fitted_vals = best_result.parameters[:3]\n",
    "fitted_errs = best_result.uncertainties[:3]\n",
    "\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "bars = ax.bar(x, [abs(tv) for tv in true_vals], width, label='True', alpha=0.6, color='steelblue')\n",
    "ax.bar(x + width, [abs(fv) for fv in fitted_vals], width,\n",
    "       yerr=[abs(e) for e in fitted_errs], capsize=5,\n",
    "       label='Fitted', alpha=0.8, color='orange')\n",
    "ax.set_xticks(x + width/2)\n",
    "ax.set_xticklabels(param_names_plot)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('|Parameter value|')\n",
    "ax.set_title('True vs Fitted Parameters (absolute value)')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFitted parameters:\")\n",
    "for name, tv, fv, fe in zip(param_names_plot, true_vals, fitted_vals, fitted_errs):\n",
    "    rel = abs(fv - tv) / abs(tv) * 100 if tv != 0 else float('nan')\n",
    "    print(f\"  {name}: true={tv:.4g}, fitted={fv:.4g} ± {fe:.4g}  ({rel:.1f}% error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "Key takeaways from static mode analysis:\n",
    "\n",
    "- **D₀** characterizes particle dynamics; compare to Stokes-Einstein for size\n",
    "- **alpha** reveals diffusion regime (< 0: sub, 0: normal, > 0: super)\n",
    "- **Anti-degeneracy** (`per_angle_mode: \"auto\"`) protects physical parameters\n",
    "- **Multi-start** provides confidence that the global minimum was found\n",
    "- **chi²_nu ~ 1** indicates a good fit with well-estimated uncertainties\n",
    "\n",
    "For rigorous uncertainty quantification, proceed to `04_bayesian_inference.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.unlink(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
