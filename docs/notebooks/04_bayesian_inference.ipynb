{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference with CMC\n",
    "\n",
    "This notebook demonstrates the complete Bayesian analysis workflow:\n",
    "\n",
    "1. NLSQ warm-start optimization\n",
    "2. CMC (Consensus Monte Carlo) configuration\n",
    "3. Running NUTS sampling via NumPyro\n",
    "4. Posterior analysis with ArviZ\n",
    "5. Comparing NLSQ and CMC uncertainty estimates\n",
    "\n",
    "**When to use CMC:** for publication-quality uncertainty estimates, multi-modal\n",
    "posteriors, or uncertainty propagation into derived quantities.\n",
    "\n",
    "**Always run NLSQ first** as a warm-start — this reduces divergence rates from\n",
    "~28% (cold start) to < 5%.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from homodyne.config import ConfigManager\n",
    "from homodyne.optimization.cmc import fit_mcmc_jax\n",
    "from homodyne.optimization.cmc.sampler import SamplingPlan\n",
    "from homodyne.optimization.nlsq import fit_nlsq_jax\n",
    "from homodyne.utils.logging import get_logger, log_phase\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "print(f\"ArviZ version: {az.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=777)\n",
    "\n",
    "TRUE = {\n",
    "    \"D0\": 1500.0,  # Å²/s\n",
    "    \"alpha\": -0.4,\n",
    "    \"D_offset\": 0.03,\n",
    "    \"contrast\": 0.10,\n",
    "    \"offset\": 1.0,\n",
    "}\n",
    "\n",
    "q = 0.054  # Å⁻¹\n",
    "n_t = 35\n",
    "n_phi = 6\n",
    "dt = 0.1\n",
    "t = dt * np.arange(n_t)\n",
    "phi_deg = np.linspace(0, 300, n_phi)\n",
    "\n",
    "c2 = np.zeros((n_phi, n_t, n_t))\n",
    "for i_phi in range(n_phi):\n",
    "    for i_t1 in range(n_t):\n",
    "        for i_t2 in range(i_t1, n_t):\n",
    "            t1_v, t2_v = t[i_t1], t[i_t2]\n",
    "            J = TRUE[\"D0\"] * (\n",
    "                t2_v ** (TRUE[\"alpha\"] + 1) - t1_v ** (TRUE[\"alpha\"] + 1)\n",
    "            ) / (TRUE[\"alpha\"] + 1) + TRUE[\"D_offset\"] * (t2_v - t1_v)\n",
    "            val = TRUE[\"offset\"] + TRUE[\"contrast\"] * np.exp(-2 * q**2 * J)\n",
    "            noise = 0.003 * rng.standard_normal()\n",
    "            c2[i_phi, i_t1, i_t2] = val + noise\n",
    "            c2[i_phi, i_t2, i_t1] = val + noise\n",
    "\n",
    "data = {\n",
    "    \"c2_exp\": c2,\n",
    "    \"t1\": t,\n",
    "    \"t2\": t,\n",
    "    \"phi_angles_list\": phi_deg,\n",
    "    \"wavevector_q_list\": np.array([q]),\n",
    "    \"sigma\": 0.003 * np.ones_like(c2),\n",
    "    \"L\": 5.0e6,\n",
    "    \"dt\": dt,\n",
    "}\n",
    "\n",
    "print(f\"Dataset: {c2.size:,} correlation values  ({n_phi} angles × {n_t}² times)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Step 1: NLSQ Warm-Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_yaml = \"\"\"\n",
    "data:\n",
    "  file_path: \"dummy.h5\"\n",
    "  q_value: 0.054\n",
    "  dt: 0.1\n",
    "\n",
    "analysis:\n",
    "  mode: \"static\"\n",
    "\n",
    "optimization:\n",
    "  method: \"nlsq\"\n",
    "  nlsq:\n",
    "    anti_degeneracy:\n",
    "      per_angle_mode: \"auto\"\n",
    "\n",
    "parameter_space:\n",
    "  D0:\n",
    "    initial: 1000.0\n",
    "    bounds: [0.1, 1.0e5]\n",
    "  alpha:\n",
    "    initial: -0.5\n",
    "    bounds: [-2.0, 1.0]\n",
    "  D_offset:\n",
    "    initial: 0.1\n",
    "    bounds: [0.0, 100.0]\n",
    "\"\"\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".yaml\", delete=False) as f:\n",
    "    f.write(config_yaml)\n",
    "    config_path = f.name\n",
    "\n",
    "config = ConfigManager.from_yaml(config_path)\n",
    "\n",
    "print(\"Running NLSQ warm-start...\")\n",
    "with log_phase(\"NLSQ Warm-Start\"):\n",
    "    nlsq_result = fit_nlsq_jax(data, config)\n",
    "\n",
    "print(\"\\nNLSQ Result:\")\n",
    "print(f\"  Convergence:  {nlsq_result.convergence_status}\")\n",
    "print(f\"  chi^2_nu:     {nlsq_result.reduced_chi_squared:.4f}\")\n",
    "print(\n",
    "    f\"  D0:           {nlsq_result.parameters[0]:.1f} ± {nlsq_result.uncertainties[0]:.1f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  alpha:        {nlsq_result.parameters[1]:.3f} ± {nlsq_result.uncertainties[1]:.3f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  D_offset:     {nlsq_result.parameters[2]:.4f} ± {nlsq_result.uncertainties[2]:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Pooled Data for CMC\n",
    "\n",
    "CMC requires flat (pooled) arrays, not the (n_phi, n_t1, n_t2) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pool data from all angles into flat arrays\n",
    "c2_arr = data[\"c2_exp\"]  # (n_phi, n_t1, n_t2)\n",
    "phi_arr = data[\"phi_angles_list\"]  # (n_phi,)\n",
    "t1_arr = data[\"t1\"]\n",
    "t2_arr = data[\"t2\"]\n",
    "\n",
    "# Create meshgrid for all (phi, t1, t2) combinations\n",
    "PHI, T1, T2 = np.meshgrid(phi_arr, t1_arr, t2_arr, indexing=\"ij\")\n",
    "c2_flat = c2_arr.ravel()\n",
    "phi_flat = PHI.ravel()\n",
    "t1_flat = T1.ravel()\n",
    "t2_flat = T2.ravel()\n",
    "\n",
    "# Keep only upper triangle (t2 >= t1) to avoid double-counting\n",
    "mask = t2_flat >= t1_flat\n",
    "c2_pooled = c2_flat[mask]\n",
    "phi_pooled = phi_flat[mask]\n",
    "t1_pooled = t1_flat[mask]\n",
    "t2_pooled = t2_flat[mask]\n",
    "\n",
    "q_val = float(data[\"wavevector_q_list\"][0])\n",
    "L_val = float(data.get(\"L\", 5.0e6))\n",
    "dt_val = float(data.get(\"dt\", 0.1))\n",
    "\n",
    "print(\n",
    "    f\"Pooled data: {len(c2_pooled):,} points (from {c2_arr.size:,} total, upper triangle only)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CMC Configuration\n",
    "\n",
    "Configure CMC for this dataset size and analysis mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMC configuration\n",
    "cmc_config = {\n",
    "    \"max_points_per_shard\": \"auto\",  # ALWAYS use auto\n",
    "    \"sharding_strategy\": \"stratified\",\n",
    "    \"num_warmup\": 200,  # Small for demo; use 500+ for production\n",
    "    \"num_samples\": 500,  # Small for demo; use 1500+ for production\n",
    "    \"num_chains\": 2,  # 2 for demo; use 4 for production\n",
    "    \"max_tree_depth\": 8,\n",
    "    \"adaptive_sampling\": True,\n",
    "    \"per_angle_mode\": \"auto\",  # Match NLSQ setting\n",
    "    \"validation\": {\n",
    "        \"max_divergence_rate\": 0.15,  # Slightly relaxed for demo\n",
    "    },\n",
    "}\n",
    "\n",
    "# Check what SamplingPlan would use for this shard size\n",
    "from homodyne.optimization.cmc.config import CMCConfig\n",
    "\n",
    "cfg_obj = CMCConfig.from_dict(cmc_config)\n",
    "\n",
    "shard_size_estimate = min(5000, len(c2_pooled))\n",
    "plan = SamplingPlan.from_config(cfg_obj, shard_size=shard_size_estimate, n_params=5)\n",
    "print(f\"SamplingPlan for shard_size={shard_size_estimate}:\")\n",
    "print(f\"  Warmup:   {plan.n_warmup}\")\n",
    "print(f\"  Samples:  {plan.n_samples}\")\n",
    "print(f\"  Adapted:  {plan.was_adapted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run CMC\n",
    "\n",
    "This is the main CMC call. The NLSQ result is passed as `nlsq_result` for\n",
    "warm-start priors.\n",
    "\n",
    "**Note:** On a real dataset this takes minutes to hours. For this demo notebook\n",
    "with small n_samples, it should complete in a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build parameter space from config\n",
    "parameter_space = config.get_parameter_space()\n",
    "initial_values = config.get_initial_parameters()\n",
    "\n",
    "print(\"Running CMC analysis...\")\n",
    "print(f\"  Dataset: {len(c2_pooled):,} pooled points\")\n",
    "print(\"  Mode:    static\")\n",
    "print(f\"  Chains:  {cmc_config['num_chains']}\")\n",
    "print(f\"  Warmup:  {cmc_config['num_warmup']}, Samples: {cmc_config['num_samples']}\")\n",
    "print()\n",
    "\n",
    "with log_phase(\"CMC\"):\n",
    "    cmc_result = fit_mcmc_jax(\n",
    "        data=c2_pooled,\n",
    "        t1=t1_pooled,\n",
    "        t2=t2_pooled,\n",
    "        phi=phi_pooled,\n",
    "        q=q_val,\n",
    "        L=L_val,\n",
    "        analysis_mode=\"static\",\n",
    "        cmc_config=cmc_config,\n",
    "        initial_values=initial_values,\n",
    "        parameter_space=parameter_space,\n",
    "        dt=dt_val,\n",
    "        nlsq_result=nlsq_result,  # NLSQ warm-start\n",
    "        progress_bar=True,\n",
    "    )\n",
    "\n",
    "print(\"\\nCMC Result:\")\n",
    "print(f\"  Convergence:  {cmc_result.convergence_status}\")\n",
    "print(f\"  Divergences:  {cmc_result.divergences}\")\n",
    "print(f\"  Time:         {cmc_result.execution_time:.1f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convergence Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Convergence Diagnostics\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nR-hat (should be < 1.05 for all parameters):\")\n",
    "all_ok = True\n",
    "for param, rhat in cmc_result.r_hat.items():\n",
    "    status = \"OK\" if rhat < 1.05 else \"WARNING\"\n",
    "    if rhat >= 1.05:\n",
    "        all_ok = False\n",
    "    print(f\"  {param:<25} {rhat:.4f}  [{status}]\")\n",
    "print(\n",
    "    f\"  → {'All R-hat OK' if all_ok else 'Some R-hat elevated (increase num_warmup)'}\"\n",
    ")\n",
    "\n",
    "print(\"\\nBulk ESS (should be > 400):\")\n",
    "for param, ess in cmc_result.ess_bulk.items():\n",
    "    status = \"OK\" if ess >= 400 else \"LOW\"\n",
    "    print(f\"  {param:<25} {ess:.0f}  [{status}]\")\n",
    "\n",
    "n_total_transitions = cmc_result.n_chains * cmc_result.n_samples\n",
    "div_rate = cmc_result.divergences / max(n_total_transitions, 1) * 100\n",
    "print(\n",
    "    f\"\\nDivergences: {cmc_result.divergences}/{n_total_transitions} = {div_rate:.1f}%\"\n",
    ")\n",
    "if div_rate < 5:\n",
    "    print(\"  → Excellent: < 5% divergences\")\n",
    "elif div_rate < 15:\n",
    "    print(\"  → Acceptable: < 15% divergences\")\n",
    "else:\n",
    "    print(\"  → High divergence rate: consider NLSQ warm-start, increase max_tree_depth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Posterior Analysis with ArviZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata = cmc_result.inference_data\n",
    "\n",
    "# Summary table\n",
    "print(\"Posterior Summary\")\n",
    "print(\"=\" * 60)\n",
    "summary = az.summary(idata, var_names=cmc_result.param_names)\n",
    "print(summary[[\"mean\", \"sd\", \"hdi_3%\", \"hdi_97%\", \"r_hat\", \"ess_bulk\"]].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots — check chain mixing\n",
    "# (Only for parameters that exist in the inference data)\n",
    "plot_vars = [v for v in [\"D0\", \"alpha\", \"D_offset\"] if v in idata.posterior]\n",
    "if plot_vars:\n",
    "    az.plot_trace(idata, var_names=plot_vars, compact=True)\n",
    "    plt.suptitle(\"MCMC Trace Plots (visual convergence check)\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\n",
    "        \"No standard parameter names found in inference data (using reparameterized names)\"\n",
    "    )\n",
    "    print(f\"Available: {list(idata.posterior.data_vars)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(13, 4))\n",
    "\n",
    "param_display = [\n",
    "    (\"D0\", \"D₀ (Å²/s)\", TRUE[\"D0\"]),\n",
    "    (\"alpha\", \"α\", TRUE[\"alpha\"]),\n",
    "    (\"D_offset\", \"D_offset (Å²/s)\", TRUE[\"D_offset\"]),\n",
    "]\n",
    "\n",
    "for ax, (param_name, label, true_val) in zip(axes, param_display):\n",
    "    # CMC posterior samples\n",
    "    if param_name in cmc_result.samples:\n",
    "        samples = cmc_result.samples[param_name].ravel()\n",
    "        ax.hist(\n",
    "            samples,\n",
    "            bins=40,\n",
    "            density=True,\n",
    "            alpha=0.6,\n",
    "            color=\"orange\",\n",
    "            label=\"CMC posterior\",\n",
    "        )\n",
    "        ax.axvline(\n",
    "            np.mean(samples),\n",
    "            color=\"orange\",\n",
    "            linestyle=\"-\",\n",
    "            linewidth=2,\n",
    "            label=f\"CMC mean: {np.mean(samples):.3g}\",\n",
    "        )\n",
    "\n",
    "    # NLSQ Gaussian approximation\n",
    "    i = [\"D0\", \"alpha\", \"D_offset\"].index(param_name)\n",
    "    nlsq_mean = nlsq_result.parameters[i]\n",
    "    nlsq_std = nlsq_result.uncertainties[i]\n",
    "\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    x_range = np.linspace(nlsq_mean - 5 * nlsq_std, nlsq_mean + 5 * nlsq_std, 200)\n",
    "    ax.plot(\n",
    "        x_range,\n",
    "        norm.pdf(x_range, nlsq_mean, nlsq_std),\n",
    "        \"b-\",\n",
    "        linewidth=2,\n",
    "        label=f\"NLSQ: {nlsq_mean:.3g} ± {nlsq_std:.3g}\",\n",
    "    )\n",
    "\n",
    "    # True value\n",
    "    ax.axvline(\n",
    "        true_val,\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=2,\n",
    "        label=f\"True: {true_val:.3g}\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(label)\n",
    "    ax.set_ylabel(\"Probability density\")\n",
    "    ax.set_title(f\"Posterior: {param_name}\")\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.suptitle(\"NLSQ Gaussian Approximation vs CMC Posterior\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. NLSQ vs CMC Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Parameter Comparison: NLSQ vs CMC\")\n",
    "print(\"=\" * 65)\n",
    "print(\n",
    "    f\"{'Parameter':<15} {'True':>10} {'NLSQ mean':>12} {'NLSQ std':>10} {'CMC mean':>12} {'CMC std':>10}\"\n",
    ")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "param_map = [(\"D0\", 0), (\"alpha\", 1), (\"D_offset\", 2)]\n",
    "true_map = {\"D0\": TRUE[\"D0\"], \"alpha\": TRUE[\"alpha\"], \"D_offset\": TRUE[\"D_offset\"]}\n",
    "\n",
    "for param_name, idx in param_map:\n",
    "    true_val = true_map[param_name]\n",
    "    nlsq_m = nlsq_result.parameters[idx]\n",
    "    nlsq_s = nlsq_result.uncertainties[idx]\n",
    "\n",
    "    if param_name in cmc_result.samples:\n",
    "        samples = cmc_result.samples[param_name].ravel()\n",
    "        cmc_m = np.mean(samples)\n",
    "        cmc_s = np.std(samples)\n",
    "    else:\n",
    "        cmc_m = cmc_result.parameters[idx]\n",
    "        cmc_s = cmc_result.uncertainties[idx]\n",
    "\n",
    "    print(\n",
    "        f\"{param_name:<15} {true_val:>10.4g} {nlsq_m:>12.4g} {nlsq_s:>10.4g} {cmc_m:>12.4g} {cmc_s:>10.4g}\"\n",
    "    )\n",
    "\n",
    "print()\n",
    "print(\"Interpretation:\")\n",
    "print(\"  - CMC std / NLSQ std ratio > 2 → NLSQ underestimates uncertainty\")\n",
    "print(\"  - Consistent means → posterior is approximately Gaussian (NLSQ sufficient)\")\n",
    "print(\"  - Inconsistent means → multi-modal or non-Gaussian posterior\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"bayesian_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save ArviZ NetCDF (recommended format for posterior)\n",
    "nc_path = output_dir / \"cmc_posterior.nc\"\n",
    "cmc_result.inference_data.to_netcdf(str(nc_path))\n",
    "print(f\"Saved posterior to: {nc_path}\")\n",
    "\n",
    "# Reload and verify\n",
    "idata_loaded = az.from_netcdf(str(nc_path))\n",
    "print(f\"Reloaded posterior: {list(idata_loaded.posterior.data_vars)[:5]}\")\n",
    "print(\"Posterior saved and reloaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary\n",
    "\n",
    "Key takeaways from Bayesian inference:\n",
    "\n",
    "- **Always use NLSQ warm-start** (`nlsq_result=nlsq_result`) to reduce divergences\n",
    "- **R-hat < 1.05** for all parameters before trusting posterior summaries\n",
    "- **ESS > 400** for reliable uncertainty estimates\n",
    "- **CMC provides**: full posterior, multi-modal detection, proper uncertainty quantification\n",
    "- **For production**: use `num_warmup=500, num_samples=1500, num_chains=4`\n",
    "- **ArviZ** is the standard tool for posterior analysis and visualization\n",
    "\n",
    "### Recommended production settings:\n",
    "\n",
    "```yaml\n",
    "optimization:\n",
    "  cmc:\n",
    "    sharding:\n",
    "      max_points_per_shard: \"auto\"\n",
    "    per_shard_mcmc:\n",
    "      num_warmup: 500\n",
    "      num_samples: 1500\n",
    "      num_chains: 4\n",
    "      max_tree_depth: 10\n",
    "      chain_method: \"parallel\"\n",
    "      adaptive_sampling: true\n",
    "    per_angle_mode: \"auto\"\n",
    "    validation:\n",
    "      max_divergence_rate: 0.10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.unlink(config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
