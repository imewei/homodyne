# Homodyne v2 Quality Control Configuration Template
# ==================================================
# Enhanced template demonstrating comprehensive data quality control integration.
# This template showcases the new quality control features added in Phase 3.

_template_info:
  _comment: COMPREHENSIVE QUALITY CONTROL TEMPLATE - Demonstrates Phase 3 enhancements
  _creation_date: '2025-09-12'
  _phase: Phase 3 - Data Quality Control Integration
  _features:
    - Progressive quality validation throughout data loading pipeline
    - Auto-repair functionality for common data issues
    - Real-time quality assessment and reporting
    - Integration with filtering and preprocessing systems
    - Exportable quality reports with actionable insights
  _usage: Use this template when you need comprehensive data quality control with auto-repair and detailed reporting
  _integration: Works with existing filtering (Phase 1) and preprocessing (Phase 2) systems

metadata:
  config_version: 0.8.0
  description: 'Quality Control Template: Comprehensive data quality management for XPCS analysis'
  based_on: Enhanced Homodyne v2 with Phase 3 quality control integration
  analysis_mode: 'static_anisotropic'
  quality_features:
    progressive_validation: Real-time quality assessment at each processing stage
    auto_repair: Intelligent data repair with conservative/aggressive strategies
    quality_reporting: Detailed exportable quality assessment reports
    integration: Seamless integration with filtering and preprocessing pipelines
  parameters_optimized: '[D0, alpha, D_offset] with comprehensive quality control'

# Comprehensive logging configuration for quality control
logging:
  enabled: true
  level: INFO
  console:
    enabled: true
    level: INFO
    format: detailed
    colors: true
  file:
    enabled: true
    level: DEBUG
    path: ~/.homodyne/logs/
    filename: homodyne_quality.log
    max_size_mb: 15
    backup_count: 10
  performance:
    enabled: true
    level: INFO
    filename: quality_performance.log
    threshold_seconds: 0.05
  modules:
    homodyne.data.quality_controller: DEBUG
    homodyne.data.validation: INFO
    homodyne.data.xpcs_loader: INFO
    homodyne.data.filtering_utils: INFO
    homodyne.data.preprocessing: INFO

# Experimental data configuration
experimental_data:
  data_folder_path: ./data/quality_demo/
  data_file_name: sample_xpcs_data.hdf
  phi_angles_path: ./data/phi_angles/
  phi_angles_file: phi_list.txt
  exchange_key: exchange
  cache_file_path: ./data/quality_demo/
  cache_filename_template: cached_c2_frames_{start_frame}_{end_frame}_quality.npz
  cache_compression: true
  data_type: float64
  file_format: NPZ
  preprocessing:
    apply_diagonal_correction: true
    vectorized_correction: true
    cache_processed_data: true
    normalize_data: true
    normalization_method: baseline

# COMPREHENSIVE QUALITY CONTROL CONFIGURATION
quality_control:
  _comment: 'PHASE 3 FEATURE: Complete data quality control system with progressive validation, auto-repair, and reporting'
  _architecture: 'Raw Data → Basic Validation → Filtering → Filter Validation → Preprocessing → Transform Validation → Final Validation → Quality Report'
  enabled: true
  _enabled_note: 'Enable comprehensive quality control throughout data loading pipeline'
  
  # VALIDATION LEVELS AND SETTINGS
  validation_level: standard
  _validation_level_options:
    none: 'No validation - quality control disabled'
    basic: 'Essential data integrity and format checks only'
    standard: 'Comprehensive validation including physics and statistical checks'
    comprehensive: 'Maximum validation with detailed analysis and physics validation'
  _validation_level_note: 'Standard recommended for production use, comprehensive for critical analysis'
  
  # AUTO-REPAIR CONFIGURATION
  auto_repair: conservative
  _auto_repair_options:
    disabled: 'No automatic data repair - issues reported only'
    conservative: 'Safe repairs only: NaN/Inf fixing, format standardization'
    aggressive: 'Advanced repairs: negative correlation fixing, scaling corrections'
  _auto_repair_note: 'Conservative recommended for production, aggressive for problematic datasets'
  
  # QUALITY THRESHOLDS (0-100 scale)
  pass_threshold: 60.0
  _pass_threshold_note: 'Minimum quality score for data to pass validation (0-100)'
  warn_threshold: 75.0
  _warn_threshold_note: 'Quality score above which data is considered good quality'
  excellent_threshold: 85.0
  _excellent_threshold_note: 'Quality score for excellent data quality'
  
  # STAGE-SPECIFIC VALIDATION SETTINGS
  validation_stages:
    _comment: 'Enable/disable validation at specific processing stages'
    enable_raw_validation: true
    _raw_validation_note: 'Validate data immediately after loading from HDF5 files'
    enable_filtering_validation: true
    _filtering_validation_note: 'Validate data after filtering to ensure adequate data retention'
    enable_preprocessing_validation: true  
    _preprocessing_validation_note: 'Validate data after preprocessing to check transformation quality'
    enable_final_validation: true
    _final_validation_note: 'Final comprehensive validation before analysis'
  
  # AUTO-REPAIR DETAILED SETTINGS
  repair_settings:
    _comment: 'Fine-tune automatic data repair capabilities'
    repair_nan_values: true
    _repair_nan_note: 'Replace NaN values with interpolated or median values'
    repair_infinite_values: true
    _repair_infinite_note: 'Replace infinite values with min/max of finite values'
    repair_negative_correlations: false
    _repair_negative_correlations_note: 'Fix negative correlation values (aggressive mode only)'
    repair_scaling_issues: true
    _repair_scaling_note: 'Correct obvious scaling problems (10x, 100x factors)'
    repair_format_inconsistencies: true
    _repair_format_note: 'Standardize data formats and array types'
  
  # PERFORMANCE OPTIMIZATION
  performance:
    _comment: 'Quality control performance settings'
    cache_validation_results: true
    _cache_note: 'Cache validation results to avoid redundant checks'
    incremental_validation: true
    _incremental_note: 'Use incremental validation when data partially changes'
    parallel_validation: false
    _parallel_note: 'Enable parallel validation for large datasets (experimental)'
  
  # REPORTING AND OUTPUT
  reporting:
    _comment: 'Quality report generation and output settings'
    generate_reports: true
    _generate_reports_note: 'Generate quality assessment reports'
    export_detailed_reports: true
    _export_detailed_note: 'Save detailed JSON reports to disk'
    save_quality_history: true
    _save_history_note: 'Keep history of quality assessments for analysis'
    report_output_directory: ./data/quality_demo/quality_reports/
    _report_directory_note: 'Directory for saving quality reports'

# Enhanced data filtering with quality control integration
data_filtering:
  enabled: true
  _integration_note: 'Data filtering now integrates seamlessly with quality control'
  q_range:
    enabled: true
    min: 0.005
    max: 0.08
  phi_range:
    enabled: true
    min: -15.0
    max: 195.0
  quality_threshold:
    enabled: true
    threshold: 0.6
    _threshold_note: 'Minimum quality score for filtering - integrates with quality_control system'
  combine_criteria: AND
  fallback_on_empty: true
  validation_level: basic
  _quality_integration: 'Filtering results are validated by quality control system'

# Enhanced preprocessing with quality control integration  
preprocessing:
  enabled: true
  _integration_note: 'Preprocessing now includes quality control validation at each stage'
  cache_intermediates: false
  progress_reporting: true
  abort_on_error: false
  fallback_on_failure: true
  save_provenance: true
  _provenance_note: 'Provenance includes quality control metrics'
  
  stages:
    correct_diagonal:
      enabled: true
      method: statistical
      window_size: 3
      estimator: median
    normalize_data:
      enabled: true
      method: baseline
    reduce_noise:
      enabled: false
      method: none
    standardize_format:
      enabled: true
    validate_output:
      enabled: true
      _validation_note: 'Final stage validation is enhanced by quality control system'

# Temporal and scattering parameters
analyzer_parameters:
  temporal:
    dt: 0.1
    start_frame: 100
    end_frame: 1000
  scattering:
    wavevector_q: 0.01
    q_unit: Å⁻¹
  geometry:
    stator_rotor_gap: 2000000
    gap_unit: Å
  computational:
    num_threads: auto
    max_threads_limit: 8
    memory_limit_gb: 8

# Initial parameters for static anisotropic analysis
initial_parameters:
  values: [100.0, -1.5, 10.0]
  parameter_names: [D0, alpha, D_offset]
  units: ['Å²/s', 'dimensionless', 'Å²/s']

# Optimization configuration with quality-aware settings
optimization_config:
  angle_filtering:
    enabled: true
    target_ranges:
      - min_angle: -10.0
        max_angle: 10.0
      - min_angle: 170.0
        max_angle: 190.0
    fallback_to_all_angles: true
  
  classical_optimization:
    methods: [Nelder-Mead]
    method_options:
      Nelder-Mead:
        maxiter: 2000
        xatol: 1.0e-06
        fatol: 1.0e-06
        adaptive: true
  
  selection_strategy: best_chi_squared

# Parameter space definition
parameter_space:
  bounds:
    - name: D0
      min: 1.0
      max: 1000000.0
      type: TruncatedNormal
      prior_mu: 10000.0
      prior_sigma: 1000.0
      unit: Å²/s

    - name: alpha
      min: -2.0
      max: 2.0
      type: Normal
      prior_mu: -1.5
      prior_sigma: 0.1
      unit: dimensionless

    - name: D_offset
      min: -100
      max: 100
      type: Normal
      prior_mu: 0.0
      prior_sigma: 10.0
      unit: Å²/s

# Analysis settings for static anisotropic mode
analysis_settings:
  static_mode: true
  static_submode: anisotropic
  model_description: 'g₂(t₁,t₂) ~ [exp(-q² ∫ D(t)dt)]² with angular filtering and quality control'

# Advanced settings with quality control enhancements
advanced_settings:
  data_loading:
    use_diagonal_correction: true
    vectorized_diagonal_fix: true
  chi_squared_calculation:
    method: standard
    minimum_sigma: 1.0e-10
    variance_method: hybrid_limited_irls
  uncertainty_calculation:
    enable_uncertainty: true
    report_uncertainty: true
    minimum_angles_for_uncertainty: 2
  validity_check:
    check_positive_D0: true
    check_parameter_bounds: true

# Performance settings optimized for quality control
performance_settings:
  caching:
    enable_memory_cache: true
    enable_disk_cache: true
    cache_size_limit_mb: 750
    auto_cleanup: true
  parallel_processing:
    enable_multiprocessing: false
    chunk_size: auto
    backend: threading
  memory_management:
    low_memory_mode: false
    garbage_collection_frequency: 10
    memory_monitoring: true
  numba_optimization:
    enable_numba: true
    warmup_numba: true
    parallel_numba: false
    cache_numba: true

# Validation rules with quality control integration
validation_rules:
  data_quality:
    check_data_range: true
    correlation_minimum: 0.0
    correlation_maximum: 10.0
    check_nan_values: true
    nan_handling: repair
    _nan_handling_note: 'Changed from "raise" to "repair" to work with quality control auto-repair'
  parameter_validation:
    check_bounds: true
    physics_constraints: true
    correlation_checks: true
  fit_quality:
    overall_chi_squared:
      excellent_threshold: 5.0
      acceptable_threshold: 10.0
      warning_threshold: 20.0
    per_angle_chi_squared:
      excellent_threshold: 5.0
      acceptable_threshold: 10.0
      warning_threshold: 20.0

# Output settings with quality reporting
output_settings:
  results_directory: ./homodyne_results_quality/
  file_formats:
    results_format: json
    save_intermediate: true
    compression: true
    precision: float64
  reporting:
    generate_plots: true
    plot_formats: [png]
    detailed_summary: true
    convergence_diagnostics: true
    _quality_integration: 'Results include comprehensive quality metrics and recommendations'
  plotting:
    general:
      create_plots: true
      plot_format: png
      dpi: 300
      figure_size: [12, 8]
      style: publication
      save_plots: true
      show_plots: false
    c2_heatmaps:
      enabled: true
      layout: single_row
      include_experimental: true
      include_theoretical: true
      include_residuals: true
      colormap: viridis
      title_prefix: 'C2 Correlation Function (Quality Controlled)'

# V2 features configuration
v2_features:
  output_format: auto
  validation_level: standard
  physics_validation: true
  performance_optimization: true
  parallel_processing: false
  gpu_acceleration: false
  cache_strategy: intelligent
  _quality_control_note: 'Quality control is automatically enabled when quality_control section is present'

# Quality control examples and use cases
_quality_control_examples:
  _comment: 'Example configurations for different use cases'
  
  high_quality_analysis:
    _description: 'Maximum quality assurance for critical analysis'
    quality_control:
      enabled: true
      validation_level: comprehensive
      auto_repair: conservative
      pass_threshold: 80.0
      warn_threshold: 90.0
      excellent_threshold: 95.0
      reporting:
        generate_reports: true
        export_detailed_reports: true
        save_quality_history: true
  
  problematic_data_processing:
    _description: 'Aggressive quality control for problematic datasets'
    quality_control:
      enabled: true
      validation_level: standard
      auto_repair: aggressive
      pass_threshold: 50.0
      warn_threshold: 65.0
      excellent_threshold: 80.0
      repair_settings:
        repair_negative_correlations: true
        repair_scaling_issues: true
  
  fast_processing:
    _description: 'Minimal quality control for fast processing'
    quality_control:
      enabled: true
      validation_level: basic
      auto_repair: conservative
      pass_threshold: 40.0
      performance:
        cache_validation_results: true
        incremental_validation: true
      reporting:
        generate_reports: false
        export_detailed_reports: false

_customization_guide:
  _step_1: 'Enable quality control by setting quality_control.enabled: true'
  _step_2: 'Choose validation_level: basic (fast), standard (recommended), or comprehensive (thorough)'
  _step_3: 'Configure auto_repair: disabled (safe), conservative (recommended), or aggressive (problematic data)'
  _step_4: 'Set quality thresholds based on your data quality requirements'
  _step_5: 'Enable/disable specific validation stages based on your workflow'
  _step_6: 'Configure reporting settings for quality assessment output'
  _step_7: 'Tune auto-repair settings for your specific data issues'
  _step_8: 'Integrate with existing filtering and preprocessing configurations'

_phase_3_features:
  _progressive_validation: 'Real-time quality assessment at Raw → Filtered → Preprocessed → Final stages'
  _auto_repair: 'Intelligent data repair with NaN/Inf fixing, scaling correction, format standardization'
  _quality_metrics: 'Comprehensive metrics: overall_score, finite_fraction, correlation_validity, signal_to_noise, symmetry_score'
  _integration: 'Seamless integration with Phase 1 filtering and Phase 2 preprocessing systems'
  _reporting: 'Detailed exportable reports with actionable recommendations'
  _caching: 'Intelligent caching with incremental validation for performance'