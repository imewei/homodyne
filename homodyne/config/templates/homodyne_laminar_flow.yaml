# ==============================================================================
# HOMODYNE LAMINAR FLOW CONFIGURATION TEMPLATE
# ==============================================================================
# Comprehensive production-ready template for laminar flow analysis.
# 7-parameter model: D(t) = D₀·t^α + D_offset
#                   γ̇(t) = γ̇₀·t^β + γ̇_offset
#
# Use for: Nonequilibrium systems, shear flow, time-dependent shear rates
# Parameter count: 7 physical + 2 × N_angles scaling = 7 + 2N total
#
# VERSION: 2.4.1
# UPDATED: 2025-12-04
# ==============================================================================

# ==============================================================================
# METADATA (Required)
# ==============================================================================
# Template metadata describing analysis configuration
metadata:
  config_version: "2.4.1" # Configuration file format version
  description: "Laminar flow analysis - 7-parameter model"
  analysis_mode: "laminar_flow" # Laminar flow mode
  parameter_count: 7 # D₀, α, D_offset, γ̇₀, β, γ̇_offset, φ₀

  # Physics model description
  physics_model: "D(t) = D₀·t^α + D_offset"
  shear_model: "γ̇(t) = γ̇₀·t^β + γ̇_offset" # Time-dependent shear rate

  # Integration and correction methods
  integration_method: "discrete_numerical" # Discrete numerical integration for stability
  diagonal_correction: "mandatory" # Diagonal correction for consistency

  # Template classification
  recommended_use: "Nonequilibrium XPCS systems under shear flow with time-dependent dynamics"
  template_type: "production_ready" # Production-ready template
  complexity: "comprehensive" # All features documented

  # Optional: Generation metadata (filled by homodyne-config)
  generated_at: null # ISO timestamp when config generated
  generated_by: null # Tool used to generate config

# ==============================================================================
# ANALYSIS MODE (Required)
# ==============================================================================
# Primary analysis mode selection
analysis_mode: "laminar_flow" # Laminar flow (nonequilibrium)

# ==============================================================================
# ANALYZER PARAMETERS (Required)
# ==============================================================================
# Core physical and instrumental parameters for analysis
analyzer_parameters:
  # Time resolution
  dt: 0.1 # Time step between correlation measurements [seconds]

  # Frame range for analysis
  start_frame: 1000 # Starting frame number (1-indexed)
  end_frame: 2000 # Ending frame number (inclusive)

  # Scattering parameters
  scattering:
    wavevector_q: 0.0054 # Wave vector magnitude [Å⁻¹] - sample dependent

  # Geometry parameters (instrumental setup)
  geometry:
    stator_rotor_gap: 2000000 # Gap between stator and rotor [Å] (200 microns = 2000000 Å)

# ==============================================================================
# ANALYSIS SETTINGS (Required)
# ==============================================================================
# Analysis mode-specific settings and model description
analysis_settings:
  static_mode: false # Laminar flow (nonequilibrium, shear present)

  # Model description for documentation
  model_description:
    type: "nonequilibrium_laminar_flow" # Laminar flow model
    parameters: 7 # D₀, α, D_offset, γ̇₀, β, γ̇_offset, φ₀
    physics: "Time-dependent diffusion and shear with flow direction and angle effects"

# ==============================================================================
# EXPERIMENTAL DATA (Required)
# ==============================================================================
# Paths to experimental data files and caching configuration
experimental_data:
  # Primary data file (HDF5 format)
  file_path: "./data/sample/experiment.hdf" # Preferred: Direct path to HDF5 file

  # Legacy format (data_folder_path + data_file_name)
  data_folder_path: "./data/sample/" # Folder containing data file
  data_file_name: "experiment.hdf" # HDF5 data file name

  # Phi angles configuration
  phi_angles_path: "./data/sample/" # Folder containing phi angles list
  phi_angles_file: "phi_angles_list.txt" # Text file with phi angles (one per line)

  # Caching for performance (saves processed C2 data)
  cache_file_path: "./data/sample/" # Cache directory
  cache_filename_template: "cached_c2_flow_q{wavevector_q:.4f}_frames_{start_frame}_{end_frame}.npz"
  cache_compression: true # Enable compression for cache files

  # Data format specifications
  data_type: "float64" # Data type for arrays
  file_format: "HDF5" # File format (currently only HDF5 supported)
  exchange_key: "exchange" # HDF5 group key for exchange data

# ==============================================================================
# PHI ANGLE FILTERING
# ==============================================================================
# Advanced phi angle filtering for optimal scattering analysis
# For laminar flow: typically use angles parallel (0°) and perpendicular (90°) to flow
# to extract directional flow information
phi_filtering:
  enabled: true # Enable angle filtering to reduce parameter count

  # Target angle ranges (all angles normalized to [-180°, 180°])
  # Angles are checked with wrap-aware logic (e.g., [170°, -170°] works correctly)
  target_ranges:
    # Range 1: Near 0° (parallel to flow direction)
    - min_angle: -10.0 # Minimum angle [degrees]
      max_angle: 10.0 # Maximum angle [degrees]
      description: "Parallel to flow"

    # Range 2: Near 90° (perpendicular to flow direction)
    - min_angle: 85.0
      max_angle: 95.0
      description: "Perpendicular to flow"

    # Optional: Additional perpendicular angle for comprehensive analysis
    # - min_angle: -95.0
    #   max_angle: -85.0
    #   description: "Perpendicular to flow (opposite side)"

    # Optional: Antiparallel angle
    # - min_angle: 170.0
    #   max_angle: -170.0
    #   description: "Antiparallel to flow"

  # Fallback behavior
  fallback_to_all_angles: true # Use all angles if no angles match target ranges

  # Filtering algorithm
  algorithm: "range_based" # Algorithm type (currently only range_based)
  tolerance: 3.0 # Angular tolerance [degrees] for range matching

  # Quality control for angle selection
  quality_control:
    min_angles_required: 1 # Minimum number of angles required for analysis
    max_angle_spread: 36.0 # Maximum spread within a single range [degrees]
    validate_coverage: true # Validate that angles adequately cover target ranges
    require_orthogonal_angles: true # Recommended for flow (parallel + perpendicular)

# ==============================================================================
# INITIAL PARAMETERS (Required)
# ==============================================================================
# Starting parameter values for optimization
#
# PARAMETER COUNT (Laminar Flow):
# --------------------------------
# **PER-ANGLE SCALING MANDATORY (v2.4.0)**:
#   - Legacy scalar contrast/offset mode REMOVED
#   - Each scattering angle has unique optical/detector properties
#   - Passing per_angle_scaling=False will raise ValueError
#
# Physical parameters: 7 [D₀, α, D_offset, γ̇₀, β, γ̇_offset, φ₀]
# Per-angle scaling: 2 × N_angles [contrast, offset]
# Total: 7 + 2N (e.g., 3 angles → 13 parameters)
#
initial_parameters:
  # Parameter names to optimize (7 parameters for laminar_flow mode)
  parameter_names:
    - D0 # Diffusion coefficient prefactor
    - alpha # Anomalous diffusion exponent
    - D_offset # Baseline diffusion
    - gamma_dot_t0 # Initial shear rate at t=0
    - beta # Shear rate exponent
    - gamma_dot_t_offset # Baseline shear rate offset
    - phi0 # Initial angle offset

  # Optional: Initial values (if not provided, uses mid-point of bounds)
  values: null # List of 7 floats matching parameter_names order
  # Example: [1000.0, 0.5, 10.0, 0.01, 0.0, 0.0, 0.0]

  # Per-angle scaling initialization (v2.4.0 mandatory)
  # IMPORTANT: Initialize from NLSQ results or estimate from data to prevent MCMC convergence failures
  # For NLSQ→MCMC workflow: Run NLSQ first, copy contrast/offset from results
  # For data estimation: contrast ≈ (C2_max - C2_min), offset ≈ C2_min
  per_angle_scaling:
    contrast: null # List of N floats (one per angle)
    offset: null # List of N floats (one per angle)
    # Example for 3 angles: contrast: [0.05, 0.06, 0.05], offset: [1.0, 0.99, 1.01]
    # Example for 1 angle:  contrast: [0.06], offset: [0.99]
    # Typical ranges: contrast [0.01-0.2], offset [0.9-1.1] for XPCS data

  # Optional: Units for documentation
  units: # Parameter units (for reference)
    - "Å²/s" # D0
    - "dimensionless" # alpha
    - "Å²/s" # D_offset
    - "s⁻¹" # gamma_dot_t0
    - "dimensionless" # beta
    - "s⁻¹" # gamma_dot_t_offset
    - "degrees" # phi0

  # Optional: Optimize only a subset of parameters (rest held at initial values)
  active_parameters: null # List of parameter names to actively optimize
  # Example: ["D0", "alpha", "gamma_dot_t0", "phi0"]  # Fix beta and offsets

  # Optional: Fix specific parameters at given values
  fixed_parameters: null # Dict mapping parameter names to fixed values
  # Example: {"beta": 0.0, "gamma_dot_t_offset": 0.0}  # Constant shear, no offset

# ==============================================================================
# PARAMETER SPACE (Required)
# ==============================================================================
# Parameter bounds and constraints for laminar flow model
parameter_space:
  model: "laminar_flow" # Laminar flow mode

  bounds:
    # -------------------------------------------------------------------------
    # DIFFUSION PARAMETERS (Required for all models)
    # -------------------------------------------------------------------------
    - name: D0
      min: 100.0 # Minimum diffusion coefficient [Å²/s]
      max: 1e5 # Maximum diffusion coefficient [Å²/s]
      type: TruncatedNormal # Bound type for priors
      prior_mu: 1000.0 # Prior mean (for Bayesian methods)
      prior_sigma: 1000.0 # Prior std dev (for Bayesian methods)
      unit: "Å²/s"
      # Physical meaning: Controls magnitude of diffusion in D(t) = D₀·t^α + D_offset
      # Typical range: 100-10000 for colloidal systems (may be higher under shear)

    - name: alpha
      min: -2.0 # ✅ FIXED: Physically realistic minimum (was -10.0)
      max: 2.0 # ✅ FIXED: Physically realistic maximum (was 10.0)
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: 0.5 # Prior mean (superdiffusion common under shear)
      prior_sigma: 0.5 # Prior std dev
      unit: "dimensionless"
      # Physical meaning: Anomalous diffusion exponent
      # 0 = normal diffusion, <0 = subdiffusion, >0 = superdiffusion
      # Shear often induces superdiffusion (α > 0)
      # ✅ Bounds tightened: [-10,10] caused numerical underflow (alpha=-4.96 → theory≈0)

    - name: D_offset
      min: -100000.0 # Minimum baseline diffusion [Å²/s]
      max: 100000.0 # Maximum baseline diffusion [Å²/s]
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: 10.0 # Prior mean (nonzero offset common under shear)
      prior_sigma: 200.0 # Prior std dev
      unit: "Å²/s"
      # Physical meaning: Constant diffusion contribution (can be negative)
      # Shear may enhance baseline diffusion

    # -------------------------------------------------------------------------
    # FLOW PARAMETERS (Required for laminar_flow mode only)
    # -------------------------------------------------------------------------
    - name: gamma_dot_t0 # Initial shear rate at t=0
      min: 1e-6 # Minimum initial shear rate [s⁻¹]
      max: 0.5 # Maximum initial shear rate [s⁻¹]
      type: TruncatedNormal
      prior_mu: 0.01 # Prior mean
      prior_sigma: 0.1 # Prior std dev
      unit: "s⁻¹"
      # Physical meaning: Shear rate prefactor in γ̇(t) = γ̇₀·t^β + γ̇_offset
      # Adjust based on experimental shear rates

    - name: beta
      min: -2.0 # Minimum shear exponent
      max: 2.0 # Maximum shear exponent
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: 0.0 # Prior mean (constant shear common)
      prior_sigma: 0.5 # Prior std dev
      unit: "dimensionless"
      # Physical meaning: Shear rate time evolution exponent
      # 0 = constant shear, >0 = increasing shear, <0 = decreasing shear

    - name: gamma_dot_t_offset # Baseline shear rate offset
      min: -0.1 # Minimum baseline shear [s⁻¹]
      max: 0.1 # Maximum baseline shear [s⁻¹]
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: 0.0 # Prior mean
      prior_sigma: 0.02 # Prior std dev
      unit: "s⁻¹"
      # Physical meaning: Constant shear contribution
      # Typically small or zero

    - name: phi0 # Initial angle offset
      min: -180.0 # Minimum initial angle [degrees]
      max: 180.0 # Maximum initial angle [degrees]
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: 0.0 # Prior mean (aligned with flow)
      prior_sigma: 30.0 # Prior std dev
      unit: "degrees"
      # Physical meaning: Angle between flow direction and scattering vector
      # Automatically normalized to [-180°, 180°]

  # Optional: Prior distributions for Bayesian methods
  priors: null # Advanced prior specifications (rarely needed)

# ==============================================================================
# OPTIMIZATION METHODS
# ==============================================================================
# Optimization method selection and configuration
optimization:
  method:
    "nlsq" # Options: "nlsq" | "mcmc"
    # Note: MCMC uses CMC-only architecture (v2.4.1) with per-shard NUTS sampling

  # ---------------------------------------------------------------------------
  # NLSQ - Trust-Region Nonlinear Least Squares (Primary Method)
  # ---------------------------------------------------------------------------
  # Fast, deterministic optimization using Levenberg-Marquardt algorithm
  # CPU-optimized with JAX 0.8.0 (v2.3.0+), JIT-compiled for performance
  # Automatic strategy selection based on dataset size:
  #   < 1M points     → STANDARD (curve_fit)
  #   1M-10M points   → LARGE (curve_fit_large)
  #   10M-100M points → CHUNKED (curve_fit_large with progress)
  #   > 100M points   → STREAMING (unlimited data with checkpointing)
  nlsq:
    max_iterations: 100 # Maximum optimization iterations
    tolerance: 1e-8 # Convergence tolerance
    trust_region_scale: 1.0 # Trust region scaling factor (0.1-10.0)
    verbose: false # Print iteration details

    # ROBUST LOSS FUNCTION SELECTION
    # --------------------------------
    # Controls how outliers affect the fit. All loss functions are JAX JIT-compiled.
    #
    # Available options:
    #   "linear"  - Standard least squares: ρ(z) = z
    #               No outlier protection; fastest; optimal for clean data
    #
    #   "huber"   - Huber loss: ρ(z) = z if z ≤ 1, else 2√z - 1
    #               Quadratic for small residuals, linear for large
    #               Good balance between efficiency and robustness
    #
    #   "soft_l1" - Soft L1 loss: ρ(z) = 2(√(1+z) - 1)
    #               Smooth approximation to L1 norm
    #               More robust than Huber; preserves differentiability
    #               RECOMMENDED DEFAULT for XPCS data
    #
    #   "cauchy"  - Cauchy/Lorentzian: ρ(z) = ln(1 + z)
    #               Extremely robust; handles heavy-tailed errors
    #               May converge slowly; use cautiously
    #
    #   "arctan"  - Arctangent: ρ(z) = arctan(z)
    #               Bounded loss; very robust to extreme outliers
    #               May converge slowly; use cautiously
    #
    # LOSS FUNCTION SELECTION FOR XPCS:
    # ----------------------------------
    # | Data Quality              | Recommended Loss |
    # |---------------------------|------------------|
    # | Clean, well-characterized | "linear"         |
    # | Typical XPCS data         | "soft_l1"        |
    # | Few outliers/artifacts    | "huber"          |
    # | Many outliers             | "soft_l1"        |
    # | Severe contamination      | "cauchy"         |
    # | Unknown quality           | "soft_l1"        |
    #
    # XPCS-specific considerations:
    #   - Detector artifacts, cosmic rays, dead pixels → use "soft_l1"
    #   - High-quality synchrotron data → "linear" or "huber"
    #   - If convergence issues with "cauchy"/"arctan" → fall back to "soft_l1"
    #
    loss: "soft_l1"

    # Parameter-Specific Scaling (CRITICAL FOR LAMINAR FLOW)
    # -------------------------------------------------------
    # Fixes gradient imbalance: shear parameters can have 100-10,000× larger gradients
    # than diffusion parameters, causing premature convergence and missing oscillations
    #
    # Recommended values (based on gradient diagnostics):
    #   - Diffusion params (D0, D_offset, phi0): 1.0 (baseline)
    #   - alpha: 0.001 (1000× smaller if gradient 1000× larger)
    #   - gamma_dot_t0: 0.00001 (100,000× smaller if gradient 100,000× larger)
    #   - beta: 0.0003 (3,000× smaller if gradient 3,000× larger)
    #   - gamma_dot_t_offset: 0.000001 (1,000,000× smaller if gradient 1,000,000× larger)
    #
    # Use gradient_diagnostics.py to compute optimal values for your dataset:
    #   python scripts/diagnose_gradients.py --results-dir ./homodyne_results/nlsq
    x_scale_map: # RECOMMENDED: Apply these values to fix gradient imbalance
      D0: 1.20 # Baseline diffusion (1.0× scaling)
      alpha: 0.000761 # Anomalous exponent (1,313× reduction)
      D_offset: 1.13 # Baseline diffusion offset (1.0× scaling)
      gamma_dot_t0: 0.00000371 # Shear rate (269,251× reduction)
      beta: 0.000314 # Shear exponent (3,188× reduction)
      gamma_dot_t_offset: 0.0000000930 # Shear offset (10,755,776× reduction!)
      phi0: 0.739 # Flow angle (1.0× scaling)
    # These values are derived from C020 dataset analysis (Nov 2025)
    # They fix gradient imbalance causing missing oscillations in fitted c2 heatmaps
    # To compute dataset-specific values, run: python scripts/diagnose_gradients.py

    # Shear Transform Configuration
    # ------------------------------
    # Applies coordinate transformations to shear parameters to improve conditioning
    # Helps normalize parameter magnitudes for better optimization
    shear_transforms:
      enabled: false # Enable shear parameter transforms
      # gamma_dot_t0_ref: 0.01                # Reference shear rate (shifts beta constraint)
      # beta_ref: 0.0                         # Reference beta exponent (improves conditioning)

    # Diagnostics and Validation
    # ---------------------------
    # Enable detailed diagnostics for gradient analysis and convergence monitoring
    diagnostics:
      enabled: false # Enable NLSQ diagnostics
      sample_size: 2048 # Sample size for Jacobian diagnostics
      check_gradients: true # Verify gradient computations
      log_jacobian_norms: false # Log parameter sensitivity (Jacobian norms)

  # ---------------------------------------------------------------------------
  # MCMC - Markov Chain Monte Carlo (Uncertainty Quantification)
  # ---------------------------------------------------------------------------
  # CMC-only architecture (v2.4.1): per-shard NUTS sampling with
  # weighted Gaussian combination of subposteriors
  # Provides full posterior distributions and uncertainty estimates
  # For laminar_flow with 7 parameters: increased warmup recommended
  mcmc:
    backend: "numpyro"           # "numpyro" | "blackjax"
    # Base MCMC settings (single-shard). These are
    # intentionally moderate; CMC-specific per-shard
    # settings are configured separately below.
    num_warmup: 500              # Increase if divergences persist
    num_samples: 2000            # Lower for quick diagnostics, raise for publication
    num_chains: 2                # ≥2 for R-hat calculation
    progress_bar: true
    target_accept_prob: 0.90     # NUTS target acceptance
    max_tree_depth: 12
    dense_mass_matrix: true      # Full covariance adaptation

    # Per-phi initialization (rarely needed)
    initial_values:
      phi: {}                    # {angle_deg: {contrast: X, offset: Y}}
      percentile_fallback:
        contrast_low_pct: 5
        contrast_high_pct: 95
        offset_pct: 50

  # ---------------------------------------------------------------------------
  # STREAMING - For Large Datasets (> 100M points)
  # ---------------------------------------------------------------------------
  # Constant memory footprint with checkpoint/resume capability
  streaming:
    enable_checkpoints: true # Enable HDF5 checkpoint save/resume
    checkpoint_dir: "./checkpoints" # Directory for checkpoint files
    checkpoint_frequency: 10 # Save checkpoint every N batches
    resume_from_checkpoint: true # Auto-detect and resume from latest checkpoint
    keep_last_checkpoints: 3 # Number of recent checkpoints to keep (older deleted)

    # Fault tolerance and error recovery
    enable_fault_tolerance: true # Enable numerical validation and recovery
    max_retries_per_batch: 2 # Maximum retry attempts per failed batch
    min_success_rate: 0.5 # Minimum batch success rate (0.0-1.0) before failing

    # Batch processing
    batch_size: null # Batch size in points (null = auto-detect based on memory)
    adaptive_batching: true # Dynamically adjust batch size based on performance

  # ---------------------------------------------------------------------------
  # CMC - Consensus Monte Carlo (v2.4.1: Default MCMC Architecture)
  # ---------------------------------------------------------------------------
  # CMC is the only MCMC path in v2.4.1+ (NUTS auto-selection removed)
  # Parallelizes MCMC across data shards with per-shard NUTS sampling
  # and combines subposteriors using weighted Gaussian combination
  cmc:
    backend: "jax" # Options: "jax" (CPU-only in v2.3.0+) | "numpy"
    diagonal_correction: true # Apply diagonal correction to correlation matrix

    # RNG seeding (for reproducibility)
    # Note: Each shard uses deterministic seed = shard_idx by default
    # See docs/developer-guide/cmc_rng_and_initialization.md for details
    # rng_seed_offset: null                   # Optional: offset all shard seeds (future extension)
    # Example: offset=42 → shard 0 uses seed 42, shard 1 uses seed 43, etc.

    # Data sharding configuration
  sharding:
    strategy: "stratified" # Options: "stratified" | "random" | "contiguous"
    num_shards: "auto" # Number of shards (int or "auto" for automatic)
    max_points_per_shard: 250000 # Max points per shard; auto uses 250k to reduce shard count

  # Per-shard timeout (seconds). Matches multiprocessing backend default
  # and can be lowered/raised here if site walltimes differ.
    per_shard_timeout: 7200

    # Backend configuration for parallel execution
    backend_config:
      name: "auto" # Options: "auto" | "pjit" | "multiprocessing" | "pbs" | "slurm"
      enable_checkpoints: true # Enable checkpoint functionality
      checkpoint_frequency: 1 # Save checkpoint every N shards
      checkpoint_dir: "./cmc_checkpoints" # Directory for CMC checkpoint files
      keep_last_checkpoints: 3 # Number of recent checkpoints to keep
      resume_from_checkpoint: true # Auto-resume from latest checkpoint

    # Subposterior combination method
    combination:
      method: "weighted_gaussian" # Options: "weighted_gaussian" | "simple_average" | "auto"
      validate_results: true # Validate combined posterior quality
      min_success_rate: 0.8 # Minimum fraction of shards that must converge (0.0-1.0)

    # Per-shard MCMC (overrides base mcmc settings for shards)
    # Tuned to avoid per-shard timeouts on large laminar_flow
    # datasets while still providing usable posteriors. No subsampling is
    # performed; each shard uses all assigned points.
    per_shard_mcmc:
      num_warmup: 500
      num_samples: 1500
      num_chains: 2
      target_accept_prob: 0.85

    # Convergence validation
    validation:
      strict_mode: false # Fail if validation criteria not met
      min_per_shard_ess: 100 # Minimum effective sample size per parameter per shard
      max_per_shard_rhat: 1.2 # Maximum R-hat per parameter per shard
      max_between_shard_kl: 0.5 # Maximum KL divergence between shard posteriors
      min_success_rate: 0.8 # Minimum fraction of shards that must converge

# ==============================================================================
# NOISE ESTIMATION (Optional)
# ==============================================================================
# Automatic noise level estimation using hybrid NumPyro approach
# Estimates per-angle or global noise variance to improve fit quality
noise_estimation:
  enabled: false # Enable automatic noise estimation
  model: "per_angle" # Options: "per_angle" | "global"

  # Adam optimization settings for noise parameter estimation
  adam_config:
    learning_rate: 0.01 # Adam learning rate
    max_epochs: 500 # Maximum optimization epochs
    convergence_threshold: 1e-6 # Convergence threshold for loss
    early_stopping: true # Enable early stopping for efficiency

  # Posterior sampling for uncertainty quantification
  posterior_samples: 1200 # Number of posterior samples for noise uncertainty

  # Quality control for noise estimation
  validation:
    check_convergence: true # Verify optimization convergence
    reasonable_range: [1e-4, 1.0] # Expected noise range (bounds for sanity check)
    warn_outliers: true # Warn about unusual noise estimates

  # Per-angle model settings
  per_angle:
    min_angles_required: 2 # Minimum angles needed for per-angle estimation
    validate_coverage: true # Ensure proper angle coverage

# ==============================================================================
# PERFORMANCE OPTIMIZATION
# ==============================================================================
# Performance and memory management settings
performance:
  # Strategy override (null = automatic selection based on dataset size)
  strategy_override: null # Options: null | "standard" | "large" | "chunked" | "streaming"

  # Memory management
  memory_limit_gb: null # Custom memory limit in GB (null = auto-detect)
  enable_progress: true # Show progress bars during optimization

  # Memory optimization settings
  memory_optimization:
    enabled: true # Enable memory optimization
    max_memory_usage_gb: 6.0 # Maximum memory usage [GB]
    chunk_size: 8000 # Data chunk size for processing
    enable_caching: true # Enable intelligent caching
    cache_strategy: "adaptive" # Options: "adaptive" | "aggressive" | "conservative"

  # Computation settings (CPU-only in v2.3.0+)
  computation:
    enable_jit: true # Enable JAX JIT compilation
    cpu_threads: "auto" # Number of CPU threads (int or "auto")
    vectorization_level: "high" # Options: "low" | "medium" | "high"
    # Note: GPU support removed in v2.3.0 (use v2.2.x for GPU)

# ==============================================================================
# LOGGING
# ==============================================================================
# Logging configuration for analysis monitoring
logging:
  enabled: true # Enable logging
  level: "INFO" # Options: "DEBUG" | "INFO" | "WARNING" | "ERROR"

  # Console logging
  console:
    enabled: true # Log to console
    level: "INFO" # Console log level
    format: "detailed" # Options: "simple" | "detailed"
    colors: true # Enable colored output
    show_progress: true # Show progress indicators

  # File logging
  file:
    enabled: false # Log to file
    level: "DEBUG" # File log level
    path: "./logs/" # Log directory
    filename: "homodyne_laminar_flow_analysis.log" # Log file name
    max_size_mb: 10 # Maximum log file size before rotation
    backup_count: 5 # Number of backup log files to keep

  # Module-specific logging levels
  modules:
    "homodyne.data.phi_filtering": "INFO"
    "homodyne.data.xpcs_loader": "INFO"
    "homodyne.optimization.nlsq_wrapper": "INFO"
    "jax._src": "WARNING" # Suppress JAX internal messages

# ==============================================================================
# QUALITY CONTROL (Optional)
# ==============================================================================
# Advanced quality control for data validation and analysis monitoring
quality_control:
  enabled: false # Enable quality control checks

  # Angle-specific quality checks
  angle_quality:
    validate_angle_coverage: true # Validate angle coverage adequacy
    min_angles_per_range: 1 # Minimum angles required per target range
    check_angle_distribution: true # Check angle distribution uniformity

  # Multi-angle data validation
  multi_angle_validation:
    check_correlation_consistency: true # Check correlation consistency across angles
    validate_angle_dependencies: true # Validate physical angle dependencies
    detect_anomalous_angles: true # Detect and warn about anomalous angles

# ==============================================================================
# VISUALIZATION (Optional)
# ==============================================================================
# Plot generation and output configuration
plotting:
  save_plots: true # Save plots to output directory
  show_plots: false # Display plots interactively
  format: "png" # Options: "png" | "pdf" | "svg"
  dpi: 300 # Resolution [dots per inch]
  style: "publication" # Plot style (matplotlib style name)

  # Rendering mode selection (hybrid plotting system)
  # Controls speed vs quality tradeoff for C2 heatmap plots
  preview_mode:
    false # false = publication quality (matplotlib, slower)
    # true = fast preview (Datashader, 5-10x faster)
  fit_surface: "solver"

  color_scale:
    mode: "legacy"
    pin_legacy_range: true
    percentile_min: 1.0
    percentile_max: 99.0
    fixed_min: 1.0
    fixed_max: 1.5

  # Datashader configuration (used when preview_mode: true)
  datashader:
    canvas_width: 1200 # Rendering resolution in pixels
    canvas_height: 1200 # Higher values = more detail, larger files
    # Note: CPU-only rendering in v2.3.0+

  # Matplotlib configuration (used when preview_mode: false)
  matplotlib:
    interpolation: "bilinear" # Options: "none" | "bilinear" | "bicubic"
    use_tight_layout: true # Use tight layout for plots
    savefig_kwargs:
      bbox_inches: "tight"
      pad_inches: 0.1

  # Plot types to generate
  correlation_function: true # C1(t) and C2(t1,t2) plots
  fit_quality: true # Residuals and fit quality plots
  parameter_distributions: true # Parameter posterior distributions (MCMC only)
  residual_analysis: true # Residual analysis plots

  # Angle-specific plots
  angle_coverage: true # Show which angles were used
  angle_correlation: true # Correlation quality vs angle

# ==============================================================================
# OUTPUT
# ==============================================================================
# Output file configuration
output:
  directory: "./results" # Base output directory
  base_directory: "./homodyne_results/" # Alternative: more descriptive directory name

  # Output formats
  formats:
    hdf5: true # Save results in HDF5 format
    json: true # Save results in JSON format
    csv: true # Save results in CSV format (tables only)

  # Output organization
  create_subdirs: true # Create method-specific subdirectories (nlsq/, mcmc/, cmc/)
  timestamp_dirs: false # Add timestamp to directory names

  # Compression
  compress_hdf5: true # Enable HDF5 compression (saves disk space)
  compression_level: 6 # HDF5 compression level (0-9, higher = more compression)

# ==============================================================================
# VALIDATION (Optional)
# ==============================================================================
# Configuration validation settings
validation:
  strict_mode: false # Fail on validation warnings
  check_file_existence: true # Verify data files exist before analysis
  validate_parameter_ranges: true # Check parameters are within reasonable physics bounds
  check_mode_compatibility: true # Verify configuration matches selected analysis mode

  # Angle validation
  angle_validation:
    require_multiple_angles: false # Not strictly required (can analyze with 1 angle)
    min_angle_count: 1 # Minimum number of angles required
    validate_angle_ranges: true # Validate angle ranges are physically meaningful


# ==============================================================================
# LAMINAR FLOW - USAGE NOTES
# ==============================================================================
#
# QUICK START (v2.4.1 Workflow):
# ----------------------------------------
# Step 1 - NLSQ optimization:
#   1. Update experimental_data paths to your HDF5 file
#   2. Adjust phi_filtering for parallel (0°) and perpendicular (90°) to flow
#   3. Run: homodyne --config this_file.yaml --method nlsq
#   4. Note best-fit parameters from output
#
# Step 2 - MCMC initialization:
#   5. Manually copy NLSQ best-fit results from output
#   6. Update initial_parameters.values in this file with NLSQ results
#   7. Example: values: [1234.5, 0.567, 12.34, 0.01, 0.0, 0.0, 0.0]
#   8. Run: homodyne --config this_file.yaml --method mcmc
#   9. CMC-only architecture with per-shard NUTS sampling
#
# LAMINAR FLOW PHYSICS:
# ---------------------
# Model: D(t) = D₀·t^α + D_offset
#        γ̇(t) = γ̇₀·t^β + γ̇_offset
#
# Diffusion parameters:
#   D₀: Diffusion coefficient prefactor (magnitude)
#   α: Anomalous diffusion exponent (shear often causes α > 0)
#   D_offset: Baseline diffusion (often enhanced by shear)
#
# Shear parameters:
#   γ̇₀: Shear rate prefactor (magnitude of applied shear)
#   β: Shear rate time evolution (0=constant, ≠0=time-dependent)
#   γ̇_offset: Baseline shear rate (usually small)
#   φ₀: Flow direction angle (alignment with scattering vector)
#
# Typical values:
#   D₀: 100-10000 Å²/s (may be higher under shear)
#   α: -2 to 2 (shear often induces superdiffusion α > 0)
#   D_offset: -100 to 100 Å²/s (shear effects)
#   γ̇₀: 1e-6 to 0.5 s⁻¹ (depends on applied shear)
#   β: -2 to 2 (0 for constant shear)
#   γ̇_offset: -0.1 to 0.1 s⁻¹ (typically small)
#   φ₀: -180° to 180° (flow direction)
#
# PARAMETER COUNTING:
# -------------------
# Total = 7 physical + 2 × N_angles scaling
# Example with 3 filtered angles: 7 + 2×3 = 13 parameters
#   Physical: [D₀, α, D_offset, γ̇₀, β, γ̇_offset, φ₀]
#   Scaling: [contrast₁, offset₁, contrast₂, offset₂, contrast₃, offset₃]
#
# ANGLE FILTERING FOR LAMINAR FLOW:
# ----------------------------------
# Recommended ranges:
#   - 0° (parallel): Maximum shear effects
#   - 90° (perpendicular): Minimal shear effects
#   - Orthogonal angles provide complementary flow information
#
# Use require_orthogonal_angles: true to ensure both directions sampled
#
# OPTIMIZATION METHOD SELECTION (v2.4.1):
# ----------------------------------------
# NLSQ (Recommended first):
#   - Fast: ~seconds to minutes
#   - CPU-optimized with JAX 0.8.0 JIT compilation
#   - Handles 7 parameters efficiently
#   - Good for exploration and initial fit
#   - CRITICAL FOR LAMINAR FLOW: Use x_scale_map to fix gradient imbalance
#
# MCMC (For publication with uncertainty quantification):
#   - Slower: ~hours for 7 parameters
#   - Full posterior distributions with credible intervals
#   - CMC-only architecture (v2.4.1): per-shard NUTS sampling with
#     weighted Gaussian combination of subposteriors
#   - Convergence diagnostics (R-hat, ESS, divergences)
#   - Increased warmup (2500) recommended for 7 parameters
#   - Manual workflow: Run NLSQ → copy results → update YAML → run MCMC
#
# Streaming (Automatic for >100M points):
#   - Constant memory footprint
#   - Checkpoint/resume capability
#
# CRITICAL: GRADIENT IMBALANCE IN LAMINAR FLOW
# ---------------------------------------------
# Shear parameters (gamma_dot_t0, beta, gamma_dot_t_offset) can have gradients
# 100-10,000× larger than diffusion parameters (D0, alpha, D_offset).
#
# This causes:
#   - Premature convergence (optimizer stops while shear params still need work)
#   - Missing fine-scale features (decay oscillations near baseline)
#   - Poor fit quality despite low chi-squared values
#
# SOLUTION: Apply parameter-specific scaling via x_scale_map
#
# Step 1: Run initial NLSQ optimization (without x_scale_map)
#   homodyne --config this_file.yaml --method nlsq
#
# Step 2: Diagnose gradient imbalance
#   python -c "
#   from homodyne.optimization.gradient_diagnostics import print_gradient_report
#   from homodyne.data.xpcs_loader import load_results
#   result, data, config = load_results('./homodyne_results/nlsq')
#   print_gradient_report(result.parameters, data, config, 'laminar_flow')
#   "
#
# Step 3: Add recommended x_scale_map to this config file
#   (copy from diagnostic report output)
#
# Step 4: Re-run optimization with proper scaling
#   homodyne --config this_file.yaml --method nlsq
#
# Step 5: Verify improved fit quality
#   - Check that fitted c2 heatmaps show decay oscillations
#   - Verify chi-squared improvement
#   - Confirm all parameters converged properly
#
# DATASET SIZE HANDLING:
# ----------------------
# NLSQ automatic strategy selection:
#   < 1M points     → STANDARD
#   1M-10M points   → LARGE
#   10M-100M points → CHUNKED
#   > 100M points   → STREAMING
#
# PLATFORM SUPPORT (v2.3.0):
# ---------------------------
# CPU-only: Linux, macOS, Windows (full support, multi-core optimized)
# GPU support removed in v2.3.0 (use v2.2.1 for GPU features)
# HPC-ready: Optimized for 14+ core CPUs, tested on 36-128 core nodes
#
# Installation:
#   pip install homodyne  # Automatically installs CPU-only JAX 0.8.0
#
# Requirements:
#   - Python 3.12+
#   - JAX==0.8.0 and jaxlib==0.8.0 (exact match required, CPU-only)
#   - For GPU: Stay on homodyne v2.2.1 (last GPU-supporting version)
#
# PHYSICAL INTERPRETATION:
# ------------------------
# Shear effects on diffusion:
#   - Enhanced D₀: Shear typically increases diffusion magnitude
#   - Superdiffusion: Shear often causes α > 0
#   - β ≈ 0: Steady shear (constant γ̇)
#   - β > 0: Increasing shear (acceleration)
#   - β < 0: Decreasing shear (deceleration)
#   - φ₀: Should align with known flow direction
#
# VALIDATION:
# -----------
# homodyne-config --validate this_file.yaml
# python -m homodyne.runtime.utils.system_validator --quick
#
# ==============================================================================
# END OF LAMINAR FLOW TEMPLATE
# ==============================================================================
