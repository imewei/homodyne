# ==============================================================================
# HOMODYNE MASTER CONFIGURATION TEMPLATE
# ==============================================================================
# Complete, maintained reference template for all homodyne configuration knobs.
# Covers static and laminar_flow analysis, Nonlinear Least Squares (NLSQ)
# optimization, and Consensus Monte Carlo (CMC).
#
# HOW TO USE THIS TEMPLATE:
# -------------------------
# 1. Copy this file and rename for your experiment (e.g., my_analysis.yaml)
# 2. Update experimental_data paths to your HDF5 file and phi angles
# 3. Set analysis_mode: "static" or "laminar_flow"
# 4. Adjust phi_filtering.target_ranges for your scattering geometry
# 5. Run NLSQ first: homodyne --config your_config.yaml --method nlsq
# 6. For MCMC: Copy NLSQ results to initial_parameters, then run with --method mcmc
#
# For production use, consider starting with the focused templates:
#   - homodyne_static.yaml: 3-parameter equilibrium diffusion
#   - homodyne_laminar_flow.yaml: 7-parameter shear flow
#
# VERSION: 2.6.0
# UPDATED: 2025-12-20
# ==============================================================================

# ==============================================================================
# METADATA (Required)
# ==============================================================================
# Template metadata for documentation and validation.
# The config_version must match the homodyne package version.
metadata:
  config_version: "2.6.0"  # Configuration schema version (must match package)
  description: "Master template - comprehensive reference with all configuration options"
  analysis_mode: "laminar_flow"  # Default mode; set in analysis_mode section below

  # Parameter count summary (physical parameters only, excludes per-angle scaling)
  #   static:       3 params [D₀, α, D_offset]
  #   laminar_flow: 7 params [D₀, α, D_offset, γ̇₀, β, γ̇_offset, φ₀]
  #   Total with scaling: physical + 2 × N_angles
  parameter_count: 7

  # Physics model equations
  physics_model: "D(t) = D₀·t^α + D_offset"
  shear_model: "γ̇(t) = γ̇₀·t^β + γ̇_offset"  # Laminar flow only

  # Numerical methods
  # NLSQ element-wise integration now matches CMC physics exactly
  # Uses cumulative trapezoidal integration with searchsorted-based time grid lookup
  # Eliminates up to 3.4% C₂ error in dynamic transitions between methods
  integration_method: "discrete_numerical"  # Stable trapezoidal integration
  diagonal_correction: "mandatory"  # Siegert relation correction (always applied)
  nlsq_cmc_physics_match: true  # NLSQ and CMC use identical integration

  # Template classification
  recommended_use: "Comprehensive reference for homodyne analyses; slim down for production"
  template_type: "reference"
  complexity: "comprehensive"

  # Auto-filled by CLI tools (leave as null)
  generated_at: null  # ISO timestamp when generated
  generated_by: null  # Tool name/version

# ==============================================================================
# ANALYSIS MODE (Required)
# ==============================================================================
# Determines which physical model to use.
#
# Options:
#   "static"       - Equilibrium diffusion only (3 physical parameters)
#                    Use for: pure diffusion, aging/jamming studies
#   "laminar_flow" - Diffusion + shear flow (7 physical parameters)
#                    Use for: rheology, Taylor-Couette flow, shear cells
#
analysis_mode: "laminar_flow"

# ==============================================================================
# ANALYZER PARAMETERS (Required)
# ==============================================================================
# Core experimental parameters. These MUST match your measurement setup.
#
# CRITICAL: Incorrect dt will shift all fitted parameters!
#   - Check your detector frame rate
#   - dt = 1 / (frames per second)
#
analyzer_parameters:
  # Time step between correlation measurements [seconds]
  # Common values: 0.001 (1 kHz), 0.01 (100 Hz), 0.1 (10 Hz)
  dt: 0.001

  # Frame range for analysis (1-indexed, inclusive)
  # Use to exclude startup transients or unstable regions
  start_frame: 1
  end_frame: 2000

  # Scattering geometry
  scattering:
    # Wave vector magnitude [Å⁻¹]
    # Typically 0.001-0.1 for XPCS; get from beamline/sample geometry
    wavevector_q: 0.0054

  # Shear cell geometry (laminar_flow mode)
  geometry:
    # Stator-rotor gap [Å]
    # 200 microns = 2,000,000 Å; 100 microns = 1,000,000 Å
    stator_rotor_gap: 2000000

# ==============================================================================
# ANALYSIS SETTINGS (Required)
# ==============================================================================
# Mode-specific settings and model description.
analysis_settings:
  # Boolean form of analysis_mode (deprecated but still supported)
  static_mode: false  # true → static, false → laminar_flow

  # Model documentation
  model_description:
    type: "nonequilibrium_laminar_flow"  # "static_diffusion" | "nonequilibrium_laminar_flow"
    parameters: 7  # 3 for static, 7 for laminar_flow
    physics: "Time-dependent diffusion with shear; C2 diagonal correction enforced"

# ==============================================================================
# EXPERIMENTAL DATA (Required)
# ==============================================================================
# Paths to your data files. Both absolute and relative paths are supported.
# Relative paths are resolved from the config file's directory.
#
# DATA FORMAT: HDF5 with exchange group structure
#   /exchange/data      - 3D array (frames, y, x)
#   /exchange/...       - Additional metadata
#
experimental_data:
  # Primary data file (preferred format)
  file_path: "./data/sample/experiment.hdf"

  # Legacy composite path (auto-normalized to file_path internally)
  data_folder_path: "./data/sample/"
  data_file_name: "experiment.hdf"

  # Phi angles file: one angle (degrees) per line, range [-180, 180]
  # Example file contents:
  #   -5.2
  #   0.1
  #   90.3
  phi_angles_path: "./data/sample/"
  phi_angles_file: "phi_angles_list.txt"

  # Caching (processed C2 data, speeds up re-runs)
  cache_file_path: "./data/sample/"
  cache_filename_template: "cached_c2_q{wavevector_q:.4f}_frames_{start_frame}_{end_frame}.npz"
  cache_compression: true

  # Data format specifications
  data_type: "float64"  # "float32" faster but less precise; "float64" recommended
  file_format: "HDF5"
  exchange_key: "exchange"

# ==============================================================================
# PHI ANGLE FILTERING
# ==============================================================================
# Select which scattering angles to include in analysis.
#
# WHY FILTER ANGLES?
#   - Reduces number of per-angle scaling parameters
#   - Focuses on angles with strongest signal
#   - For laminar flow: 0° (parallel) and 90° (perpendicular) capture flow effects
#   - For static: 0° and 180° detect anisotropy
#
# ANGLE CONVENTION:
#   - Angles in degrees, range [-180, 180]
#   - Wrap-aware: [170, -170] captures angles from 170° through 180° to -170°
#
phi_filtering:
  enabled: true

  # Target angle ranges to include
  target_ranges:
    - min_angle: -10.0
      max_angle: 10.0
      description: "Parallel to flow / primary axis"
    - min_angle: 85.0
      max_angle: 95.0
      description: "Perpendicular to flow"
    # Uncomment for additional angles:
    # - min_angle: -95.0
    #   max_angle: -85.0
    #   description: "Perpendicular (opposite side)"
    # - min_angle: 170.0
    #   max_angle: -170.0
    #   description: "Antiparallel"

  # If no angles match target_ranges, use all available angles
  fallback_to_all_angles: true

  # Filtering algorithm settings
  algorithm: "range_based"
  tolerance: 3.0  # Degrees; angles within tolerance of range edges are included

  # Quality control
  quality_control:
    min_angles_required: 1  # Minimum angles needed (≥2 recommended for flow)
    max_angle_spread: 36.0  # Maximum spread within each range (keep tight)
    validate_coverage: true  # Warn if ranges are poorly covered
    require_orthogonal_angles: true  # Recommended for laminar_flow (0°/90°)

# ==============================================================================
# INITIAL PARAMETERS (Required)
# ==============================================================================
# Starting values for optimization.
#
# PARAMETER COUNT:
#   Total = physical + 2 × N_angles (per-angle contrast + offset)
#   static:       3 + 2N (e.g., 3 angles → 9 parameters)
#   laminar_flow: 7 + 2N (e.g., 3 angles → 13 parameters)
#
# WORKFLOW (NLSQ → MCMC):
#   1. Run NLSQ first with values: null (uses mid-bounds)
#   2. Copy fitted parameters from NLSQ output
#   3. Paste into values: [...] for MCMC initialization
#   4. Run MCMC with good starting point
#
# PER-ANGLE SCALING:
#   MANDATORY - each angle has unique contrast/offset
#   Legacy scalar mode removed; per_angle_scaling=False raises ValueError
#
initial_parameters:
  # Physical parameter names (order matters for values list)
  parameter_names:
    - D0                   # Diffusion prefactor [Å²/s]
    - alpha                # Anomalous exponent [dimensionless]
    - D_offset             # Baseline diffusion [Å²/s]
    - gamma_dot_t0         # Shear rate prefactor [s⁻¹] (laminar_flow only)
    - beta                 # Shear exponent [dimensionless] (laminar_flow only)
    - gamma_dot_t_offset   # Baseline shear [s⁻¹] (laminar_flow only)
    - phi0                 # Flow angle offset [degrees] (laminar_flow only)

  # Initial values: list matching parameter_names order, or null for mid-bounds
  # Static example:       [1000.0, 0.5, 10.0]
  # Laminar flow example: [1000.0, 0.5, 10.0, 0.01, 0.0, 0.0, 0.0]
  values: null

  # Per-angle scaling initialization (one value per filtered angle)
  # Estimate from data: contrast ≈ (C2_max - C2_min), offset ≈ C2_min
  per_angle_scaling:
    contrast: null  # e.g., [0.05, 0.06, 0.05] for 3 angles
    offset: null    # e.g., [1.0, 0.99, 1.01] for 3 angles

  # Units for documentation (not used by optimizer)
  units:
    - "Å²/s"           # D0
    - "dimensionless"  # alpha
    - "Å²/s"           # D_offset
    - "s⁻¹"            # gamma_dot_t0
    - "dimensionless"  # beta
    - "s⁻¹"            # gamma_dot_t_offset
    - "degrees"        # phi0

  # Optional: Optimize only a subset of parameters
  active_parameters: null  # e.g., ["D0", "alpha", "gamma_dot_t0"]

  # Optional: Fix parameters at specific values
  fixed_parameters: null  # e.g., {"beta": 0.0, "gamma_dot_t_offset": 0.0}

# ==============================================================================
# PARAMETER SPACE (Required)
# ==============================================================================
# Parameter bounds and prior distributions.
#
# DEFAULT BOUNDS (from homodyne.core.fitting.ParameterSpace):
# -----------------------------------------------------------
# | Parameter          | Default Bounds      | Notes                              |
# |--------------------|---------------------|------------------------------------|
# | contrast           | (0.0, 1.0)          | Physical: visibility/coherence     |
# | offset             | (0.5, 1.5)          | Baseline around 1.0 ± 50%          |
# | D0                 | (1.0, 1,000,000)    | Diffusion coefficient              |
# | alpha              | (-2.0, 2.0)         | Tighter for numerical stability    |
# | D_offset           | (-100,000, 100,000) | Diffusion baseline correction      |
# | gamma_dot_t0       | (1e-5, 1.0)         | Shear rate                         |
# | beta               | (-2.0, 2.0)         | Tighter for numerical stability    |
# | gamma_dot_t_offset | (-1.0, 1.0)         | Shear baseline correction          |
# | phi0               | (-30.0, 30.0)       | Flow direction angle [degrees]     |
#
# BOUNDS GUIDELINES:
#   - Too narrow: May miss true optimum
#   - Too wide: Slow convergence, numerical issues
#   - Start with template bounds, tighten for MCMC if posteriors wander
#
# PRIOR DISTRIBUTIONS:
#   - type: "TruncatedNormal" - Bounded Gaussian (recommended)
#   - prior_mu/prior_sigma: Used only by MCMC/CMC
#
parameter_space:
  model: "laminar_flow"  # Must match analysis_mode

  bounds:
    # -------------------------------------------------------------------------
    # SCALING PARAMETERS (applied per angle; shown once for reference)
    # -------------------------------------------------------------------------
    - name: contrast
      min: 0.0      # Physical minimum (no negative contrast)
      max: 1.0      # Physical maximum (fully coherent) - CANNOT exceed 1.0
      type: TruncatedNormal
      # DEFAULT BOUNDS: (0.0, 1.0) - Physical range for visibility/coherence
      # Typical XPCS values: 0.01-0.2

    - name: offset
      min: 0.5      # Baseline should be near 1.0
      max: 1.5      # Allow some variation
      type: TruncatedNormal
      # DEFAULT BOUNDS: (0.5, 1.5) - Baseline around 1.0 ± 50%
      # Typical XPCS values: 0.9-1.1

    # -------------------------------------------------------------------------
    # DIFFUSION PARAMETERS (all modes)
    # -------------------------------------------------------------------------
    - name: D0
      min: 100.0           # Minimum diffusion [Å²/s]
      max: 100000.0        # Maximum diffusion [Å²/s]
      type: TruncatedNormal
      prior_mu: 1000.0     # Prior mean for MCMC
      prior_sigma: 1000.0  # Prior std for MCMC
      unit: "Å²/s"
      # DEFAULT BOUNDS: (1.0, 1,000,000) - Wide range for diverse systems
      # Physical meaning: Diffusion coefficient magnitude
      # D(t) = D₀·t^α + D_offset

    - name: alpha
      min: -2.0            # Strong subdiffusion
      max: 2.0             # Strong superdiffusion
      type: TruncatedNormal
      prior_mu: -1.2       # Prior mean (subdiffusive default)
      prior_sigma: 0.3     # Prior std
      unit: "dimensionless"
      # DEFAULT BOUNDS: (-2.0, 2.0) - Tighter for numerical stability
      # Physical meaning: Anomalous diffusion exponent
      #   α < 0: Subdiffusion (crowded, jammed systems)
      #   α = 0: Normal diffusion
      #   α > 0: Superdiffusion (shear-enhanced, active systems)

    - name: D_offset
      min: -100000.0       # Allow negative (rare but possible)
      max: 100000.0        # Wide range for exploratory fits
      type: TruncatedNormal
      prior_mu: 0.0
      prior_sigma: 150.0
      unit: "Å²/s"
      # DEFAULT BOUNDS: (-100,000, 100,000) - Allows negative for arrested systems
      # Physical meaning: Constant diffusion baseline
      # Negative values may indicate arrested dynamics

    # -------------------------------------------------------------------------
    # FLOW PARAMETERS (laminar_flow mode only)
    # -------------------------------------------------------------------------
    - name: gamma_dot_t0
      min: 1e-6            # Near-zero shear
      max: 0.5             # High shear rate
      type: TruncatedNormal
      prior_mu: 0.01
      prior_sigma: 0.1
      unit: "s⁻¹"
      # DEFAULT BOUNDS: (1e-5, 1.0) - Realistic shear rates for XPCS
      # Physical meaning: Shear rate magnitude
      # γ̇(t) = γ̇₀·t^β + γ̇_offset

    - name: beta
      min: -2.0            # Decreasing shear
      max: 2.0             # Increasing shear
      type: TruncatedNormal
      prior_mu: 0.0        # Default: constant shear
      prior_sigma: 0.5
      unit: "dimensionless"
      # DEFAULT BOUNDS: (-2.0, 2.0) - Tighter for numerical stability
      # Physical meaning: Shear rate time evolution
      #   β = 0: Constant shear
      #   β > 0: Shear increases with time
      #   β < 0: Shear decreases with time

    - name: gamma_dot_t_offset
      min: -0.1
      max: 0.1
      type: TruncatedNormal
      prior_mu: 0.0
      prior_sigma: 0.02
      unit: "s⁻¹"
      # DEFAULT BOUNDS: (-1.0, 1.0) - Allows negative offsets
      # Physical meaning: Baseline shear rate offset
      # Usually small or zero

    - name: phi0
      min: -10.0           # Tight bounds help MCMC convergence
      max: 10.0            # Widen if flow misalignment suspected
      type: TruncatedNormal
      prior_mu: 0.0
      prior_sigma: 5.0
      unit: "degrees"
      # DEFAULT BOUNDS: (-30.0, 30.0) - Flow direction angle offset
      # Physical meaning: Flow direction angle offset
      # Accounts for misalignment between flow and detector axes

  # Advanced prior specifications (rarely needed)
  priors: null

# ==============================================================================
# OPTIMIZATION (NLSQ + CMC-only MCMC)
# ==============================================================================
# Optimization method selection and configuration.
#
# RECOMMENDED WORKFLOW:
#   1. Run NLSQ first (fast, deterministic)
#   2. Inspect residuals and fitted C2 heatmaps
#   3. If fit quality poor, apply x_scale_map (see nlsq.x_scale_map)
#   4. Copy best-fit to initial_parameters
#   5. Run MCMC for uncertainty quantification
#
# METHOD SELECTION:
#   "nlsq" - Nonlinear least squares (seconds to minutes)
#   "mcmc" - Markov Chain Monte Carlo via CMC (minutes to hours)
#   "cmc"  - Same as "mcmc" (CMC is the only MCMC path)
#
optimization:
  method: "nlsq"

  # ---------------------------------------------------------------------------
  # NLSQ - Trust-Region Nonlinear Least Squares
  # ---------------------------------------------------------------------------
  # Fast, deterministic point estimation using Levenberg-Marquardt.
  # CPU-optimized with JAX JIT compilation.
  #
  # AUTOMATIC STRATEGY SELECTION (by dataset size):
  #   < 1M points      → STANDARD (curve_fit)
  #   1M-10M points    → LARGE (curve_fit_large)
  #   10M-100M points  → CHUNKED (with progress bar)
  #   > 100M points    → STREAMING (checkpoint/resume)
  #
  nlsq:
    max_iterations: 100    # Increase to 200-300 if convergence slow
    tolerance: 1e-8        # Loosen to 1e-6 for quick exploratory fits
    trust_region_scale: 1.0
    verbose: false

    # ROBUST LOSS FUNCTION SELECTION
    # --------------------------------
    # Controls how outliers affect the fit. All loss functions are JAX JIT-compiled.
    #
    # Available options:
    #   "linear"  - Standard least squares: ρ(z) = z
    #               No outlier protection; fastest; optimal for clean data
    #
    #   "huber"   - Huber loss: ρ(z) = z if z ≤ 1, else 2√z - 1
    #               Quadratic for small residuals, linear for large
    #               Good balance between efficiency and robustness
    #
    #   "soft_l1" - Soft L1 loss: ρ(z) = 2(√(1+z) - 1)
    #               Smooth approximation to L1 norm
    #               More robust than Huber; preserves differentiability
    #               RECOMMENDED DEFAULT for XPCS data
    #
    #   "cauchy"  - Cauchy/Lorentzian: ρ(z) = ln(1 + z)
    #               Extremely robust; handles heavy-tailed errors
    #               May converge slowly; use cautiously
    #
    #   "arctan"  - Arctangent: ρ(z) = arctan(z)
    #               Bounded loss; very robust to extreme outliers
    #               May converge slowly; use cautiously
    #
    # LOSS FUNCTION SELECTION FOR XPCS:
    # ----------------------------------
    # | Data Quality              | Recommended Loss |
    # |---------------------------|------------------|
    # | Clean, well-characterized | "linear"         |
    # | Typical XPCS data         | "soft_l1"        |
    # | Few outliers/artifacts    | "huber"          |
    # | Many outliers             | "soft_l1"        |
    # | Severe contamination      | "cauchy"         |
    # | Unknown quality           | "soft_l1"        |
    #
    # XPCS-specific considerations:
    #   - Detector artifacts, cosmic rays, dead pixels → use "soft_l1"
    #   - High-quality synchrotron data → "linear" or "huber"
    #   - If convergence issues with "cauchy"/"arctan" → fall back to "soft_l1"
    #
    loss: "soft_l1"

    # PARAMETER-SPECIFIC SCALING (Critical for laminar_flow)
    # ------------------------------------------------------
    # Fixes gradient imbalance: shear gradients can be 1000-10,000× larger
    # than diffusion gradients, causing premature convergence.
    #
    # SYMPTOM: Early convergence, flat shear params, missing C2 oscillations
    #
    # DIAGNOSIS:
    #   python scripts/diagnose_gradients.py --results-dir ./homodyne_results/nlsq
    #
    # Values below are from C020 dataset analysis (Nov 2025).
    # Compute dataset-specific values using diagnose_gradients.py
    x_scale_map:
      D0: 1.20
      alpha: 0.000761
      D_offset: 1.13
      gamma_dot_t0: 0.00000371
      beta: 0.000314
      gamma_dot_t_offset: 0.0000000930
      phi0: 0.739

    # Shear parameter transforms (experimental)
    shear_transforms:
      enabled: false
      gamma_dot_t0_ref: 0.01
      beta_ref: 0.0

    # Diagnostics for troubleshooting
    diagnostics:
      enabled: false
      sample_size: 2048
      check_gradients: true
      log_jacobian_norms: false

    # -------------------------------------------------------------------------
    # PROGRESS BAR AND LOGGING
    # -------------------------------------------------------------------------
    # Controls progress bar display and logging verbosity during optimization.
    # Provides real-time feedback on optimization progress.
    progress:
      enable: true       # Show tqdm progress bar during fitting
      verbose: 1         # Verbosity level: 0=quiet, 1=normal (milestones), 2=detailed
      log_interval: 10   # Log every N iterations (for verbose >= 2)

    # -------------------------------------------------------------------------
    # HYBRID STREAMING OPTIMIZER (AdaptiveHybridStreamingOptimizer)
    # -------------------------------------------------------------------------
    # Four-phase optimizer for large datasets (>10M points):
    #   Phase 0: Parameter normalization setup
    #   Phase 1: Adam warmup with adaptive switching
    #   Phase 2: Streaming Gauss-Newton (quadratic convergence)
    #   Phase 3: Denormalization and covariance transform
    #
    # Memory: Bounded at ~2 GB regardless of dataset size
    # Expected: ~10x fewer iterations (110 vs 1000+)
    hybrid_streaming:
      enable: true                              # Use hybrid optimizer for large datasets
      normalize: true                           # Enable parameter normalization
      normalization_strategy: "auto"            # "auto" | "bounds" | "p0" | "none"
      warmup_iterations: 200                    # Adam warmup before switch check
      max_warmup_iterations: 500                # Force switch to Gauss-Newton
      warmup_learning_rate: 0.001               # Adam base learning rate
      gauss_newton_max_iterations: 100          # Max Gauss-Newton iterations
      gauss_newton_tol: 1.0e-8                  # Convergence tolerance
      chunk_size: 10000                         # Points per chunk for streaming J^T J
      trust_region_initial: 1.0                 # Initial trust region size
      regularization_factor: 1.0e-10            # Tikhonov regularization for J^T J
      enable_checkpoints: true                  # Enable checkpoint save/resume
      checkpoint_frequency: 100                 # Checkpoint every N iterations
      validate_numerics: true                   # Numerical validation (NaN/Inf)
      verbose: 1                                # 0=silent, 1=progress, 2=debug
      log_frequency: 1                          # Log every N iterations

      # 4-LAYER DEFENSE STRATEGY (NLSQ 0.3.6)
      # ------------------------------------
      # Prevents Adam warmup from diverging when starting from good parameters.
      # All layers ENABLED BY DEFAULT - protects good starting points while
      # preserving Adam's exploration benefits for poor starting points.
      #
      # Layer 1: Warm Start Detection - skip warmup if already at good solution
      enable_warm_start_detection: true         # Enable warm start detection
      warm_start_threshold: 0.01                # Skip warmup if loss/variance < this
      #
      # Layer 2: Adaptive Learning Rate - scale LR based on initial loss quality
      enable_adaptive_warmup_lr: true           # Enable adaptive LR
      warmup_lr_refinement: 1.0e-6              # LR for good starts (rel_loss < 0.1)
      warmup_lr_careful: 1.0e-5                 # LR for moderate starts (rel_loss < 1.0)
      #
      # Layer 3: Cost-Increase Guard - abort if loss increases during warmup
      enable_cost_guard: true                   # Enable cost guard
      cost_increase_tolerance: 0.05             # Abort if loss increases >5%
      #
      # Layer 4: Step Clipping - limit max parameter change per iteration
      enable_step_clipping: true                # Enable step clipping
      max_warmup_step_size: 0.1                 # Max step (fraction of normalized range)

      # -------------------------------------------------------------------------
      # GROUP VARIANCE REGULARIZATION (NLSQ 0.3.8) - DEPRECATED
      # -------------------------------------------------------------------------
      # NOTE: This section is DEPRECATED in favor of the new anti_degeneracy
      # system below. Group variance regularization is now part of Layer 3
      # (Adaptive CV-based Regularization) in the 4-layer defense system.
      #
      # Legacy settings preserved for backward compatibility:
      enable_group_variance_regularization: false  # Use anti_degeneracy instead
      group_variance_lambda: 0.01                  # Legacy value
      # group_variance_indices: null

    # ---------------------------------------------------------------------------
    # ANTI-DEGENERACY DEFENSE SYSTEM (v2.9.0)
    # ---------------------------------------------------------------------------
    # Comprehensive 4-layer defense against structural degeneracy where per-angle
    # parameters absorb physical signals (especially shear parameters).
    #
    # Problem: With many angles (n_phi > 3), per-angle params can "absorb"
    # angle-dependent shear signals, causing gamma_dot_t0 to collapse to zero.
    #
    # Solution: 4 complementary defense layers:
    #   Layer 1: Fourier Reparameterization - reduces per-angle param count
    #   Layer 2: Hierarchical Optimization - alternating physical/per-angle stages
    #   Layer 3: Adaptive CV Regularization - auto-tuned λ≈10 (100× stronger)
    #   Layer 4: Gradient Collapse Monitor - runtime detection with auto-response
    #
    # When to enable: laminar_flow mode with per_angle_scaling and n_phi > 3
    # For static mode: Can disable (enable: false) as no shear parameters
    #
    # See: docs/specs/anti-degeneracy-defense-v2.9.0.md
    anti_degeneracy:
      enable: true                    # Master enable for all defenses
      per_angle_mode: "auto"          # "direct" | "fourier" | "auto"

      # Layer 1: Fourier Reparameterization
      fourier:
        order: 2                      # Fourier series order
        min_phi_for_fourier: 6        # Minimum n_phi to use Fourier mode
        regularize_high_order: false

      # Layer 2: Hierarchical Two-Stage Optimization
      hierarchical:
        enable: true
        max_outer_iterations: 5
        outer_tolerance: 1.0e-6
        physical_max_iterations: 100
        physical_ftol: 1.0e-8
        per_angle_max_iterations: 50
        per_angle_ftol: 1.0e-6
        log_stage_transitions: true
        save_intermediate_results: false

      # Layer 3: Adaptive CV-based Regularization
      regularization:
        enable: true
        mode: "relative"              # "absolute" | "relative" | "auto"
        lambda: 1.0
        target_cv: 0.10               # Target coefficient of variation (10%)
        target_contribution: 0.10     # Target regularization contribution (10%)
        auto_tune_lambda: true
        max_cv: 0.20

      # Layer 4: Gradient Collapse Monitor
      gradient_monitoring:
        enable: true
        ratio_threshold: 0.01         # Collapse threshold (1% of per-angle grad)
        consecutive_triggers: 5
        response: "hierarchical"      # "warn" | "hierarchical" | "reset" | "abort"
        check_interval: 1
        lambda_multiplier_on_collapse: 10.0

  # ---------------------------------------------------------------------------
  # STREAMING - Checkpoint/Resume for Large Datasets (>100M points)
  # ---------------------------------------------------------------------------
  # Maintains constant memory footprint with fault tolerance.
  # Automatically activated when dataset exceeds streaming threshold.
  streaming:
    enable_checkpoints: true
    checkpoint_dir: "./checkpoints"
    checkpoint_frequency: 10     # Save every N batches
    resume_from_checkpoint: true
    keep_last_checkpoints: 3     # Delete older checkpoints
    enable_fault_tolerance: true
    max_retries_per_batch: 2
    min_success_rate: 0.5        # Fail if <50% batches succeed
    batch_size: null             # Auto-detect based on memory
    adaptive_batching: true

  # ---------------------------------------------------------------------------
  # STRATIFICATION - Angle-Stratified Chunking
  # ---------------------------------------------------------------------------
  # Fixes per-angle scaling compatibility with NLSQ chunking.
  # Reorganizes data so every chunk contains all phi angles.
  #
  # PROBLEM SOLVED: Without stratification, arbitrary chunking can create
  # chunks missing certain angles → zero gradients → silent failures.
  stratification:
    enabled: "auto"              # "auto" | true | false
    target_chunk_size: 100000
    max_imbalance_ratio: 5.0     # Fall back to sequential if ratio exceeded
    force_sequential_fallback: false
    check_memory_safety: true
    use_index_based: false       # true = zero-copy, lower memory
    collect_diagnostics: false
    log_diagnostics: false

  # ---------------------------------------------------------------------------
  # SEQUENTIAL - Per-Angle Optimization Fallback
  # ---------------------------------------------------------------------------
  # Used when stratification cannot be applied (extreme angle imbalance).
  # Optimizes each angle independently, then combines with weighted averaging.
  sequential:
    min_success_rate: 0.5        # Fail if <50% angles converge
    weighting: "inverse_variance"  # "inverse_variance" | "uniform" | "n_points"

  # ---------------------------------------------------------------------------
  # NLSQ MULTI-START OPTIMIZATION
  # ---------------------------------------------------------------------------
  # Explores parameter space from multiple starting points using Latin
  # Hypercube Sampling to find global optimum and detect parameter degeneracy.
  # See multistart_example.yaml for detailed configuration options.
  #
  # Strategy Selection (automatic based on dataset size):
  # - < 1M points:    FULL strategy (N complete fits in parallel)
  # - 1M - 100M:      SUBSAMPLE strategy (multi-start on 500K subsample)
  # - > 100M points:  PHASE1 strategy (parallel Adam warmup, single GN)
  #
  # Configure in nlsq section:
  #   nlsq:
  #     multi_start:
  #       enable: false                   # Default OFF - user opt-in
  #       n_starts: 10                    # Number of LHS starting points
  #       seed: 42                        # Random seed for reproducibility
  #       sampling_strategy: "latin_hypercube"  # or "random"
  #       n_workers: 0                    # 0 = auto (min of n_starts, cpu_count)
  #       use_screening: true             # Pre-filter by initial cost
  #       screen_keep_fraction: 0.5       # Keep top 50%
  #       subsample_size: 500000          # Subsample size for 1M-100M datasets
  #       warmup_only_threshold: 100000000  # 100M: switch to Phase 1 strategy
  #       refine_top_k: 3                 # Polish top 3 solutions
  #       refinement_ftol: 1.0e-12        # Tighter tolerance for refinement
  #       degeneracy_threshold: 0.1       # Flag if chi² within 10%

  # ---------------------------------------------------------------------------
  # MCMC - Base MCMC Sampler Configuration
  # ---------------------------------------------------------------------------
  # Base configuration for NumPyro/BlackJAX NUTS sampler.
  # Used by CMC shards; can be overridden in cmc.per_shard_mcmc.
  mcmc:
    backend: "numpyro"           # "numpyro" | "blackjax"
    num_warmup: 1000             # Increase if divergences persist
    num_samples: 3000            # Lower for diagnostics, raise for publication
    num_chains: 4                # ≥2 for R-hat calculation
    progress_bar: true
    target_accept_prob: 0.90     # NUTS target acceptance
    max_tree_depth: 12
    dense_mass_matrix: true      # Full covariance adaptation

    # Per-phi initialization (rarely needed)
    initial_values:
      phi: {}                    # {angle_deg: {contrast: X, offset: Y}}
      percentile_fallback:
        contrast_low_pct: 5
        contrast_high_pct: 95
        offset_pct: 50

  # ---------------------------------------------------------------------------
  # CMC - Consensus Monte Carlo (Only MCMC Path)
  # ---------------------------------------------------------------------------
  # Parallelizes MCMC across data shards using per-shard NUTS sampling.
  # Combines subposteriors via Consensus Monte Carlo (precision-weighted means).
  #
  # AUTO-ACTIVATION:
  #   CMC is used when: enable="auto" AND dataset ≥ min_points_for_cmc
  #   Set enable=true to force CMC on any dataset size.
  #
  # MODE-SPECIFIC THRESHOLDS (when min_points_for_cmc=500000):
  #   - laminar_flow: 100,000 (7-param model benefits from earlier sharding)
  #   - static: 500,000 (3-param model handles larger single-shard runs)
  #
  cmc:
    enable: "auto"               # true | false | "auto"
    min_points_for_cmc: 500000   # Threshold for auto-enable (see mode-specific note above)
    run_id: null                 # Optional: tag for multi-run tracking

    # Computational backend
    backend: "jax"               # "jax" | "numpy"; for parallel backend use backend_config.name (prefer "multiprocessing"/"auto")

    # Parallel execution configuration
    backend_config:
      name: "auto"               # "auto" | "multiprocessing" | "pjit" | "pbs" | "slurm"; legacy "jax" maps to "multiprocessing"
      enable_checkpoints: true
      checkpoint_frequency: 1    # Save every N shards
      checkpoint_dir: "./cmc_checkpoints"
      keep_last_checkpoints: 3
      resume_from_checkpoint: true

    # Data sharding
    sharding:
      strategy: "stratified"     # "stratified" (angle-aware) | "random" | "contiguous"
      num_shards: "auto"         # "auto" uses n_phi for stratified
      max_points_per_shard: "auto"  # "auto" → 20k/10k (laminar_flow) or 100k (static)
      # Note: Tune based on timeout behavior. ~20-40 min per shard expected.
      seed_base: 0               # Shard seed = seed_base + shard_id

    # Per-shard timeout (seconds). Matches multiprocessing backend default.
    # Can be lowered/raised based on dataset size and shard configuration.
    #
    # TIMEOUT TUNING GUIDANCE:
    # ----------------------------------
    # | Dataset Size | Shard Size | Recommended Timeout |
    # |--------------|------------|---------------------|
    # | < 2M points  | 20K auto   | 7200s (2 hours)     |
    # | 2M - 10M     | 10K auto   | 7200s (2 hours)     |
    # | 10M - 50M    | 10K auto   | 10800s (3 hours)    |
    # | > 50M        | 5K-10K     | 14400s (4 hours)    |
    #
    # Increase timeout if:
    # - Running on slower CPUs (< 36 cores)
    # - Higher num_warmup/num_samples per shard
    # - Complex posteriors requiring deep tree exploration
    # - Consistently hitting timeout limits in logs
    per_shard_timeout: 7200
    heartbeat_timeout: 600       # 10 minutes - terminate unresponsive workers

    # Subposterior combination
    combination:
      method: "consensus_mc"     # "consensus_mc" (recommended) | "weighted_gaussian" | "simple_average"
      validate_results: true
      min_success_rate: 0.90     # Require 90% shard convergence
      min_success_rate_warning: 0.80  # Warn if success rate below this threshold

    # Per-shard MCMC (overrides base mcmc settings for shards). No
    # subsampling is performed; each shard uses all assigned points.
    per_shard_mcmc:
      num_warmup: 500
      num_samples: 1500
      num_chains: 2
      target_accept_prob: 0.85

    # Convergence validation
    validation:
      strict_mode: true          # Fail if thresholds not met
      min_per_shard_ess: 100.0   # Effective sample size threshold
      max_per_shard_rhat: 1.1    # R-hat threshold
      max_between_shard_kl: 2.0  # KL divergence between shards
      min_success_rate: 0.90

# ==============================================================================
# NOISE ESTIMATION (Optional)
# ==============================================================================
# Automatic noise variance estimation for improved fit weighting.
# Uses hybrid NumPyro approach with Adam optimization.
noise_estimation:
  enabled: false
  model: "per_angle"             # "per_angle" | "global"

  adam_config:
    learning_rate: 0.01
    max_epochs: 500
    convergence_threshold: 1e-6
    early_stopping: true

  posterior_samples: 1200

  validation:
    check_convergence: true
    reasonable_range: [1e-4, 1.0]
    warn_outliers: true

  per_angle:
    min_angles_required: 2
    validate_coverage: true

# ==============================================================================
# PERFORMANCE (CPU Only)
# ==============================================================================
# Memory management and computation settings.
# GPU support removed (CPU-only).
performance:
  strategy_override: null        # null | "standard" | "large" | "chunked" | "streaming"
  memory_limit_gb: null          # null = auto-detect
  enable_progress: true

  memory_optimization:
    enabled: true
    max_memory_usage_gb: 6.0
    chunk_size: 8000
    enable_caching: true
    cache_strategy: "adaptive"   # "adaptive" | "aggressive" | "conservative"

  computation:
    enable_jit: true             # JAX JIT compilation
    cpu_threads: "auto"          # Number of CPU threads
    vectorization_level: "high"  # "low" | "medium" | "high"

# ==============================================================================
# LOGGING
# ==============================================================================
# Logging configuration for analysis monitoring.
logging:
  enabled: true
  level: "INFO"                  # "DEBUG" | "INFO" | "WARNING" | "ERROR"

  console:
    enabled: true
    level: "INFO"
    format: "detailed"           # "simple" | "detailed"
    colors: true
    show_progress: true

  file:
    enabled: false
    level: "DEBUG"
    path: "./logs/"
    filename: "homodyne_analysis.log"
    max_size_mb: 10
    backup_count: 5

  # Module-specific log levels
  modules:
    "homodyne.data.phi_filtering": "INFO"
    "homodyne.data.xpcs_loader": "INFO"
    "homodyne.optimization.nlsq_wrapper": "INFO"
    "jax._src": "WARNING"        # Suppress JAX internal messages

# ==============================================================================
# QUALITY CONTROL (Optional)
# ==============================================================================
# Data validation and analysis quality checks.
quality_control:
  enabled: false

  angle_quality:
    validate_angle_coverage: true
    min_angles_per_range: 1
    check_angle_distribution: true

  multi_angle_validation:
    check_correlation_consistency: true
    validate_angle_dependencies: true
    detect_anomalous_angles: true

# ==============================================================================
# VISUALIZATION
# ==============================================================================
# Plot generation and output settings.
plotting:
  save_plots: true
  show_plots: false
  format: "png"                  # "png" | "pdf" | "svg"
  dpi: 300
  style: "publication"

  # Rendering mode
  preview_mode: false            # false = matplotlib (quality), true = datashader (fast)
  fit_surface: "solver"          # "solver" | "posthoc"

  color_scale:
    mode: "legacy"               # "legacy" | "adaptive"
    pin_legacy_range: true
    percentile_min: 1.0
    percentile_max: 99.0
    fixed_min: 1.0
    fixed_max: 1.5

  datashader:
    canvas_width: 1200
    canvas_height: 1200

  matplotlib:
    interpolation: "bilinear"    # "none" | "bilinear" | "bicubic"
    use_tight_layout: true
    savefig_kwargs:
      bbox_inches: "tight"
      pad_inches: 0.1

  # Plot types to generate
  correlation_function: true     # C1(t) and C2(t1,t2)
  fit_quality: true              # Residuals
  parameter_distributions: true  # MCMC posteriors
  residual_analysis: true
  angle_coverage: true
  angle_correlation: true

# ==============================================================================
# OUTPUT
# ==============================================================================
# Result file configuration.
output:
  directory: "./results"
  base_directory: "./homodyne_results/"

  formats:
    hdf5: true
    json: true
    csv: true

  create_subdirs: true           # Creates nlsq/, mcmc/, cmc/
  timestamp_dirs: false

  compress_hdf5: true
  compression_level: 6           # 0-9, higher = more compression

# ==============================================================================
# VALIDATION (Optional)
# ==============================================================================
# Configuration validation settings.
validation:
  strict_mode: false             # Fail on warnings
  check_file_existence: true
  validate_parameter_ranges: true
  check_mode_compatibility: true

  angle_validation:
    require_multiple_angles: false
    min_angle_count: 1
    validate_angle_ranges: true

# ==============================================================================
# USAGE NOTES & TROUBLESHOOTING
# ==============================================================================
#
# QUICK START WORKFLOW:
# ---------------------
# 1. Copy this template and update experimental_data paths
# 2. Set analysis_mode: "static" or "laminar_flow"
# 3. Run NLSQ: homodyne --config your_config.yaml --method nlsq
# 4. Check output plots for fit quality
# 5. If poor fit, see "GRADIENT IMBALANCE FIX" below
# 6. For publication: Run MCMC with NLSQ results as initial values
#
# GRADIENT IMBALANCE FIX (laminar_flow):
# --------------------------------------
# Symptom: Early convergence, missing C2 oscillations, flat shear parameters
#
# 1. Run: python scripts/diagnose_gradients.py --results-dir ./homodyne_results/nlsq
# 2. Copy recommended x_scale_map from output
# 3. Paste into optimization.nlsq.x_scale_map section
# 4. Re-run NLSQ
#
# CMC CONVERGENCE ISSUES:
# -----------------------
# If shards fail validation (ESS/R-hat):
#   - Increase per_shard_mcmc.num_warmup and num_samples
#   - Tighten phi0 bounds for faster MCMC mixing
#   - Check for multimodal posteriors (may need different priors)
#
# PARAMETER COUNTING:
# -------------------
#   static:       3 physical + 2 × N_angles = 3 + 2N
#   laminar_flow: 7 physical + 2 × N_angles = 7 + 2N
#
# Examples with 3 angles:
#   static:       9 total parameters
#   laminar_flow: 13 total parameters
#
# ANGLE SELECTION GUIDELINES:
# ---------------------------
#   Static mode:
#     - 0° and 180° for anisotropy detection
#     - All angles if isotropic behavior expected
#
#   Laminar flow mode:
#     - 0° (parallel): Maximum shear effects
#     - 90° (perpendicular): Diffusion-dominated signal
#     - Both required for proper shear/diffusion decoupling
#
# DATASET SIZE STRATEGIES:
# ------------------------
#   < 1M points:   STANDARD - fast, simple
#   1M-10M:        LARGE - optimized curve_fit
#   10M-100M:      CHUNKED - progress bar, checkpoints
#   > 100M:        STREAMING - constant memory, fault tolerance
#
# PLATFORM REQUIREMENTS:
# --------------------------------
#   - Python 3.12+
#   - JAX 0.8.0 / jaxlib 0.8.0 (CPU-only)
#   - NumPy 2.x
#   - GPU support removed
#
# CONFIGURATION VALIDATION:
# -------------------------
#   homodyne-config --validate your_config.yaml
#   python -m homodyne.runtime.utils.system_validator --quick
#
# ==============================================================================
# END OF MASTER TEMPLATE
# ==============================================================================
