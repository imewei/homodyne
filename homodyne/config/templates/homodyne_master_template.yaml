# ==============================================================================
# HOMODYNE MASTER CONFIGURATION TEMPLATE
# ==============================================================================
# Complete, maintained reference template for all homodyne configuration knobs.
# Covers static and laminar_flow analysis, Nonlinear Least Squares (NLSQ)
# optimization, and Consensus Monte Carlo (CMC).
#
# HOW TO USE THIS TEMPLATE:
# -------------------------
# 1. Copy this file and rename for your experiment (e.g., my_analysis.yaml)
# 2. Update experimental_data paths to your HDF5 file and phi angles
# 3. Set analysis_mode: "static" or "laminar_flow"
# 4. Adjust phi_filtering.target_ranges for your scattering geometry
# 5. Run NLSQ first: homodyne --config your_config.yaml --method nlsq
# 6. For MCMC: Copy NLSQ results to initial_parameters, then run with --method mcmc
#
# For production use, consider starting with the focused templates:
#   - homodyne_static.yaml: 3-parameter equilibrium diffusion
#   - homodyne_laminar_flow.yaml: 7-parameter shear flow
#
# VERSION: 2.18.0
# UPDATED: 2026-01-18
# ==============================================================================

# ==============================================================================
# METADATA (Documentation Only)
# ==============================================================================
# Template metadata for documentation and validation.
# The config_version should match the homodyne package version.
metadata:
  config_version: "2.18.0"
  description: "Master template - comprehensive reference with all configuration options"
  analysis_mode: "laminar_flow"

  # Parameter count summary (physical parameters only, excludes per-angle scaling)
  #   static:       3 params [D₀, α, D_offset]
  #   laminar_flow: 7 params [D₀, α, D_offset, γ̇₀, β, γ̇_offset, φ₀]
  #   Total with scaling: physical + 2 × N_angles
  parameter_count: 7

  # Physics model equations
  physics_model: "D(t) = D₀·t^α + D_offset"
  shear_model: "γ̇(t) = γ̇₀·t^β + γ̇_offset"

  # Numerical methods
  integration_method: "discrete_numerical"
  diagonal_correction: "mandatory"
  nlsq_cmc_physics_match: true

  # Template classification
  template_type: "reference"
  complexity: "comprehensive"

  # Auto-filled by CLI tools
  generated_at: null
  generated_by: null

# ==============================================================================
# ANALYSIS MODE (Required)
# ==============================================================================
# Determines which physical model to use.
#
# Options:
#   "static"       - Equilibrium diffusion only (3 physical parameters)
#                    Use for: pure diffusion, aging/jamming studies
#   "laminar_flow" - Diffusion + shear flow (7 physical parameters)
#                    Use for: rheology, Taylor-Couette flow, shear cells
#
analysis_mode: "laminar_flow"

# ==============================================================================
# ANALYZER PARAMETERS (Required)
# ==============================================================================
# Core experimental parameters. These MUST match your measurement setup.
#
# CRITICAL: Incorrect dt will shift all fitted parameters!
#   - Check your detector frame rate
#   - dt = 1 / (frames per second)
#
analyzer_parameters:
  # Time step between correlation measurements [seconds]
  # Common values: 0.001 (1 kHz), 0.01 (100 Hz), 0.1 (10 Hz)
  # CONSTRAINT: Must be > 0
  dt: 0.001

  # Frame range for analysis (1-indexed, inclusive)
  # Use to exclude startup transients or unstable regions
  # CONSTRAINTS: start_frame >= 1, end_frame > start_frame
  start_frame: 1
  end_frame: 2000

  # Scattering geometry
  scattering:
    # Wave vector magnitude [Å⁻¹]
    # Typically 0.001-0.1 for XPCS; get from beamline/sample geometry
    # CONSTRAINT: Must be > 0
    wavevector_q: 0.0054

  # Shear cell geometry (laminar_flow mode)
  geometry:
    # Stator-rotor gap [Å]
    # 200 microns = 2,000,000 Å; 100 microns = 1,000,000 Å
    # CONSTRAINT: Must be > 0
    stator_rotor_gap: 2000000

# ==============================================================================
# ANALYSIS SETTINGS (Optional - Documentation)
# ==============================================================================
# Mode-specific settings and model description.
analysis_settings:
  model_description:
    type: "nonequilibrium_laminar_flow"
    parameters: 7
    physics: "Time-dependent diffusion with shear; C2 diagonal correction enforced"

# ==============================================================================
# EXPERIMENTAL DATA (Required)
# ==============================================================================
# Paths to your data files. Both absolute and relative paths are supported.
# Relative paths are resolved from the config file's directory.
#
# DATA FORMAT: HDF5 with exchange group structure
#   /exchange/data      - 3D array (frames, y, x)
#   /exchange/...       - Additional metadata
#
experimental_data:
  # Primary data file (preferred format)
  file_path: "./data/sample/experiment.hdf"

  # Legacy composite path (auto-normalized to file_path internally)
  data_folder_path: "./data/sample/"
  data_file_name: "experiment.hdf"

  # Phi angles file: one angle (degrees) per line, range [-180, 180]
  phi_angles_path: "./data/sample/"
  phi_angles_file: "phi_angles_list.txt"

  # Caching (processed C2 data, speeds up re-runs)
  cache_file_path: "./data/sample/"
  cache_filename_template: "cached_c2_q{wavevector_q:.4f}_frames_{start_frame}_{end_frame}.npz"
  cache_compression: true

  # Data format specifications
  data_type: "float64"     # "float32" or "float64" (recommended)
  file_format: "HDF5"      # Only HDF5 supported
  exchange_key: "exchange" # HDF5 exchange group key

# ==============================================================================
# PHI ANGLE FILTERING
# ==============================================================================
# Select which scattering angles to include in analysis.
#
# WHY FILTER ANGLES?
#   - Reduces number of per-angle scaling parameters
#   - Focuses on angles with strongest signal
#   - For laminar flow: 0° (parallel) and 90° (perpendicular) capture flow effects
#   - For static: 0° and 180° detect anisotropy
#
# ANGLE CONVENTION:
#   - Angles in degrees, range [-180, 180]
#   - Wrap-aware: [170, -170] captures angles from 170° through 180° to -170°
#
phi_filtering:
  enabled: true

  # Target angle ranges to include
  target_ranges:
    - min_angle: -10.0
      max_angle: 10.0
      description: "Parallel to flow / primary axis"
    - min_angle: 85.0
      max_angle: 95.0
      description: "Perpendicular to flow"
    # Uncomment for additional angles:
    # - min_angle: -95.0
    #   max_angle: -85.0
    #   description: "Perpendicular (opposite side)"
    # - min_angle: 170.0
    #   max_angle: -170.0
    #   description: "Antiparallel"

  # If no angles match target_ranges, use all available angles
  fallback_to_all_angles: true

  # Filtering algorithm settings
  algorithm: "range_based"
  tolerance: 3.0           # Degrees; angles within tolerance of range edges included

  # Quality control
  quality_control:
    min_angles_required: 1          # Minimum angles needed (≥2 recommended for flow)
    max_angle_spread: 36.0          # Maximum spread within each range
    validate_coverage: true         # Warn if ranges are poorly covered
    require_orthogonal_angles: true # Recommended for laminar_flow (0°/90°)

# ==============================================================================
# INITIAL PARAMETERS (Required)
# ==============================================================================
# Starting values for optimization.
#
# PARAMETER COUNT:
#   Total = physical + 2 × N_angles (per-angle contrast + offset)
#   static:       3 + 2N (e.g., 3 angles → 9 parameters)
#   laminar_flow: 7 + 2N (e.g., 3 angles → 13 parameters)
#
# WORKFLOW (NLSQ → MCMC):
#   1. Run NLSQ first with values: null (uses mid-bounds)
#   2. Copy fitted parameters from NLSQ output
#   3. Paste into values: [...] for MCMC initialization
#   4. Run MCMC with good starting point
#
# PER-ANGLE SCALING:
#   MANDATORY - each angle has unique contrast/offset
#   Legacy scalar mode removed; per_angle_scaling=False raises ValueError
#
initial_parameters:
  # Physical parameter names (order matters for values list)
  parameter_names:
    - D0                   # Diffusion prefactor [Å²/s]
    - alpha                # Anomalous exponent [dimensionless]
    - D_offset             # Baseline diffusion [Å²/s]
    - gamma_dot_t0         # Shear rate prefactor [s⁻¹] (laminar_flow only)
    - beta                 # Shear exponent [dimensionless] (laminar_flow only)
    - gamma_dot_t_offset   # Baseline shear [s⁻¹] (laminar_flow only)
    - phi0                 # Flow angle offset [degrees] (laminar_flow only)

  # Initial values: list matching parameter_names order, or null for mid-bounds
  # Static example:       [1000.0, 0.5, 10.0]
  # Laminar flow example: [1000.0, 0.5, 10.0, 0.01, 0.0, 0.0, 0.0]
  values: null

  # Per-angle scaling initialization (one value per filtered angle)
  # v2.17.0+: When null, uses quantile-based initialization to compute robust
  # initial values from experimental data using quantile statistics
  # Estimate from data: contrast ≈ (C2_max - C2_min), offset ≈ C2_min
  per_angle_scaling:
    contrast: null  # null = quantile-based init, or [0.05, 0.06, 0.05] for 3 angles
    offset: null    # null = quantile-based init, or [1.0, 0.99, 1.01] for 3 angles

  # Units for documentation (not used by optimizer)
  units:
    - "Å²/s"
    - "dimensionless"
    - "Å²/s"
    - "s⁻¹"
    - "dimensionless"
    - "s⁻¹"
    - "degrees"

  # Optional: Optimize only a subset of parameters
  active_parameters: null  # e.g., ["D0", "alpha", "gamma_dot_t0"]

  # Optional: Fix parameters at specific values
  fixed_parameters: null   # e.g., {"beta": 0.0, "gamma_dot_t_offset": 0.0}

# ==============================================================================
# PARAMETER SPACE (Required)
# ==============================================================================
# Parameter bounds and prior distributions.
#
# DEFAULT BOUNDS (from homodyne.core.fitting.ParameterSpace):
# -----------------------------------------------------------
# | Parameter          | Default Bounds      | Notes                          |
# |--------------------|---------------------|--------------------------------|
# | contrast           | (0.0, 1.0)          | Physical: visibility/coherence |
# | offset             | (0.5, 1.5)          | Baseline around 1.0 ± 50%      |
# | D0                 | (1.0, 1,000,000)    | Diffusion coefficient          |
# | alpha              | (-2.0, 2.0)         | Anomalous diffusion exponent   |
# | D_offset           | (-100,000, 100,000) | Diffusion baseline correction  |
# | gamma_dot_t0       | (1e-5, 1.0)         | Shear rate                     |
# | beta               | (-2.0, 2.0)         | Shear exponent                 |
# | gamma_dot_t_offset | (-1.0, 1.0)         | Shear baseline correction      |
# | phi0               | (-30.0, 30.0)       | Flow direction angle [degrees] |
#
# BOUNDS GUIDELINES:
#   - Too narrow: May miss true optimum
#   - Too wide: Slow convergence, numerical issues
#   - Start with template bounds, tighten for MCMC if posteriors wander
#
# PRIOR DISTRIBUTIONS:
#   - type: "TruncatedNormal" - Bounded Gaussian (recommended)
#   - prior_mu/prior_sigma: Used only by MCMC/CMC
#
parameter_space:
  model: "laminar_flow"

  bounds:
    # -------------------------------------------------------------------------
    # SCALING PARAMETERS (applied per angle)
    # -------------------------------------------------------------------------
    - name: contrast
      min: 0.0                       # Physical minimum (no negative contrast)
      max: 1.0                       # Physical maximum (fully coherent)
      type: TruncatedNormal
      # CONSTRAINT: max <= 1.0 (physical limit)
      # Typical XPCS values: 0.01-0.2

    - name: offset
      min: 0.5                       # Baseline should be near 1.0
      max: 1.5                       # Allow some variation
      type: TruncatedNormal
      # Typical XPCS values: 0.9-1.1

    # -------------------------------------------------------------------------
    # DIFFUSION PARAMETERS (all modes)
    # -------------------------------------------------------------------------
    - name: D0
      min: 100.0                     # Minimum diffusion [Å²/s]
      max: 100000.0                  # Maximum diffusion [Å²/s]
      type: TruncatedNormal
      prior_mu: 1000.0               # Prior mean for MCMC
      prior_sigma: 1000.0            # Prior std for MCMC
      unit: "Å²/s"
      # Physical meaning: Diffusion coefficient magnitude
      # D(t) = D₀·t^α + D_offset

    - name: alpha
      min: -2.0                      # Strong subdiffusion
      max: 2.0                       # Strong superdiffusion
      type: TruncatedNormal
      prior_mu: -1.2                 # Prior mean (subdiffusive default)
      prior_sigma: 0.3               # Prior std
      unit: "dimensionless"
      # Physical meaning: Anomalous diffusion exponent
      #   α < 0: Subdiffusion (crowded, jammed systems)
      #   α = 0: Normal diffusion
      #   α > 0: Superdiffusion (shear-enhanced, active systems)

    - name: D_offset
      min: -100000.0                 # Allow negative (rare but possible)
      max: 100000.0                  # Wide range for exploratory fits
      type: TruncatedNormal
      prior_mu: 0.0
      prior_sigma: 150.0
      unit: "Å²/s"
      # Physical meaning: Constant diffusion baseline
      # Negative values may indicate arrested dynamics

    # -------------------------------------------------------------------------
    # FLOW PARAMETERS (laminar_flow mode only)
    # -------------------------------------------------------------------------
    - name: gamma_dot_t0
      min: 1.0e-6                    # Near-zero shear
      max: 0.5                       # High shear rate
      type: TruncatedNormal
      prior_mu: 0.01
      prior_sigma: 0.1
      unit: "s⁻¹"
      # Physical meaning: Shear rate magnitude
      # γ̇(t) = γ̇₀·t^β + γ̇_offset

    - name: beta
      min: -2.0                      # Decreasing shear
      max: 2.0                       # Increasing shear
      type: TruncatedNormal
      prior_mu: 0.0                  # Default: constant shear
      prior_sigma: 0.5
      unit: "dimensionless"
      # Physical meaning: Shear rate time evolution
      #   β = 0: Constant shear
      #   β > 0: Shear increases with time
      #   β < 0: Shear decreases with time

    - name: gamma_dot_t_offset
      min: -0.1
      max: 0.1
      type: TruncatedNormal
      prior_mu: 0.0
      prior_sigma: 0.02
      unit: "s⁻¹"
      # Physical meaning: Baseline shear rate offset

    - name: phi0
      min: -10.0                     # Tight bounds help MCMC convergence
      max: 10.0                      # Widen if flow misalignment suspected
      type: TruncatedNormal
      prior_mu: 0.0
      prior_sigma: 5.0
      unit: "degrees"
      # Physical meaning: Flow direction angle offset
      # Accounts for misalignment between flow and detector axes

  # Advanced prior specifications (rarely needed)
  priors: null

# ==============================================================================
# OPTIMIZATION (NLSQ + CMC)
# ==============================================================================
# Optimization method selection and configuration.
#
# RECOMMENDED WORKFLOW:
#   1. Run NLSQ first (fast, deterministic)
#   2. Inspect residuals and fitted C2 heatmaps
#   3. If poor fit, check x_scale_map or enable CMA-ES for multi-scale problems
#   4. Copy best-fit to initial_parameters
#   5. Run MCMC for uncertainty quantification
#
# METHOD SELECTION:
#   "nlsq" - Nonlinear least squares (seconds to minutes)
#   "mcmc" - Markov Chain Monte Carlo via CMC (minutes to hours)
#   "cmc"  - Same as "mcmc" (CMC is the only MCMC path)
#
optimization:
  method: "nlsq"

  # ===========================================================================
  # NLSQ - Trust-Region Nonlinear Least Squares
  # ===========================================================================
  # Fast, deterministic point estimation using Levenberg-Marquardt.
  # CPU-optimized with JAX JIT compilation.
  #
  # STRATEGY SELECTION (automatic based on dataset size AND memory):
  # ----------------------------------------------------------------
  # | Dataset Size   | Strategy   | Description                     |
  # |----------------|------------|---------------------------------|
  # | < 1M points    | STANDARD   | Direct curve_fit                |
  # | 1M-10M points  | LARGE      | Optimized curve_fit_large       |
  # | 10M-100M pts   | CHUNKED    | Progress bar, memory-bounded    |
  # | > 100M points  | STREAMING  | Checkpoint/resume, fault-tolerant|
  #
  # Memory override: If estimated memory > threshold, uses streaming regardless
  # of dataset size. Estimate = Jacobian (n × p × 8) × 6.5 overhead factor.
  #
  nlsq:
    # -------------------------------------------------------------------------
    # MEMORY CONFIGURATION
    # -------------------------------------------------------------------------
    # Choose ONE of:
    #   memory_fraction: Use percentage of available RAM (adaptive)
    #   memory_threshold_gb: Use explicit threshold in GB (fixed)
    #
    # Environment variable override: NLSQ_MEMORY_FRACTION (0.1-0.9)
    memory_fraction: 0.75           # Use 75% of available RAM
    # memory_threshold_gb: 48.0     # OR: explicit 48 GB threshold

    # -------------------------------------------------------------------------
    # CONVERGENCE SETTINGS
    # -------------------------------------------------------------------------
    max_iterations: 100             # Increase to 200-300 if convergence slow
                                    # CONSTRAINT: > 0

    # Tolerance settings (all must be > 0)
    tolerance: 1.0e-8               # Function tolerance (ftol)
    xtol: 1.0e-8                    # Parameter tolerance
    gtol: 1.0e-8                    # Gradient tolerance

    trust_region_scale: 1.0         # Scale factor for trust region
                                    # CONSTRAINT: > 0

    verbose: false                  # Enable verbose optimizer output

    # -------------------------------------------------------------------------
    # LOSS FUNCTION
    # -------------------------------------------------------------------------
    # Controls how outliers affect the fit. All loss functions are JAX JIT-compiled.
    #
    # Options:
    #   "linear"  - Standard least squares: ρ(z) = z
    #               No outlier protection; fastest; optimal for clean data
    #
    #   "huber"   - Huber loss: ρ(z) = z if z ≤ 1, else 2√z - 1
    #               Quadratic for small residuals, linear for large
    #               Good balance between efficiency and robustness
    #
    #   "soft_l1" - Soft L1 loss: ρ(z) = 2(√(1+z) - 1)
    #               Smooth approximation to L1 norm
    #               RECOMMENDED DEFAULT for XPCS data
    #
    #   "cauchy"  - Cauchy/Lorentzian: ρ(z) = ln(1 + z)
    #               Extremely robust; handles heavy-tailed errors
    #               May converge slowly
    #
    #   "arctan"  - Arctangent: ρ(z) = arctan(z)
    #               Bounded loss; very robust to extreme outliers
    #               May converge slowly
    #
    # SELECTION GUIDE:
    # ----------------
    # | Data Quality              | Recommended Loss |
    # |---------------------------|------------------|
    # | Clean, well-characterized | "linear"         |
    # | Typical XPCS data         | "soft_l1"        |
    # | Few outliers/artifacts    | "huber"          |
    # | Severe contamination      | "cauchy"         |
    #
    loss: "soft_l1"

    # -------------------------------------------------------------------------
    # PARAMETER SCALING (x_scale_map)
    # -------------------------------------------------------------------------
    # Fixes gradient imbalance: shear gradients can be 1000-10,000× larger
    # than diffusion gradients, causing premature convergence.
    #
    # SYMPTOM: Early convergence, flat shear params, missing C2 oscillations
    #
    # DIAGNOSIS: Run diagnose_gradients.py to compute dataset-specific values
    #   python scripts/diagnose_gradients.py --results-dir ./homodyne_results/nlsq
    #
    # Values below are example from C020 dataset (Nov 2025).
    # Compute your own dataset-specific values using diagnose_gradients.py
    #
    # Set to null to use automatic Jacobian-based scaling ("jac")
    x_scale_map: null
    # x_scale_map:
    #   D0: 1.20
    #   alpha: 0.000761
    #   D_offset: 1.13
    #   gamma_dot_t0: 0.00000371
    #   beta: 0.000314
    #   gamma_dot_t_offset: 0.0000000930
    #   phi0: 0.739

    # -------------------------------------------------------------------------
    # PROGRESS AND LOGGING
    # -------------------------------------------------------------------------
    progress:
      enable: true                  # Show tqdm progress bar during fitting
      verbose: 1                    # 0=quiet, 1=milestones, 2=detailed
      log_interval: 10              # Log every N iterations (for verbose >= 2)

    # -------------------------------------------------------------------------
    # DIAGNOSTICS
    # -------------------------------------------------------------------------
    diagnostics:
      enabled: false                # Compute diagnostics (Jacobian stats, etc.)
      sample_size: 2048             # Sample size for gradient checking
      check_gradients: true         # Verify gradients numerically
      log_jacobian_norms: false     # Log Jacobian norm per iteration

    # -------------------------------------------------------------------------
    # HYBRID STREAMING OPTIMIZER (v2.6.0+)
    # -------------------------------------------------------------------------
    # Four-phase optimizer for large datasets (>10M points):
    #   Phase 0: Parameter normalization setup
    #   Phase 1: L-BFGS warmup with adaptive switching
    #   Phase 2: Streaming Gauss-Newton (quadratic convergence)
    #   Phase 3: Denormalization and covariance transform
    #
    # Memory: Bounded at ~2 GB regardless of dataset size
    # Expected: ~10x fewer iterations (110 vs 1000+)
    #
    hybrid_streaming:
      enable: true                  # Enable for large datasets

      # Normalization settings
      normalize: true               # Enable parameter normalization
      normalization_strategy: "auto" # "auto" | "bounds" | "p0" | "none"
                                    #   auto: selects based on problem characteristics
                                    #   bounds: normalize to [0,1] using bounds
                                    #   p0: normalize relative to initial guess
                                    #   none: no normalization

      # L-BFGS warmup (Phase 1)
      warmup_iterations: 200        # L-BFGS iterations before switch check
                                    # CONSTRAINT: > 0
      max_warmup_iterations: 500    # Force switch to Gauss-Newton after this
                                    # CONSTRAINT: > 0
      warmup_learning_rate: 0.001   # L-BFGS line search scale
                                    # CONSTRAINT: > 0

      # Gauss-Newton refinement (Phase 2)
      gauss_newton_max_iterations: 100  # Max Gauss-Newton iterations
      gauss_newton_tol: 1.0e-8          # Convergence tolerance

      # Streaming settings
      chunk_size: 10000             # Points per chunk for streaming J^T J
                                    # CONSTRAINT: > 0
      trust_region_initial: 1.0     # Initial trust region size
      regularization_factor: 1.0e-10 # Tikhonov regularization for J^T J

      # Checkpointing
      enable_checkpoints: true      # Enable checkpoint save/resume
      checkpoint_frequency: 100     # Checkpoint every N iterations
      validate_numerics: true       # Validate NaN/Inf detection

      # Verbosity
      verbose: 1                    # 0=silent, 1=progress, 2=debug
      log_frequency: 1              # Log every N iterations

      # ---------------------------------------------------------------------
      # 4-LAYER DEFENSE STRATEGY (NLSQ 0.3.6+)
      # ---------------------------------------------------------------------
      # Prevents L-BFGS warmup from diverging when starting from good
      # parameters. All layers ENABLED BY DEFAULT.
      #
      # Layer 1: Warm Start Detection
      # Skip warmup entirely if already at good solution
      enable_warm_start_detection: true
      warm_start_threshold: 0.01    # Skip warmup if loss/variance < this
                                    # CONSTRAINT: > 0

      # Layer 2: Adaptive Learning Rate
      # Scale LR based on initial loss quality
      enable_adaptive_warmup_lr: true
      warmup_lr_refinement: 1.0e-6  # LR for good starts (rel_loss < 0.1)
                                    # CONSTRAINT: > 0
      warmup_lr_careful: 1.0e-5     # LR for moderate starts (rel_loss < 1.0)
                                    # CONSTRAINT: > 0

      # Layer 3: Cost-Increase Guard
      # Abort warmup if loss increases significantly
      enable_cost_guard: true
      cost_increase_tolerance: 0.05 # Abort if loss increases >5%
                                    # CONSTRAINT: (0, 1)

      # Layer 4: Step Clipping
      # Limit max parameter change per iteration
      enable_step_clipping: true
      max_warmup_step_size: 0.1     # Max step (fraction of normalized range)
                                    # CONSTRAINT: > 0

    # -------------------------------------------------------------------------
    # ANTI-DEGENERACY DEFENSE SYSTEM (v2.9.0+)
    # -------------------------------------------------------------------------
    # Comprehensive solution for structural degeneracy in laminar_flow mode
    # with many phi angles.
    #
    # ROOT CAUSES ADDRESSED:
    #   1. Gradient Cancellation: Shear gradient changes sign across angles
    #   2. Structural Degeneracy: Per-angle params absorb physical signals
    #   3. Ineffective Regularization: Previous λ was too weak
    #
    # CRITICAL: hierarchical.enable MUST be true for shear_weighting to work!
    #
    # For static mode: Can disable (enable: false) as no shear parameters
    #
    anti_degeneracy:
      enable: true                  # Master enable

      # -----------------------------------------------------------------------
      # PER-ANGLE SCALING MODE (v2.18.0+)
      # -----------------------------------------------------------------------
      # Controls dimensionality reduction for per-angle contrast/offset.
      # Same logic as CMC per-angle mode (except NLSQ also has "fourier").
      #
      # MODES:
      #   "auto" (RECOMMENDED): Auto-selects based on n_phi threshold.
      #     When n_phi >= threshold: Estimates per-angle values from quantile
      #     analysis, AVERAGES them to single value, broadcasts to all angles.
      #     Results in 9-param optimization (7 physical + 2 averaged scaling).
      #
      #   "constant": Per-angle values from quantile estimation, used DIRECTLY.
      #     Different fixed value per angle (NOT averaged, NOT optimized).
      #     Results in physical-only optimization (7 params).
      #
      #   "fourier": Fourier basis for smooth angle variation (NLSQ only).
      #     Configured via fourier.order and fourier.min_phi_for_fourier.
      #
      #   "individual": Independent per-angle params, optimized during fitting.
      #     Prone to absorption with many angles. Use with caution.
      #     Results in 7 + 2*N_phi parameters for laminar_flow.
      #
      # PARAMETER COUNT (laminar_flow, n_phi=23):
      #   - auto (n_phi >= 3): 9 params (7 physical + 2 averaged scaling)
      #   - constant:          7 params (physical only, scaling fixed)
      #   - fourier:          17 params (7 physical + 10 Fourier coeffs, order=2)
      #   - individual:       53 params (7 physical + 46 per-angle scaling)
      #
      per_angle_mode: "auto"
      constant_scaling_threshold: 3 # Use constant when n_phi >= this
                                    # CONSTRAINT: >= 1

      # Fourier reparameterization (Layer 1 - legacy, rarely needed)
      fourier:
        order: 2                    # Number of Fourier harmonics
                                    # CONSTRAINT: >= 1
        min_phi_for_fourier: 6      # Min angles for Fourier mode
                                    # CONSTRAINT: >= 1
        regularize_high_order: false # Regularize high-order Fourier terms

      # Hierarchical Optimization (Layer 2)
      # Alternates between physical and per-angle params
      # REQUIRED for shear_weighting to function!
      hierarchical:
        enable: true                # CRITICAL: Must be true for shear_weighting
        max_outer_iterations: 5     # Outer loop iterations
                                    # CONSTRAINT: > 0
        outer_tolerance: 1.0e-6     # Convergence tolerance
                                    # CONSTRAINT: > 0
        physical_max_iterations: 100 # Max iterations for physical params
                                    # CONSTRAINT: > 0
        per_angle_max_iterations: 50 # Max iterations for per-angle params
                                    # CONSTRAINT: > 0

      # Adaptive Regularization (Layer 3)
      # CV-based regularization that scales properly with data
      regularization:
        enable: false               # Enable CV-based regularization
        mode: "relative"            # "absolute" | "relative" | "auto"
        lambda: 1.0                 # Base regularization strength (100× v2.8)
                                    # CONSTRAINT: > 0
        target_cv: 0.10             # Target 10% coefficient of variation
                                    # CONSTRAINT: (0, 1)
        target_contribution: 0.10   # Target 10% of MSE contribution
                                    # CONSTRAINT: (0, 1)
        max_cv: 0.20                # Maximum allowed CV
                                    # CONSTRAINT: (0, 1)
        auto_tune_lambda: true      # Auto-tune lambda during optimization

      # Gradient Collapse Detection (Layer 4)
      gradient_monitoring:
        enable: true                # Enable gradient monitoring
        ratio_threshold: 0.01       # Trigger if |∇_physical|/|∇_scaling| < 0.01
                                    # CONSTRAINT: > 0
        consecutive_triggers: 5     # Must trigger N times consecutively
                                    # CONSTRAINT: > 0
        response: "hierarchical"    # Response to gradient collapse
                                    # Options: "warn", "hierarchical", "reset", "abort"

      # Shear-Sensitivity Weighting (Layer 5)
      # Weights residuals by |cos(φ₀-φ)| to prevent gradient cancellation
      # CRITICAL: Requires hierarchical.enable: true to function!
      shear_weighting:
        enable: true                # Enable for laminar_flow with n_phi > 3
        alpha: 1.0                  # Sensitivity exponent (1.0 = linear)
        min_weight: 0.3             # Minimum weight for perpendicular angles
        update_frequency: 50        # Update weights every N L-BFGS iterations
                                    # CONSTRAINT: > 0
        normalize: true             # Normalize weights so mean = 1.0

    # -------------------------------------------------------------------------
    # MULTI-START OPTIMIZATION (v2.6.0+)
    # -------------------------------------------------------------------------
    # Explores parameter space from multiple starting points using Latin
    # Hypercube Sampling (LHS) to find global optimum and detect degeneracy.
    #
    # NOTE: DISABLED when CMA-ES is enabled - CMA-ES provides better global
    # optimization through population-based search with covariance adaptation.
    # Enable multi_start only when NOT using CMA-ES.
    #
    # STRATEGY: FULL only (no subsampling per project requirements)
    # Numerical precision and reproducibility take priority over speed.
    #
    # EXECUTION MODE (auto-selected):
    #   < 500K points: Parallel (ProcessPoolExecutor)
    #   ≥ 500K points: Sequential (avoid serialization overhead)
    #
    multi_start:
      enable: false                 # DISABLED when CMA-ES is enabled
      n_starts: 10                  # Number of LHS starting points
                                    # CONSTRAINT: > 0
      seed: 42                      # Random seed for reproducibility
      sampling_strategy: "latin_hypercube"  # "latin_hypercube" | "random"
      n_workers: 0                  # Parallel workers (0 = auto)
                                    # CONSTRAINT: >= 0

      # Screening phase
      use_screening: true           # Pre-filter poor starting points
      screen_keep_fraction: 0.5     # Keep top 50% after screening
                                    # CONSTRAINT: (0, 1]

      # Refinement phase
      refine_top_k: 3               # Refine top K solutions
                                    # CONSTRAINT: >= 0
      refinement_ftol: 1.0e-12      # Tighter tolerance for refinement
                                    # CONSTRAINT: > 0

      # Degeneracy detection
      degeneracy_threshold: 0.1     # Flag if chi² within 10%
                                    # CONSTRAINT: (0, 1)

    # -------------------------------------------------------------------------
    # CMA-ES GLOBAL OPTIMIZATION (v2.15.0+ / NLSQ 0.6.4+)
    # -------------------------------------------------------------------------
    # Covariance Matrix Adaptation Evolution Strategy for global optimization.
    #
    # WHEN TO USE CMA-ES:
    #   - laminar_flow mode with vastly different parameter scales
    #     (e.g., D₀ ~ 1e4 vs γ̇₀ ~ 1e-3, scale ratio > 1e7)
    #   - When multi-start local optimization finds inconsistent minima
    #   - Auto-selected when scale_ratio > scale_threshold (if auto_select=true)
    #
    # REQUIRES: pip install nlsq[evosax]
    #
    # TWO-PHASE ARCHITECTURE:
    #   Phase 1: CMA-ES Global Search
    #     - Population-based exploration with BIPOP restarts
    #     - Covariance matrix adapts to parameter scales
    #     - Memory batching for large datasets (100M+ points)
    #
    #   Phase 2: NLSQ TRF Refinement (optional, enabled by default)
    #     - Local refinement from CMA-ES solution
    #     - Tighter tolerances (1e-10) for precision
    #
    cmaes:
      enable: false                 # Enable CMA-ES global optimization

      # Presets (shorthand for common configurations)
      #   "cmaes-fast": 50 generations (quick exploration)
      #   "cmaes": 100 generations (balanced)
      #   "cmaes-global": 200 generations (thorough global search - RECOMMENDED)
      preset: "cmaes-global"

      # CMA-ES global search settings
      max_generations: 300          # Maximum CMA-ES generations
                                    # CONSTRAINT: > 0
      sigma: 0.5                    # Initial step size (fraction of range)
                                    # CONSTRAINT: (0, 1]
      popsize: 40                   # Population size (default ~4+3*ln(n_params))
                                    # 40 recommended for 13-param laminar_flow
      tol_fun: 1.0e-8               # Function value tolerance
                                    # CONSTRAINT: > 0
      tol_x: 1.0e-8                 # Parameter tolerance
                                    # CONSTRAINT: > 0

      # Restart strategy
      restart_strategy: "bipop"     # "none" | "bipop"
                                    # bipop: alternates large/small populations
      max_restarts: 20              # Maximum BIPOP restarts
                                    # CONSTRAINT: >= 0

      # Memory management (null = auto-configure)
      population_batch_size: null   # Batch size for population evaluation
      data_chunk_size: null         # Chunk size for data streaming
      memory_limit_gb: 8.0          # Memory limit for auto-configuration
                                    # CONSTRAINT: > 0

      # Auto-selection based on scale ratio
      auto_select: true             # Auto-select CMA-ES vs multi-start
      scale_threshold: 1000.0       # Scale ratio threshold for auto-selection
                                    # CONSTRAINT: > 0

      # Post-CMA-ES NLSQ TRF refinement
      refine_with_nlsq: true        # Refine CMA-ES solution with L-M
      refinement_workflow: "auto"   # "auto" | "standard" | "streaming"
      refinement_ftol: 1.0e-10      # Function tolerance for refinement
                                    # CONSTRAINT: > 0
      refinement_xtol: 1.0e-10      # Parameter tolerance for refinement
                                    # CONSTRAINT: > 0
      refinement_gtol: 1.0e-10      # Gradient tolerance for refinement
                                    # CONSTRAINT: > 0
      refinement_max_nfev: 500      # Max function evaluations for refinement
                                    # CONSTRAINT: > 0
      refinement_loss: "linear"     # Loss for refinement
                                    # Options: "linear", "soft_l1", "huber", etc.

  # ===========================================================================
  # STREAMING CHECKPOINT/RESUME (>100M points)
  # ===========================================================================
  # Maintains constant memory footprint with fault tolerance.
  # Automatically activated when dataset exceeds streaming threshold.
  #
  streaming:
    enable_checkpoints: true        # Enable checkpoint save/resume
    checkpoint_dir: "./checkpoints" # Checkpoint directory
    checkpoint_frequency: 10        # Save every N batches
    resume_from_checkpoint: true    # Auto-resume from checkpoint
    keep_last_checkpoints: 3        # Keep N recent checkpoints
    enable_fault_tolerance: true    # Enable fault tolerance
    max_retries_per_batch: 2        # Retry attempts per batch
    min_success_rate: 0.5           # Fail if success < 50%
    batch_size: null                # Batch size (null = auto-detect)
    adaptive_batching: true         # Adapt batch size dynamically

  # ===========================================================================
  # STRATIFICATION (Angle-Stratified Chunking)
  # ===========================================================================
  # Fixes per-angle scaling compatibility with NLSQ chunking.
  # Reorganizes data so every chunk contains all phi angles.
  #
  # PROBLEM SOLVED: Without stratification, arbitrary chunking can create
  # chunks missing certain angles → zero gradients → silent failures.
  #
  stratification:
    enabled: "auto"                 # "auto" | true | false
    target_chunk_size: 100000       # Target points per chunk
                                    # CONSTRAINT: > 0
    max_imbalance_ratio: 5.0        # Fall back to sequential if exceeded
                                    # CONSTRAINT: > 0
    force_sequential_fallback: false # Force per-angle optimization
    check_memory_safety: true       # Check available memory
    use_index_based: false          # Zero-copy stratification
    collect_diagnostics: false      # Collect diagnostics
    log_diagnostics: false          # Log diagnostics

  # ===========================================================================
  # SEQUENTIAL (Per-Angle Optimization Fallback)
  # ===========================================================================
  # Used when stratification cannot be applied (extreme angle imbalance).
  # Optimizes each angle independently, then combines with weighted averaging.
  #
  sequential:
    min_success_rate: 0.5           # Fail if <50% angles converge
                                    # CONSTRAINT: [0, 1]
    weighting: "inverse_variance"   # "inverse_variance" | "uniform" | "n_points"

  # ===========================================================================
  # RECOVERY SETTINGS
  # ===========================================================================
  # Automatic error recovery with progressively conservative settings.
  #
  recovery:
    enable: true                    # Enable automatic recovery
    max_attempts: 3                 # Maximum recovery attempts
                                    # CONSTRAINT: >= 0
    lr_decay: 0.5                   # Learning rate multiplier per retry
    lambda_growth: 2.0              # Regularization multiplier per retry
    trust_decay: 0.5                # Trust region multiplier per retry
    log_retries: true               # Log retry attempts

  # ===========================================================================
  # MCMC - Base MCMC Configuration
  # ===========================================================================
  # Base configuration for NumPyro/BlackJAX NUTS sampler.
  # Used by CMC shards; can be overridden in cmc.per_shard_mcmc.
  #
  mcmc:
    backend: "numpyro"              # "numpyro" | "blackjax"
    num_warmup: 1000                # Warmup samples per chain
                                    # CONSTRAINT: > 0
    num_samples: 3000               # Posterior samples per chain
                                    # CONSTRAINT: > 0
    num_chains: 4                   # Number of chains (≥2 for R-hat)
                                    # CONSTRAINT: > 0
    progress_bar: true              # Show progress bar
    target_accept_prob: 0.90        # NUTS target acceptance
                                    # CONSTRAINT: (0, 1)
    max_tree_depth: 12              # NUTS max tree depth
                                    # CONSTRAINT: > 0
    dense_mass_matrix: true         # Full covariance adaptation

    # Per-phi initialization (rarely needed)
    initial_values:
      phi: {}                       # {angle_deg: {contrast: X, offset: Y}}
      percentile_fallback:
        contrast_low_pct: 5
        contrast_high_pct: 95
        offset_pct: 50

  # ===========================================================================
  # CMC - Consensus Monte Carlo (Only MCMC Path)
  # ===========================================================================
  # Parallelizes MCMC across data shards using per-shard NUTS sampling.
  # Combines subposteriors via Consensus Monte Carlo (precision-weighted means).
  #
  # AUTOMATIC NLSQ WARM-START (v2.20.0):
  #   When using CLI: homodyne --method cmc --config config.yaml
  #   NLSQ is run AUTOMATICALLY first, and results are used as CMC initial values.
  #   This reduces divergence rate from ~28% to <5%.
  #
  #   To disable (NOT recommended): homodyne --method cmc --no-nlsq-warmstart
  #
  #   For API usage, pass nlsq_result to fit_mcmc_jax():
  #     nlsq_result = fit_nlsq_jax(data, config)
  #     cmc_result = fit_mcmc_jax(data, config, nlsq_result=nlsq_result)
  #
  # AUTO-ACTIVATION:
  #   CMC used when: enable="auto" AND dataset ≥ min_points_for_cmc
  #
  # MODE-SPECIFIC THRESHOLDS (when min_points_for_cmc=500000):
  #   - laminar_flow: 100,000 (7-param model benefits from earlier sharding)
  #   - static: 500,000 (3-param model handles larger single-shard runs)
  #
  cmc:
    enable: "auto"                  # true | false | "auto"
    min_points_for_cmc: 500000      # Threshold for auto-enable
    run_id: null                    # Optional run tag

    # -------------------------------------------------------------------------
    # ANTI-DEGENERACY: PER-ANGLE SCALING MODE (v2.18.0+)
    # -------------------------------------------------------------------------
    # Controls how per-angle contrast/offset are handled to prevent parameter
    # absorption degeneracy.
    # Same logic as NLSQ per-angle mode (except CMC does not have "fourier").
    #
    # MODES:
    #   "auto" (RECOMMENDED): Auto-selects based on n_phi threshold.
    #     When n_phi >= threshold: Estimates per-angle values from quantile
    #     analysis, AVERAGES them to single value, broadcasts to all angles.
    #     Reduces to 8 params (7 physical + 1 sigma).
    #
    #   "constant": Per-angle values from quantile estimation, used DIRECTLY.
    #     Different fixed value per angle (NOT averaged, NOT sampled).
    #     Reduces to 8 params (7 physical + 1 sigma).
    #
    #   "individual": Independent contrast + offset per angle, all sampled.
    #     May suffer from parameter absorption degeneracy with many angles.
    #     Use only when per-angle variation should be inferred from data.
    #
    # PARAMETER REDUCTION (laminar_flow, n_phi=23):
    #   - auto (n_phi >= 3): 8 params (7 physical + 1 sigma)
    #   - constant:          8 params (7 physical + 1 sigma)
    #   - individual:       54 params (7 physical + 46 scaling + 1 sigma)
    #   - Reduction:        85%
    #
    per_angle_mode: "auto"
    constant_scaling_threshold: 3   # Use constant when n_phi >= this
                                    # CONSTRAINT: >= 1

    # Computational backend
    backend: "jax"                  # "jax" | "numpy"

    # Parallel execution configuration
    backend_config:
      name: "auto"                  # "auto" | "multiprocessing" | "pjit" | "pbs" | "slurm"
      enable_checkpoints: true      # Enable checkpoints
      checkpoint_frequency: 1       # Checkpoint every N shards
      checkpoint_dir: "./cmc_checkpoints"
      keep_last_checkpoints: 3      # Keep N recent checkpoints
      resume_from_checkpoint: true  # Auto-resume

    # Data sharding
    sharding:
      strategy: "stratified"        # "stratified" | "random" | "contiguous"
      num_shards: "auto"            # "auto" uses n_phi for stratified
      max_points_per_shard: "auto"  # "auto" → dynamic based on dataset size (v2.20.0)
                                    # laminar_flow: 12K-21K after angle scaling
                                    # static: 50K-100K
      min_points_per_shard: "auto"  # "auto" → 10K (laminar) or 5K (static) (v2.20.0)
                                    # Prevents data-starved shards
      seed_base: 0                  # Shard seed = seed_base + shard_id

    # Per-shard timeout (seconds)
    #
    # TIMEOUT TUNING:
    # ---------------
    # | Dataset Size | Shard Size | Recommended Timeout |
    # |--------------|------------|---------------------|
    # | < 2M points  | 20K auto   | 7200s (2 hours)     |
    # | 2M - 10M     | 10K auto   | 7200s (2 hours)     |
    # | 10M - 50M    | 10K auto   | 10800s (3 hours)    |
    # | > 50M        | 5K-10K     | 14400s (4 hours)    |
    #
    per_shard_timeout: 7200         # CONSTRAINT: > 60
    heartbeat_timeout: 1200         # Terminate unresponsive workers
                                    # CONSTRAINT: > 60

    # Subposterior combination
    combination:
      method: "consensus_mc"        # "consensus_mc" | "robust_consensus_mc" | "weighted_gaussian" | "simple_average"
                                    # consensus_mc: Precision-weighted combination (default)
                                    # robust_consensus_mc: MAD-based outlier detection (v2.20.0)
                                    #   - Excludes outlier shards before combination
                                    #   - Auto-enabled if heterogeneity_abort=false and CV > threshold
      validate_results: true        # Validate quality
      min_success_rate: 0.90        # Require 90% shard convergence
                                    # CONSTRAINT: [0, 1]
      min_success_rate_warning: 0.80 # Warn if below this
                                    # CONSTRAINT: [0, 1]

    # Per-shard MCMC (overrides base mcmc settings)
    per_shard_mcmc:
      num_warmup: 500               # CONSTRAINT: > 0
      num_samples: 1500             # CONSTRAINT: > 0
      num_chains: 2                 # CONSTRAINT: > 0
      target_accept_prob: 0.85      # CONSTRAINT: (0, 1)

    # Convergence validation
    validation:
      strict_mode: true             # Fail if thresholds not met
      min_per_shard_ess: 100.0      # Effective sample size threshold
      max_per_shard_rhat: 1.1       # R-hat threshold
      max_between_shard_kl: 2.0     # KL divergence between shards
      min_success_rate: 0.90        # CONSTRAINT: [0, 1]

      # -----------------------------------------------------------------------
      # NLSQ WARM-START & QUALITY CONTROL (v2.20.0)
      # -----------------------------------------------------------------------
      # IMPORTANT: As of v2.20.0, NLSQ warm-start is AUTOMATIC when using CLI:
      #   homodyne --method cmc --config config.yaml
      #
      # The CLI runs NLSQ first, then uses results as CMC initial values.
      # This reduces divergence rate from ~28% to <5%.
      #
      # To disable (NOT recommended):
      #   homodyne --method cmc --no-nlsq-warmstart
      #
      # For API usage, pass nlsq_result to fit_mcmc_jax():
      #   nlsq_result = fit_nlsq_jax(data, config)
      #   cmc_result = fit_mcmc_jax(data, config, nlsq_result=nlsq_result)
      # -----------------------------------------------------------------------

      # Divergence-based quality filtering
      max_divergence_rate: 0.10     # Filter shards with >10% divergences
                                    # CONSTRAINT: [0, 1]
                                    # Shards exceeding this are excluded from combination

      # NLSQ warm-start requirement (API-level only; CLI is automatic)
      require_nlsq_warmstart: false # Set true to REQUIRE nlsq_result in API calls
                                    # When true, fit_mcmc_jax() raises ValueError without it

      # Heterogeneity detection and abort (v2.20.0)
      max_parameter_cv: 1.0         # Maximum coefficient of variation across shard means
                                    # CONSTRAINT: > 0
                                    # CV = std(shard_means) / |mean(shard_means)|
                                    # High CV indicates shards sampling different posteriors

      heterogeneity_abort: true     # Abort if heterogeneity exceeds max_parameter_cv
                                    # When true: raises RuntimeError with guidance
                                    # When false: falls back to robust_consensus_mc

    # -------------------------------------------------------------------------
    # REPARAMETERIZATION (v2.21.0 / Jan 2026)
    # -------------------------------------------------------------------------
    # Transforms sampling space to break parameter degeneracies and improve
    # NUTS sampling efficiency for challenging parameter combinations.
    #
    # D_total Reparameterization (D0 + D_offset → D_total):
    #   Instead of sampling D0 and D_offset independently (which can be
    #   degenerate - the model only depends on their sum), sample:
    #     D_total = D0 + D_offset (the physically meaningful quantity)
    #     D_offset directly
    #   Then transform back: D0 = D_total - D_offset
    #   This breaks the linear degeneracy between D0 and D_offset.
    #
    # Log-Gamma Reparameterization (laminar_flow only):
    #   Sample log(gamma_dot_t0) instead of gamma_dot_t0 directly.
    #   Improves NUTS sampling for small shear rates spanning orders of
    #   magnitude (e.g., 1e-6 to 0.5 s⁻¹). The log transform makes the
    #   posterior more Gaussian and reduces step size adaptation issues.
    #
    # Bimodal Detection:
    #   After sampling, checks each parameter's marginal posterior for
    #   bimodality using Gaussian Mixture Models (GMM). Bimodal posteriors
    #   may indicate:
    #     - Model identifiability issues
    #     - Multimodal likelihood (multiple local minima)
    #     - Insufficient data to constrain parameters
    #   Alerts are logged when bimodality is detected.
    #
    reparameterization:
      enable_d_total: true            # Sample D_total = D0 + D_offset
                                      # Breaks D0/D_offset degeneracy
      enable_log_gamma: true          # Sample log(gamma_dot_t0) (laminar_flow)
                                      # Improves sampling for small shear rates
      bimodal_min_weight: 0.2         # Minimum GMM component weight for bimodal
                                      # CONSTRAINT: (0, 0.5]
                                      # Both components must exceed this weight
      bimodal_min_separation: 0.5     # Minimum relative separation for bimodal
                                      # CONSTRAINT: (0, 2.0]
                                      # Separation = |μ1 - μ2| / sqrt(σ1² + σ2²)

# ==============================================================================
# NOISE ESTIMATION (Optional)
# ==============================================================================
# Automatic noise variance estimation for improved fit weighting.
# Uses hybrid NumPyro approach with Adam optimization.
#
noise_estimation:
  enabled: false
  model: "per_angle"                # "per_angle" | "global"

  adam_config:
    learning_rate: 0.01             # CONSTRAINT: > 0
    max_epochs: 500                 # CONSTRAINT: > 0
    convergence_threshold: 1.0e-6   # CONSTRAINT: > 0
    early_stopping: true

  posterior_samples: 1200           # CONSTRAINT: > 0

  validation:
    check_convergence: true
    reasonable_range: [1.0e-4, 1.0] # Valid noise range
    warn_outliers: true

  per_angle:
    min_angles_required: 2
    validate_coverage: true

# ==============================================================================
# PERFORMANCE (CPU Only)
# ==============================================================================
# Memory management and computation settings.
# GPU support removed in v2.3.0 (CPU-only).
#
performance:
  strategy_override: null           # null | "standard" | "large" | "chunked" | "streaming"
  memory_limit_gb: null             # null = auto-detect
  enable_progress: true

  memory_optimization:
    enabled: true
    max_memory_usage_gb: 6.0        # CONSTRAINT: > 0
    chunk_size: 8000                # CONSTRAINT: > 0
    enable_caching: true
    cache_strategy: "adaptive"      # "adaptive" | "aggressive" | "conservative"

  computation:
    enable_jit: true                # JAX JIT compilation
    cpu_threads: "auto"             # "auto" or positive int
    vectorization_level: "high"     # "low" | "medium" | "high"

# ==============================================================================
# LOGGING
# ==============================================================================
# Logging configuration for analysis monitoring.
#
logging:
  enabled: true
  level: "INFO"                     # "DEBUG" | "INFO" | "WARNING" | "ERROR"

  console:
    enabled: true
    level: "INFO"
    format: "detailed"              # "simple" | "detailed"
    colors: true
    show_progress: true

  file:
    enabled: false
    level: "DEBUG"
    path: "./logs/"
    filename: "homodyne_analysis.log"
    max_size_mb: 10                 # Log rotation size
    backup_count: 5                 # Number of backup files

  # Module-specific log levels
  modules:
    "homodyne.data.phi_filtering": "INFO"
    "homodyne.data.xpcs_loader": "INFO"
    "homodyne.optimization.nlsq_wrapper": "INFO"
    "jax._src": "WARNING"           # Suppress JAX internal messages

# ==============================================================================
# QUALITY CONTROL (Optional)
# ==============================================================================
# Data validation and analysis quality checks.
#
quality_control:
  enabled: false

  angle_quality:
    validate_angle_coverage: true
    min_angles_per_range: 1
    check_angle_distribution: true

  multi_angle_validation:
    check_correlation_consistency: true
    validate_angle_dependencies: true
    detect_anomalous_angles: true

# ==============================================================================
# PLOTTING (Visualization)
# ==============================================================================
# Plot generation and output settings.
#
plotting:
  save_plots: true
  show_plots: false
  format: "png"                     # "png" | "pdf" | "svg"
  dpi: 300                          # CONSTRAINT: > 0
  style: "publication"

  # Rendering mode
  preview_mode: false               # false = matplotlib, true = datashader
  fit_surface: "solver"             # "solver" | "posthoc"

  color_scale:
    mode: "legacy"                  # "legacy" | "adaptive"
    pin_legacy_range: true
    percentile_min: 1.0             # CONSTRAINT: [0, 100]
    percentile_max: 99.0            # CONSTRAINT: [0, 100]
    fixed_min: 1.0
    fixed_max: 1.5

  datashader:
    canvas_width: 1200              # CONSTRAINT: > 0
    canvas_height: 1200             # CONSTRAINT: > 0

  matplotlib:
    interpolation: "bilinear"       # "none" | "bilinear" | "bicubic"
    use_tight_layout: true
    savefig_kwargs:
      bbox_inches: "tight"
      pad_inches: 0.1

  # Plot types to generate
  correlation_function: true        # C1(t) and C2(t1,t2)
  fit_quality: true                 # Residuals
  parameter_distributions: true     # MCMC posteriors
  residual_analysis: true
  angle_coverage: true
  angle_correlation: true

# ==============================================================================
# OUTPUT
# ==============================================================================
# Result file configuration.
#
output:
  directory: "./results"
  base_directory: "./homodyne_results/"

  formats:
    hdf5: true
    json: true
    csv: true

  create_subdirs: true              # Creates nlsq/, mcmc/, cmc/
  timestamp_dirs: false

  compress_hdf5: true
  compression_level: 6              # 0-9 (higher = more compression)

# ==============================================================================
# VALIDATION (Optional)
# ==============================================================================
# Configuration validation settings.
#
validation:
  strict_mode: false                # Fail on warnings
  check_file_existence: true
  validate_parameter_ranges: true
  check_mode_compatibility: true

  angle_validation:
    require_multiple_angles: false
    min_angle_count: 1
    validate_angle_ranges: true

# ==============================================================================
# ENVIRONMENT VARIABLE OVERRIDES
# ==============================================================================
# The following environment variables can override configuration settings:
#
# NLSQ_MEMORY_FRACTION    - Memory fraction (0.1-0.9), overrides memory_fraction
#
# Example:
#   export NLSQ_MEMORY_FRACTION=0.6
#   homodyne --config your_config.yaml --method nlsq
#
# ==============================================================================

# ==============================================================================
# USAGE NOTES & TROUBLESHOOTING
# ==============================================================================
#
# QUICK START WORKFLOW:
# ---------------------
# 1. Copy this template and update experimental_data paths
# 2. Set analysis_mode: "static" or "laminar_flow"
# 3. Run NLSQ: homodyne --config your_config.yaml --method nlsq
# 4. Check output plots for fit quality
# 5. If poor fit, see troubleshooting sections below
# 6. For publication: Run MCMC with NLSQ results as initial values
#
# ---------------------------------------------------------------------------
# METHOD SELECTION DECISION TREE
# ---------------------------------------------------------------------------
#
#   Is this laminar_flow mode?
#   ├─ NO → Use standard NLSQ (default settings)
#   └─ YES → Check scale ratio (D₀/γ̇₀ bounds range)
#            ├─ < 1000 → Use multi-start optimization
#            │           (nlsq.multi_start.enable: true)
#            └─ > 1000 → Use CMA-ES global optimization
#                        (nlsq.cmaes.enable: true)
#
# ---------------------------------------------------------------------------
# GRADIENT IMBALANCE FIX (laminar_flow)
# ---------------------------------------------------------------------------
# SYMPTOM: Early convergence, missing C2 oscillations, flat shear parameters
#
# DIAGNOSIS:
#   python scripts/diagnose_gradients.py --results-dir ./homodyne_results/nlsq
#
# SOLUTIONS (in order of preference):
#   1. Enable CMA-ES: nlsq.cmaes.enable: true (if scale ratio > 1000)
#   2. Compute x_scale_map from diagnosis output
#   3. Enable hierarchical optimization (already default)
#
# ---------------------------------------------------------------------------
# SHEAR PARAMETER COLLAPSE (γ̇₀ → 0)
# ---------------------------------------------------------------------------
# SYMPTOM: gamma_dot_t0 collapses to lower bound despite visible shear effects
#
# CAUSES & SOLUTIONS:
#   1. Gradient cancellation with many angles
#      → Enable: anti_degeneracy.hierarchical.enable: true
#      → Enable: anti_degeneracy.shear_weighting.enable: true
#
#   2. Per-angle parameter absorption
#      → Set: anti_degeneracy.per_angle_mode: "constant"
#
#   3. Multi-scale optimization failure
#      → Enable: nlsq.cmaes.enable: true
#
# ---------------------------------------------------------------------------
# CMC CONVERGENCE ISSUES
# ---------------------------------------------------------------------------
# If shards fail validation (ESS/R-hat):
#   - Increase per_shard_mcmc.num_warmup and num_samples
#   - Tighten phi0 bounds for faster MCMC mixing
#   - Check for multimodal posteriors (may need different priors)
#
# ---------------------------------------------------------------------------
# OUT OF MEMORY (OOM) ERRORS
# ---------------------------------------------------------------------------
# SYMPTOM: JAX or Python crashes with memory error
#
# SOLUTIONS:
#   1. Reduce memory_fraction: 0.5 (default 0.75)
#   2. Force streaming: performance.strategy_override: "streaming"
#   3. Reduce hybrid_streaming.chunk_size
#   4. For CMC: Reduce max_points_per_shard
#
# ---------------------------------------------------------------------------
# PARAMETER COUNTING
# ---------------------------------------------------------------------------
#   static:       3 physical + 2 × N_angles = 3 + 2N
#   laminar_flow: 7 physical + 2 × N_angles = 7 + 2N
#
# Examples with 3 angles:
#   static:       9 total parameters
#   laminar_flow: 13 total parameters
#
# ---------------------------------------------------------------------------
# ANGLE SELECTION GUIDELINES
# ---------------------------------------------------------------------------
# Static mode:
#   - 0° and 180° for anisotropy detection
#   - All angles if isotropic behavior expected
#
# Laminar flow mode:
#   - 0° (parallel): Maximum shear effects
#   - 90° (perpendicular): Diffusion-dominated signal
#   - Both required for proper shear/diffusion decoupling
#
# ---------------------------------------------------------------------------
# DATASET SIZE STRATEGIES
# ---------------------------------------------------------------------------
# | Dataset Size   | Strategy   | Memory    | Description                  |
# |----------------|------------|-----------|------------------------------|
# | < 1M points    | STANDARD   | ~2 GB     | Direct curve_fit             |
# | 1M-10M points  | LARGE      | ~6 GB     | Optimized curve_fit_large    |
# | 10M-100M pts   | CHUNKED    | ~8 GB     | Progress bar, memory-bounded |
# | > 100M points  | STREAMING  | ~2 GB     | Checkpoint/resume, fault-tol |
#
# ---------------------------------------------------------------------------
# PLATFORM REQUIREMENTS
# ---------------------------------------------------------------------------
#   - Python 3.12+
#   - JAX 0.8.0 / jaxlib 0.8.0 (CPU-only)
#   - NumPy 2.x
#   - NLSQ 0.6.4+ (pip install nlsq)
#   - For CMA-ES: pip install nlsq[evosax]
#
# ---------------------------------------------------------------------------
# CONFIGURATION VALIDATION
# ---------------------------------------------------------------------------
#   homodyne-config --validate your_config.yaml
#   python -m homodyne.runtime.utils.system_validator --quick
#
# ==============================================================================
# END OF MASTER TEMPLATE
# ==============================================================================
