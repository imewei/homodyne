# ==============================================================================
# HOMODYNE STATIC DIFFUSION CONFIGURATION TEMPLATE
# ==============================================================================
# Comprehensive production-ready template for static diffusion analysis.
# 3-parameter model: D(t) = D₀·t^α + D_offset
#
# Use for: Equilibrium systems, pure diffusion, anomalous diffusion
# Parameter count: 3 physical + 2 × N_angles scaling = 3 + 2N total
#
# VERSION: 2.4.1
# UPDATED: 2025-12-04
# ==============================================================================

# ==============================================================================
# METADATA (Required)
# ==============================================================================
# Template metadata describing analysis configuration
metadata:
  config_version: "2.4.1" # Configuration file format version
  description: "Static diffusion analysis - 3-parameter model"
  analysis_mode: "static" # Static diffusion mode
  parameter_count: 3 # D₀, α, D_offset

  # Physics model description
  physics_model: "D(t) = D₀·t^α + D_offset" # No shear effects (equilibrium)

  # Integration and correction methods
  integration_method: "discrete_numerical" # Discrete numerical integration for stability
  diagonal_correction: "mandatory" # Diagonal correction for consistency

  # Template classification
  recommended_use: "Equilibrium XPCS systems with pure diffusion and anomalous diffusion"
  template_type: "production_ready" # Production-ready template
  complexity: "comprehensive" # All features documented

  # Optional: Generation metadata (filled by homodyne-config)
  generated_at: null # ISO timestamp when config generated
  generated_by: null # Tool used to generate config

# ==============================================================================
# ANALYSIS MODE (Required)
# ==============================================================================
# Primary analysis mode selection
analysis_mode: "static" # Static diffusion (equilibrium)

# ==============================================================================
# ANALYZER PARAMETERS (Required)
# ==============================================================================
# Core physical and instrumental parameters for analysis
analyzer_parameters:
  # Time resolution
  dt: 0.1 # Time step between correlation measurements [seconds]

  # Frame range for analysis
  start_frame: 1000 # Starting frame number (1-indexed)
  end_frame: 2000 # Ending frame number (inclusive)

  # Scattering parameters
  scattering:
    wavevector_q: 0.0054 # Wave vector magnitude [Å⁻¹] - sample dependent

  # Geometry parameters (instrumental setup)
  geometry:
    stator_rotor_gap: 2000000 # Gap between stator and rotor [Å] (200 microns = 2000000 Å)

# ==============================================================================
# ANALYSIS SETTINGS (Required)
# ==============================================================================
# Analysis mode-specific settings and model description
analysis_settings:
  static_mode: true # Static diffusion (no flow)

  # Model description for documentation
  model_description:
    type: "static_diffusion" # Static diffusion model
    parameters: 3 # D₀, α, D_offset
    physics: "Equilibrium anomalous diffusion with time-dependent coefficient"

# ==============================================================================
# EXPERIMENTAL DATA (Required)
# ==============================================================================
# Paths to experimental data files and caching configuration
experimental_data:
  # Primary data file (HDF5 format)
  file_path: "./data/sample/experiment.hdf" # Preferred: Direct path to HDF5 file

  # Legacy format (data_folder_path + data_file_name)
  data_folder_path: "./data/sample/" # Folder containing data file
  data_file_name: "experiment.hdf" # HDF5 data file name

  # Phi angles configuration
  phi_angles_path: "./data/sample/" # Folder containing phi angles list
  phi_angles_file: "phi_angles_list.txt" # Text file with phi angles (one per line)

  # Caching for performance (saves processed C2 data)
  cache_file_path: "./data/sample/" # Cache directory
  cache_filename_template: "cached_c2_static_q{wavevector_q:.4f}_frames_{start_frame}_{end_frame}.npz"
  cache_compression: true # Enable compression for cache files

  # Data format specifications
  data_type: "float64" # Data type for arrays
  file_format: "HDF5" # File format (currently only HDF5 supported)
  exchange_key: "exchange" # HDF5 group key for exchange data

# ==============================================================================
# PHI ANGLE FILTERING
# ==============================================================================
# Advanced phi angle filtering for optimal scattering analysis
# For static diffusion: typically use angles parallel (0°) and antiparallel (180°)
# to detect anisotropic effects or verify isotropic behavior
phi_filtering:
  enabled: true # Enable angle filtering to reduce parameter count

  # Target angle ranges (all angles normalized to [-180°, 180°])
  # Angles are checked with wrap-aware logic (e.g., [170°, -170°] works correctly)
  target_ranges:
    # Range 1: Near 0° (parallel to potential anisotropy axis)
    - min_angle: -10.0 # Minimum angle [degrees]
      max_angle: 10.0 # Maximum angle [degrees]
      description: "Parallel to primary axis"

    # Range 2: Near 180° (antiparallel to anisotropy axis)
    - min_angle: 170.0
      max_angle: -170.0 # Wraps correctly: 170° to -170° = [170°, 190°]
      description: "Antiparallel to primary axis"

    # Optional: Perpendicular angles for comprehensive anisotropic analysis
    # Uncomment if your system shows perpendicular anisotropic effects
    # - min_angle: 85.0
    #   max_angle: 95.0
    #   description: "Perpendicular axis 1"
    # - min_angle: -95.0
    #   max_angle: -85.0
    #   description: "Perpendicular axis 2"

  # Fallback behavior
  fallback_to_all_angles: true # Use all angles if no angles match target ranges

  # Filtering algorithm
  algorithm: "range_based" # Algorithm type (currently only range_based)
  tolerance: 3.0 # Angular tolerance [degrees] for range matching

  # Quality control for angle selection
  quality_control:
    min_angles_required: 1 # Minimum number of angles required for analysis
    max_angle_spread: 36.0 # Maximum spread within a single range [degrees]
    validate_coverage: true # Validate that angles adequately cover target ranges
    require_orthogonal_angles: false # Not required for static (use true for anisotropic analysis)

# ==============================================================================
# INITIAL PARAMETERS (Required)
# ==============================================================================
# Starting parameter values for optimization
#
# PARAMETER COUNT (Static):
# -------------------------
# **PER-ANGLE SCALING MANDATORY (v2.4.0)**:
#   - Legacy scalar contrast/offset mode REMOVED
#   - Each scattering angle has unique optical/detector properties
#   - Passing per_angle_scaling=False will raise ValueError
#
# Physical parameters: 3 [D₀, α, D_offset]
# Per-angle scaling: 2 × N_angles [contrast, offset]
# Total: 3 + 2N (e.g., 3 angles → 9 parameters)
#
initial_parameters:
  # Parameter names to optimize (3 parameters for static mode)
  parameter_names:
    - D0 # Diffusion coefficient prefactor
    - alpha # Anomalous diffusion exponent
    - D_offset # Baseline diffusion

  # Optional: Initial values (if not provided, uses mid-point of bounds)
  values: null # List of 3 floats matching parameter_names order
  # Example: [1000.0, -1.2, 0.0]

  # Per-angle scaling initialization (v2.4.0 mandatory)
  # IMPORTANT: Initialize from NLSQ results or estimate from data to prevent MCMC convergence failures
  # For NLSQ→MCMC workflow: Run NLSQ first, copy contrast/offset from results
  # For data estimation: contrast ≈ (C2_max - C2_min), offset ≈ C2_min
  per_angle_scaling:
    contrast: null # List of N floats (one per angle)
    offset: null # List of N floats (one per angle)
    # Example for 3 angles: contrast: [0.05, 0.06, 0.05], offset: [1.0, 0.99, 1.01]
    # Example for 1 angle:  contrast: [0.06], offset: [0.99]
    # Typical ranges: contrast [0.01-0.2], offset [0.9-1.1] for XPCS data

  # Optional: Units for documentation
  units: # Parameter units (for reference)
    - "Å²/s" # D0
    - "dimensionless" # alpha
    - "Å²/s" # D_offset

  # Optional: Optimize only a subset of parameters (rest held at initial values)
  active_parameters: null # List of parameter names to actively optimize
  # Example: ["D0", "alpha"]  # Fix D_offset

  # Optional: Fix specific parameters at given values
  fixed_parameters: null # Dict mapping parameter names to fixed values
  # Example: {"D_offset": 0.0}  # Assume no offset

# ==============================================================================
# PARAMETER SPACE (Required)
# ==============================================================================
# Parameter bounds and constraints for static diffusion model
parameter_space:
  model: "static" # Static diffusion mode

  bounds:
    # -------------------------------------------------------------------------
    # DIFFUSION PARAMETERS (3 parameters for static mode)
    # -------------------------------------------------------------------------
    - name: D0
      min: 100.0 # Minimum diffusion coefficient [Å²/s]
      max: 1e5 # Maximum diffusion coefficient [Å²/s]
      type: TruncatedNormal # Bound type for priors
      prior_mu: 1000.0 # Prior mean (for Bayesian methods)
      prior_sigma: 1000.0 # Prior std dev (for Bayesian methods)
      unit: "Å²/s"
      # Physical meaning: Controls magnitude of diffusion in D(t) = D₀·t^α + D_offset
      # Typical range: 100-10000 for colloidal systems

    - name: alpha
      min: -2.0 # ✅ FIXED: Physically realistic minimum (was -10.0)
      max: 2.0 # ✅ FIXED: Physically realistic maximum (was 10.0)
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: -1.2 # Prior mean
      prior_sigma: 0.3 # Prior std dev
      # ✅ Bounds tightened: [-10,10] caused numerical underflow (alpha=-4.96 → theory≈0)
      unit: "dimensionless"
      # Physical meaning: Anomalous diffusion exponent
      # 0 = normal diffusion, <0 = subdiffusion, >0 = superdiffusion
      # Typical range: -2 to 2 for equilibrium systems

    - name: D_offset
      min: -100000.0 # Minimum baseline diffusion [Å²/s]
      max: 100000.0 # Maximum baseline diffusion [Å²/s]
      type: TruncatedNormal # ✅ FIXED: Changed from Normal to enforce bounds
      prior_mu: 0.0 # Prior mean
      prior_sigma: 150.0 # Prior std dev
      unit: "Å²/s"
      # Physical meaning: Constant diffusion contribution (can be negative)
      # Typical range: -100 to 100 for most systems

  # Optional: Prior distributions for Bayesian methods
  priors: null # Advanced prior specifications (rarely needed)

# ==============================================================================
# OPTIMIZATION METHODS
# ==============================================================================
# Optimization method selection and configuration
optimization:
  method:
    "nlsq" # Options: "nlsq" | "mcmc"
    # Note: MCMC uses CMC-only architecture (v2.4.1) with per-shard NUTS sampling

  # ---------------------------------------------------------------------------
  # NLSQ - Trust-Region Nonlinear Least Squares (Primary Method)
  # ---------------------------------------------------------------------------
  # Fast, deterministic optimization using Levenberg-Marquardt algorithm
  # CPU-optimized with JAX 0.8.0 (v2.3.0+), JIT-compiled for performance
  # Automatic strategy selection based on dataset size:
  #   < 1M points     → STANDARD (curve_fit)
  #   1M-10M points   → LARGE (curve_fit_large)
  #   10M-100M points → CHUNKED (curve_fit_large with progress)
  #   > 100M points   → STREAMING (unlimited data with checkpointing)
  nlsq:
    max_iterations: 100 # Maximum optimization iterations
    tolerance: 1e-8 # Convergence tolerance
    trust_region_scale: 1.0 # Trust region scaling factor (0.1-10.0)
    verbose: false # Print iteration details

    # ROBUST LOSS FUNCTION SELECTION
    # --------------------------------
    # Controls how outliers affect the fit. All loss functions are JAX JIT-compiled.
    #
    # Available options:
    #   "linear"  - Standard least squares: ρ(z) = z
    #               No outlier protection; fastest; optimal for clean data
    #
    #   "huber"   - Huber loss: ρ(z) = z if z ≤ 1, else 2√z - 1
    #               Quadratic for small residuals, linear for large
    #               Good balance between efficiency and robustness
    #
    #   "soft_l1" - Soft L1 loss: ρ(z) = 2(√(1+z) - 1)
    #               Smooth approximation to L1 norm
    #               More robust than Huber; preserves differentiability
    #               RECOMMENDED DEFAULT for XPCS data
    #
    #   "cauchy"  - Cauchy/Lorentzian: ρ(z) = ln(1 + z)
    #               Extremely robust; handles heavy-tailed errors
    #               May converge slowly; use cautiously
    #
    #   "arctan"  - Arctangent: ρ(z) = arctan(z)
    #               Bounded loss; very robust to extreme outliers
    #               May converge slowly; use cautiously
    #
    # LOSS FUNCTION SELECTION FOR XPCS:
    # ----------------------------------
    # | Data Quality              | Recommended Loss |
    # |---------------------------|------------------|
    # | Clean, well-characterized | "linear"         |
    # | Typical XPCS data         | "soft_l1"        |
    # | Few outliers/artifacts    | "huber"          |
    # | Many outliers             | "soft_l1"        |
    # | Severe contamination      | "cauchy"         |
    # | Unknown quality           | "soft_l1"        |
    #
    # XPCS-specific considerations:
    #   - Detector artifacts, cosmic rays, dead pixels → use "soft_l1"
    #   - High-quality synchrotron data → "linear" or "huber"
    #   - If convergence issues with "cauchy"/"arctan" → fall back to "soft_l1"
    #
    loss: "soft_l1"

    # Parameter-Specific Scaling (Optional for Static Mode)
    # ------------------------------------------------------
    # Less critical than laminar flow, but can help if alpha has large gradients
    # Use gradient diagnostics if optimization shows signs of premature convergence:
    #   python scripts/diagnose_gradients.py --results-dir ./homodyne_results/nlsq
    x_scale_map: null # Per-parameter scaling (null = uniform scaling)
    # Example if gradient diagnostics shows imbalance:
    # x_scale_map:
    #   D0: 1.0
    #   alpha: 0.01                            # If alpha gradient is 100× larger
    #   D_offset: 1.0

  # ---------------------------------------------------------------------------
  # STRATIFICATION - Angle-Stratified Chunking (v2.2+)
  # ---------------------------------------------------------------------------
  # Fixes per-angle parameter compatibility with NLSQ chunking for large datasets
  # Automatically reorganizes data to ensure all chunks contain all phi angles
  # Prevents silent optimization failures (0 iterations, zero gradients)
  stratification:
    enabled:
      "auto" # Options: "auto" | true | false
      # "auto" activates when: per_angle_scaling=True AND n_points>=100k
    target_chunk_size:
      100000 # Target size for stratified chunks [points]
      # Should match NLSQ's internal chunk size
    max_imbalance_ratio:
      5.0 # Maximum angle imbalance ratio before fallback
      # Fallback to sequential if max_count/min_count > threshold
    force_sequential_fallback:
      false # Force sequential per-angle optimization
      # Useful for highly imbalanced angle distributions
    check_memory_safety:
      true # Check available memory before stratification
      # Warns if peak memory > 70% of available
    use_index_based:
      false # Use zero-copy index-based stratification
      # Reduces memory overhead from 2x to ~1%
      # Recommended for very large datasets (>10M points)
    collect_diagnostics:
      false # Collect detailed stratification diagnostics
      # Performance metrics, chunk balance, angle coverage
      # Minimal overhead (~0.01s)
    log_diagnostics:
      false # Log diagnostic report to console
      # Requires collect_diagnostics=true
      # Useful for troubleshooting and validation

  # Performance Impact:
  # - Time overhead: <1% (0.15s for 3M points)
  # - Memory overhead: 2x peak (temporary) or ~1% (index-based)
  # - Diagnostics overhead: <0.1% (0.01s for 3M points)
  # - Fixes: Silent failures with per-angle scaling on large datasets

  # ---------------------------------------------------------------------------
  # SEQUENTIAL - Sequential Per-Angle Optimization (v2.2+)
  # ---------------------------------------------------------------------------
  # Fallback strategy when stratification cannot be applied
  # Optimizes each phi angle independently and combines results
  # Used when: angle imbalance > threshold OR force_sequential_fallback=true
  sequential:
    min_success_rate:
      0.5 # Minimum fraction of angles that must converge
      # Optimization fails if fewer angles converge
    weighting:
      "inverse_variance" # Result combination method
      # Options: "inverse_variance" | "uniform" | "n_points"
      # "inverse_variance" provides optimal statistical weighting

  # Usage Notes:
  # - Automatically activated when: imbalance_ratio > max_imbalance_ratio
  # - Can be forced via: optimization.stratification.force_sequential_fallback=true
  # - Uses scipy.optimize.least_squares per angle (CPU only)
  # - Combines results using weighted averaging

  # ---------------------------------------------------------------------------
  # MCMC - Base MCMC Sampler Configuration
  # ---------------------------------------------------------------------------
  # Base configuration for NumPyro/BlackJAX NUTS sampler.
  # Used by CMC shards; can be overridden in cmc.per_shard_mcmc.
  mcmc:
    backend: "numpyro"           # "numpyro" | "blackjax"
    num_warmup: 1000             # Increase if divergences persist
    num_samples: 3000            # Lower for diagnostics, raise for publication
    num_chains: 4                # ≥2 for R-hat calculation
    progress_bar: true
    target_accept_prob: 0.90     # NUTS target acceptance
    max_tree_depth: 12
    dense_mass_matrix: true      # Full covariance adaptation

    # Per-phi initialization (rarely needed)
    initial_values:
      phi: {}                    # {angle_deg: {contrast: X, offset: Y}}
      percentile_fallback:
        contrast_low_pct: 5
        contrast_high_pct: 95
        offset_pct: 50

  # ---------------------------------------------------------------------------
  # CMC - Consensus Monte Carlo (v2.4.1: Only MCMC Path)
  # ---------------------------------------------------------------------------
  # Parallelizes MCMC across data shards using per-shard NUTS sampling.
  # Combines subposteriors via weighted Gaussian product.
  cmc:
    enable: "auto"               # true | false | "auto"
    min_points_for_cmc: 500000   # Threshold for auto-enable
    backend: "jax"               # "jax" | "numpy"

    # Backend configuration for parallel execution
    backend_config:
      name: "auto"               # "auto" | "multiprocessing" | "pjit" | "pbs" | "slurm"
      enable_checkpoints: true
      checkpoint_frequency: 1    # Save every N shards
      checkpoint_dir: "./cmc_checkpoints"
      keep_last_checkpoints: 3
      resume_from_checkpoint: true

    # Data sharding
    sharding:
      strategy: "stratified"     # "stratified" (angle-aware) | "random" | "contiguous"
      num_shards: "auto"         # "auto" uses n_phi for stratified
      max_points_per_shard: 100000  # Maximum points per shard for NUTS tractability
      # Note: "auto" resolves to 100000 for static (3 params). ~20-40 min per shard.
      seed_base: 0               # Shard seed = seed_base + shard_id

    # Subposterior combination
    combination:
      method: "weighted_gaussian"  # "weighted_gaussian" | "simple_average" | "auto"
      validate_results: true
      min_success_rate: 0.90     # Require 90% shard convergence

    # Per-shard MCMC (overrides base mcmc settings for shards)
    per_shard_mcmc:
      num_warmup: 100
      num_samples: 3000
      num_chains: 4
      subsample_size: "auto"
      target_accept_prob: 0.80

    # Convergence validation
    validation:
      strict_mode: true          # Fail if thresholds not met
      min_per_shard_ess: 100.0   # Effective sample size threshold
      max_per_shard_rhat: 1.1    # R-hat threshold
      max_between_shard_kl: 2.0  # KL divergence between shards
      min_success_rate: 0.90

# ==============================================================================
# NOISE ESTIMATION (Optional)
# ==============================================================================
# Automatic noise level estimation using hybrid NumPyro approach
# Estimates per-angle or global noise variance to improve fit quality
noise_estimation:
  enabled: false # Enable automatic noise estimation
  model: "per_angle" # Options: "per_angle" | "global"

  # Adam optimization settings for noise parameter estimation
  adam_config:
    learning_rate: 0.01 # Adam learning rate
    max_epochs: 500 # Maximum optimization epochs
    convergence_threshold: 1e-6 # Convergence threshold for loss
    early_stopping: true # Enable early stopping for efficiency

  # Posterior sampling for uncertainty quantification
  posterior_samples: 1200 # Number of posterior samples for noise uncertainty

  # Quality control for noise estimation
  validation:
    check_convergence: true # Verify optimization convergence
    reasonable_range: [1e-4, 1.0] # Expected noise range (bounds for sanity check)
    warn_outliers: true # Warn about unusual noise estimates

  # Per-angle model settings
  per_angle:
    min_angles_required: 2 # Minimum angles needed for per-angle estimation
    validate_coverage: true # Ensure proper angle coverage

# ==============================================================================
# PERFORMANCE OPTIMIZATION
# ==============================================================================
# Performance and memory management settings
performance:
  # Strategy override (null = automatic selection based on dataset size)
  strategy_override: null # Options: null | "standard" | "large" | "chunked" | "streaming"

  # Memory management
  memory_limit_gb: null # Custom memory limit in GB (null = auto-detect)
  enable_progress: true # Show progress bars during optimization

  # Memory optimization settings
  memory_optimization:
    enabled: true # Enable memory optimization
    max_memory_usage_gb: 6.0 # Maximum memory usage [GB]
    chunk_size: 8000 # Data chunk size for processing
    enable_caching: true # Enable intelligent caching
    cache_strategy: "adaptive" # Options: "adaptive" | "aggressive" | "conservative"

  # Computation settings
  computation:
    enable_jit: true # Enable JAX JIT compilation
    cpu_threads: "auto" # Number of CPU threads (int or "auto")
    vectorization_level: "high" # Options: "low" | "medium" | "high"
    # Note: GPU support removed in v2.3.0 (use v2.2.x for GPU)

# ==============================================================================
# LOGGING
# ==============================================================================
# Logging configuration for analysis monitoring
logging:
  enabled: true # Enable logging
  level: "INFO" # Options: "DEBUG" | "INFO" | "WARNING" | "ERROR"

  # Console logging
  console:
    enabled: true # Log to console
    level: "INFO" # Console log level
    format: "detailed" # Options: "simple" | "detailed"
    colors: true # Enable colored output
    show_progress: true # Show progress indicators

  # File logging
  file:
    enabled: false # Log to file
    level: "DEBUG" # File log level
    path: "./logs/" # Log directory
    filename: "homodyne_static_analysis.log" # Log file name
    max_size_mb: 10 # Maximum log file size before rotation
    backup_count: 5 # Number of backup log files to keep

  # Module-specific logging levels
  modules:
    "homodyne.data.phi_filtering": "INFO"
    "homodyne.data.xpcs_loader": "INFO"
    "homodyne.optimization.nlsq_wrapper": "INFO"
    "jax._src": "WARNING" # Suppress JAX internal messages

# ==============================================================================
# QUALITY CONTROL (Optional)
# ==============================================================================
# Advanced quality control for data validation and analysis monitoring
quality_control:
  enabled: false # Enable quality control checks

  # Angle-specific quality checks
  angle_quality:
    validate_angle_coverage: true # Validate angle coverage adequacy
    min_angles_per_range: 1 # Minimum angles required per target range
    check_angle_distribution: true # Check angle distribution uniformity

  # Multi-angle data validation
  multi_angle_validation:
    check_correlation_consistency: true # Check correlation consistency across angles
    validate_angle_dependencies: true # Validate physical angle dependencies
    detect_anomalous_angles: true # Detect and warn about anomalous angles

# ==============================================================================
# VISUALIZATION (Optional)
# ==============================================================================
# Plot generation and output configuration
plotting:
  save_plots: true # Save plots to output directory
  show_plots: false # Display plots interactively
  format: "png" # Options: "png" | "pdf" | "svg"
  dpi: 300 # Resolution [dots per inch]
  style: "publication" # Plot style (matplotlib style name)

  # Rendering mode selection (hybrid plotting system)
  # Controls speed vs quality tradeoff for C2 heatmap plots
  preview_mode:
    false # false = publication quality (matplotlib, slower)
    # true = fast preview (Datashader, 5-10x faster)
  fit_surface: "solver" # Options: "solver" | "posthoc"

  color_scale:
    mode: "legacy"
    pin_legacy_range: true
    percentile_min: 1.0
    percentile_max: 99.0
    fixed_min: 1.0
    fixed_max: 1.5

  # Datashader configuration (used when preview_mode: true)
  datashader:
    canvas_width: 1200 # Rendering resolution in pixels
    canvas_height: 1200 # Higher values = more detail, larger files
    # Note: CPU-only rendering in v2.3.0+

  # Matplotlib configuration (used when preview_mode: false)
  matplotlib:
    interpolation: "bilinear" # Options: "none" | "bilinear" | "bicubic"
    use_tight_layout: true # Use tight layout for plots
    savefig_kwargs:
      bbox_inches: "tight"
      pad_inches: 0.1

  # Plot types to generate
  correlation_function: true # C1(t) and C2(t1,t2) plots
  fit_quality: true # Residuals and fit quality plots
  parameter_distributions: true # Parameter posterior distributions (MCMC only)
  residual_analysis: true # Residual analysis plots

  # Angle-specific plots
  angle_coverage: true # Show which angles were used
  angle_correlation: true # Correlation quality vs angle

# ==============================================================================
# OUTPUT
# ==============================================================================
# Output file configuration
output:
  directory: "./results" # Base output directory
  base_directory: "./homodyne_results/" # Alternative: more descriptive directory name

  # Output formats
  formats:
    hdf5: true # Save results in HDF5 format
    json: true # Save results in JSON format
    csv: true # Save results in CSV format (tables only)

  # Output organization
  create_subdirs: true # Create method-specific subdirectories (nlsq/, mcmc/, cmc/)
  timestamp_dirs: false # Add timestamp to directory names

  # Compression
  compress_hdf5: true # Enable HDF5 compression (saves disk space)
  compression_level: 6 # HDF5 compression level (0-9, higher = more compression)

# ==============================================================================
# VALIDATION (Optional)
# ==============================================================================
# Configuration validation settings
validation:
  strict_mode: false # Fail on validation warnings
  check_file_existence: true # Verify data files exist before analysis
  validate_parameter_ranges: true # Check parameters are within reasonable physics bounds
  check_mode_compatibility: true # Verify configuration matches selected analysis mode

  # Angle validation
  angle_validation:
    require_multiple_angles: false # Not required for static (can analyze single angle)
    min_angle_count: 1 # Minimum number of angles required
    validate_angle_ranges: true # Validate angle ranges are physically meaningful


# ==============================================================================
# STATIC DIFFUSION - USAGE NOTES
# ==============================================================================
#
# QUICK START (v2.4.1 Workflow):
# ----------------------------------------
# Step 1 - NLSQ optimization:
#   1. Update experimental_data paths to your HDF5 file
#   2. Adjust phi_filtering target_ranges based on your system
#   3. Run: homodyne --config this_file.yaml --method nlsq
#   4. Note best-fit parameters from output
#
# Step 2 - MCMC initialization:
#   5. Manually copy NLSQ best-fit results from output
#   6. Update initial_parameters.values in this file with NLSQ results
#   7. Example: values: [1234.5, 0.567, 12.34]  # 3 parameters for static
#   8. Run: homodyne --config this_file.yaml --method mcmc
#   9. CMC-only architecture with per-shard NUTS sampling
#
# STATIC DIFFUSION PHYSICS:
# -------------------------
# Model: D(t) = D₀·t^α + D_offset
#
# Parameters:
#   D₀: Diffusion coefficient prefactor (magnitude)
#   α: Anomalous diffusion exponent (0=normal, <0=sub, >0=super)
#   D_offset: Baseline/constant diffusion contribution
#
# Typical values:
#   D₀: 100-10000 Å²/s for colloidal systems
#   α: -2 to 2 for equilibrium systems
#   D_offset: Usually small (-100 to 100 Å²/s)
#
# PARAMETER COUNTING:
# -------------------
# Total = 3 physical + 2 × N_angles scaling
# Example with 3 filtered angles: 3 + 2×3 = 9 parameters
#   Physical: [D₀, α, D_offset]
#   Scaling: [contrast₁, offset₁, contrast₂, offset₂, contrast₃, offset₃]
#
# ANGLE FILTERING FOR STATIC:
# ----------------------------
# Recommended ranges:
#   - 0° (parallel): Detect primary anisotropy axis
#   - 180° (antiparallel): Verify symmetric behavior
#   - Optional 90° (perpendicular): Full anisotropic characterization
#
# Use fallback_to_all_angles: true if anisotropy direction unknown
#
# OPTIMIZATION METHOD SELECTION (v2.4.1):
# ----------------------------------------
# NLSQ (Recommended first):
#   - Fast: ~seconds to minutes
#   - CPU-optimized with JAX 0.8.0 JIT compilation
#   - Deterministic point estimates
#   - Good for exploration and initial fit
#
# MCMC (For publication with uncertainty quantification):
#   - Slower: ~minutes to hours (faster than laminar_flow for 3 params)
#   - Full posterior distributions with credible intervals
#   - CMC-only architecture (v2.4.1): per-shard NUTS sampling with
#     weighted Gaussian combination of subposteriors
#   - Convergence diagnostics (R-hat, ESS, divergences)
#   - Manual workflow: Run NLSQ → copy results → update YAML → run MCMC
#
# Streaming (Automatic for >100M points):
#   - Constant memory footprint
#   - Checkpoint/resume capability
#
# DATASET SIZE HANDLING:
# ----------------------
# NLSQ automatic strategy selection:
#   < 1M points     → STANDARD
#   1M-10M points   → LARGE
#   10M-100M points → CHUNKED
#   > 100M points   → STREAMING
#
# PLATFORM SUPPORT (v2.3.0):
# ---------------------------
# CPU-only: Linux, macOS, Windows (full support, multi-core optimized)
# GPU support removed in v2.3.0 (use v2.2.1 for GPU features)
# HPC-ready: Optimized for 14+ core CPUs, tested on 36-128 core nodes
#
# Installation:
#   pip install homodyne  # Automatically installs CPU-only JAX 0.8.0
#
# Requirements:
#   - Python 3.12+
#   - JAX==0.8.0 and jaxlib==0.8.0 (exact match required, CPU-only)
#   - For GPU: Stay on homodyne v2.2.1 (last GPU-supporting version)
#
# VALIDATION:
# -----------
# homodyne-config --validate this_file.yaml
# python -m homodyne.runtime.utils.system_validator --quick
#
# ==============================================================================
# END OF STATIC DIFFUSION TEMPLATE
# ==============================================================================
