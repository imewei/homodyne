{
  "metadata": {
    "_comment": "Large Dataset Laminar Flow Configuration - Optimized for 1-20M data points (centered on 5M). Aggressive performance settings with relaxed tolerances for high-speed 7-parameter processing.",
    "config_version": "0.7.2",
    "description": "Large dataset laminar flow homodyne scattering analysis - high-performance 7-parameter model optimized for datasets with 1-20M data points",
    "based_on": "He et al. PNAS 2024 - Transport coefficient approach (full flow model) with large dataset optimizations",
    "analysis_mode": "laminar_flow",
    "dataset_optimization": "large_dataset_optimized",
    "plotting_features": {
      "experimental_data_plotting": "Use --plot-experimental-data or 'hexp' shortcut for comprehensive flow analysis validation",
      "simulated_data_plotting": "Use --plot-simulated-data or 'hsim' shortcut with flow scaling transformation",
      "scaling_examples": [
        "--contrast 0.15 --offset 1.0",
        "--phi-angles 0,30,60,90,120,150"
      ],
      "multi_angle_support": "Individual plots for each phi angle with optimized color scaling"
    },
    "parameters_optimized": [
      "D0",
      "alpha",
      "D_offset",
      "gamma_dot_t0",
      "beta",
      "gamma_dot_t_offset",
      "phi0"
    ],
    "angle_filtering": "enabled_with_performance_boost",
    "shell_completion": "Use argcomplete for shell completion (conda environments auto-enabled)",
    "script_compatibility": "homodyne v0.7.2",
    "large_dataset_notes": "Aggressive performance settings with relaxed tolerances (5e-6) and optimized 7-parameter sampling for efficient processing of large datasets"
  },
  "experimental_data": {
    "_comment": "Data source and loading configuration optimized for large datasets with laminar flow",
    "data_folder_path": "./data/SAMPLE_NAME/",
    "data_file_name": "your_data_file.hdf",
    "phi_angles_path": "./data/phi_angles/",
    "phi_angles_file": "phi_list.txt",
    "exchange_key": "exchange",
    "cache_file_path": "./data/SAMPLE_NAME/",
    "cache_filename_template": "cached_c2_frames_{start_frame}_{end_frame}.npz",
    "cache_compression": true,
    "_cache_compression_note": "Enabled for large dataset storage optimization",
    "data_type": "float32",
    "_data_type_note": "Memory-efficient float32 for large datasets - minimal precision loss",
    "file_format": "NPZ",
    "preprocessing": {
      "apply_diagonal_correction": true,
      "vectorized_correction": true,
      "cache_processed_data": true,
      "normalize_data": true,
      "normalization_method": "baseline"
    }
  },
  "analyzer_parameters": {
    "_comment": "Core analysis parameters - laminar flow mode optimized for large datasets",
    "temporal": {
      "dt": 0.1,
      "_dt_note": "Time step between frames in seconds",
      "dt_unit": "seconds",
      "start_frame": 100,
      "_start_frame_note": "Large dataset optimized: standard start for skip initial equilibration",
      "end_frame": 5000100,
      "_end_frame_note": "Large dataset optimized: ~5M frame analysis window for comprehensive large dataset flow analysis",
      "frame_description": "Analysis window for large dataset flow experiment (1-20M frames, centered on 5M)"
    },
    "scattering": {
      "wavevector_q": 0.001,
      "_q_note": "Scattering wavevector magnitude: q = 4\u03c0 sin(\u03b8/2)/\u03bb",
      "q_unit": "\u00c5\u207b\u00b9",
      "typical_range": [
        0.001,
        0.1
      ]
    },
    "geometry": {
      "stator_rotor_gap": 2000000,
      "_gap_note": "Gap in Angstroms - critical for laminar flow analysis",
      "gap_unit": "\u00c5",
      "gap_in_microns": 200
    },
    "computational": {
      "num_threads": "auto",
      "auto_detect_cores": true,
      "max_threads_limit": 32,
      "_max_threads_note": "Large dataset optimization: aggressive threading for high-performance processing",
      "memory_limit_gb": 128,
      "_memory_limit_note": "Large dataset optimization: high memory allocation for efficient processing"
    }
  },
  "initial_parameters": {
    "_comment": "Starting values for 7-parameter laminar flow optimization [D0, alpha, D_offset, gamma_dot_t0, beta, gamma_dot_t_offset, phi0]",
    "values": [
      100.0,
      0.0,
      10.0,
      1.0,
      0.0,
      0.0,
      0.0
    ],
    "parameter_names": [
      "D0",
      "alpha",
      "D_offset",
      "gamma_dot_t0",
      "beta",
      "gamma_dot_t_offset",
      "phi0"
    ],
    "units": [
      "\u00c5\u00b2/s",
      "dimensionless",
      "\u00c5\u00b2/s",
      "s\u207b\u00b9",
      "dimensionless",
      "s\u207b\u00b9",
      "degrees"
    ],
    "physical_meaning": {
      "D0": "Reference diffusion coefficient",
      "alpha": "Power-law exponent for D(t) evolution",
      "D_offset": "Baseline diffusion coefficient",
      "gamma_dot_t0": "Reference shear rate",
      "beta": "Power-law exponent for shear rate evolution",
      "gamma_dot_t_offset": "Baseline shear rate",
      "phi0": "Angular offset between flow and scattering"
    },
    "active_parameters": [
      "D0",
      "alpha",
      "D_offset",
      "gamma_dot_t0",
      "beta",
      "gamma_dot_t_offset",
      "phi0"
    ],
    "parameter_units": {
      "D0": "\u00c5\u00b2/s",
      "alpha": "dimensionless",
      "D_offset": "\u00c5\u00b2/s",
      "gamma_dot_t0": "s\u207b\u00b9",
      "beta": "dimensionless",
      "gamma_dot_t_offset": "s\u207b\u00b9",
      "phi0": "degrees"
    }
  },
  "optimization_config": {
    "_comment": "Optimization configuration with enhanced angle filtering for large dataset laminar flow analysis",
    "angle_filtering": {
      "enabled": true,
      "_flow_note": "Angle filtering provides 3-5x speedup for complex 7-parameter fits - essential for large datasets",
      "target_ranges": [
        {
          "min_angle": -10.0,
          "max_angle": 10.0
        },
        {
          "min_angle": 80.0,
          "max_angle": 100.0
        },
        {
          "min_angle": 170.0,
          "max_angle": 190.0
        },
        {
          "min_angle": 260.0,
          "max_angle": 280.0
        }
      ],
      "fallback_to_all_angles": true,
      "_fallback_note": "Use all angles if no angles found in target ranges",
      "_performance_note": "Angle filtering provides 3-5x speedup for complex 7-parameter fits with large datasets"
    },
    "classical_optimization": {
      "methods": [
        "Nelder-Mead",
        "Gurobi"
      ],
      "_methods_note": "Classical methods: Nelder-Mead (always available), Gurobi (if licensed). Robust methods are in separate robust_optimization section.",
      "_usage_flags": {
        "--method classical": "Runs ONLY traditional classical methods: Nelder-Mead, Gurobi (if available)",
        "--method robust": "Runs ONLY robust methods: Robust-Wasserstein, Robust-Scenario, Robust-Ellipsoidal",
        "--method mcmc": "Runs Bayesian MCMC sampling for uncertainty quantification",
        "--method all": "Runs classical + robust + MCMC methods for comprehensive analysis"
      },
      "_gurobi_availability": "Gurobi quadratic programming solver provides an alternative to Nelder-Mead using quadratic approximation of the chi-squared objective function. Requires Gurobi license and installation (pip install gurobipy).",
      "method_options": {
        "Nelder-Mead": {
          "maxiter": 2500,
          "_maxiter_note": "Large dataset optimization: moderate reduction from default for 7-parameter complexity with statistical power",
          "xatol": 5e-06,
          "_xatol_note": "Large dataset optimization: relaxed parameter tolerance leveraging statistical robustness",
          "fatol": 5e-06,
          "_fatol_note": "Large dataset optimization: relaxed function tolerance for efficiency",
          "adaptive": true,
          "_adaptive_note": "Adaptive step sizes essential for efficient convergence with complex 7-parameter space"
        },
        "Gurobi": {
          "_comment": "ENHANCED: Now uses iterative Trust Region SQP instead of single-shot QP (fixes \u03c7\u00b2 convergence)",
          "_algorithm": "Iterative trust region SQP optimization with quadratic approximation and adaptive radius",
          "max_iterations": 400,
          "_max_iterations_note": "Large dataset optimization: moderate reduction leveraging statistical power for 7-parameter complexity",
          "tolerance": 5e-06,
          "_tolerance_note": "Large dataset optimization: relaxed convergence tolerance for efficiency",
          "output_flag": 0,
          "_output_flag_note": "Gurobi output verbosity (0=silent, 1=normal)",
          "method": 2,
          "_method_note": "Gurobi solution method (2=barrier method recommended for QP)",
          "time_limit": 300,
          "_time_limit_note": "Large dataset optimization: moderate time limit for complex 7-parameter optimization",
          "_trust_region_settings": {
            "initial_radius": 8.0,
            "_initial_radius_note": "Large dataset optimization: large radius for 7-parameter exploration",
            "max_radius": 80.0,
            "_max_radius_note": "Large dataset optimization: large max radius for efficiency",
            "eta1": 0.15,
            "eta2": 0.75,
            "gamma1": 0.6,
            "_gamma1_note": "Large dataset optimization: moderate shrinking factor for 7-parameter space",
            "gamma2": 3.0,
            "_gamma2_note": "Large dataset optimization: aggressive expansion for convergence",
            "max_trust_iterations": 200,
            "_note": "Large dataset optimization: moderate trust region parameters balancing performance and convergence for 7 parameters"
          },
          "_gurobi_flow_note": "Gurobi particularly effective for laminar flow with bounds constraints and large datasets",
          "_usage_note": "Gurobi uses quadratic approximation via finite differences. Best for smooth objective functions with bounds constraints.",
          "_advantages": "Handles bounds constraints naturally, can be faster for well-conditioned problems",
          "_disadvantages": "Requires license, uses quadratic approximation which may not capture all nonlinearity"
        }
      },
      "selection_strategy": "best_chi_squared",
      "_selection_strategy_note": "How to choose best result when multiple methods are used: best_chi_squared, consensus, first_success",
      "_optimization_note": "7-parameter laminar flow optimization with large datasets - complex but benefits from statistical power",
      "objective_function": {
        "type": "standard",
        "_type_note": "Objective function type: \"standard\" for min \u03c7\u00b2 or \"adaptive_target\" for min (\u03c7\u00b2 - \u03b1\u00b7DOF)\u00b2",
        "_type_options": {
          "standard": "Traditional chi-squared minimization (default)",
          "adaptive_target": "Adaptive target chi-squared to prevent overfitting"
        },
        "adaptive_target_alpha": 1.0,
        "_adaptive_target_alpha_note": "Target multiplier \u03b1 for adaptive chi-squared (recommended range: 0.8-1.2)",
        "_adaptive_target_description": "When type=\"adaptive_target\", minimizes (\u03c7\u00b2 - \u03b1\u00b7DOF)\u00b2 where DOF = N_data - N_params",
        "_adaptive_target_benefits": "Prevents overfitting by targeting statistically reasonable chi-squared values"
      }
    },
    "robust_optimization": {
      "_comment": "Robust optimization settings using CVXPY with optimized performance (CLARABEL/SCS solvers) for large datasets with laminar flow",
      "_usage_examples": [
        "python run_homodyne.py --method robust  # Run only robust methods",
        "python run_homodyne.py --method robust --laminar-flow  # Robust in laminar flow mode",
        "python run_homodyne.py --method classical  # Run all methods including robust",
        "python run_homodyne.py --method all  # Run classical (with robust) + MCMC"
      ],
      "_robust_flag_benefits": "Use --method robust for noise-resistant estimation without classical methods - valuable for large datasets with complex 7-parameter fits",
      "_performance_note": "v0.7.2+ optimizations: 100x-5000x speedup with caching, adaptive Jacobians, and streamlined solvers",
      "enabled": true,
      "uncertainty_model": "wasserstein",
      "_uncertainty_model_note": "Options: wasserstein, ellipsoidal, scenario",
      "uncertainty_radius": 0.05,
      "_uncertainty_radius_note": "Large dataset optimization: moderate increase for 7-parameter complexity while leveraging statistical power",
      "n_scenarios": 15,
      "_n_scenarios_note": "Large dataset optimization: moderate scenarios balancing robustness and efficiency for 7-parameter space",
      "regularization_alpha": 0.01,
      "_regularization_alpha_note": "Large dataset optimization: moderate regularization for 7-parameter stability",
      "regularization_beta": 0.001,
      "_regularization_beta_note": "Large dataset optimization: moderate L1 sparsity parameter for 7-parameter space",
      "jacobian_epsilon": 5e-06,
      "_jacobian_epsilon_note": "Large dataset optimization: relaxed finite difference step balancing accuracy and performance",
      "enable_caching": true,
      "_enable_caching_note": "Enable performance caching for repeated computations - critical gains for large datasets",
      "preferred_solver": "CLARABEL",
      "_preferred_solver_note": "Preferred CVXPY solver: CLARABEL, SCS, CVXOPT",
      "solver_settings": {
        "_comment": "Performance-optimized solver configuration for CVXPY-based robust optimization with large datasets and 7-parameter laminar flow",
        "_solver_hierarchy": "CLARABEL (default) -> SCS (fallback) -> CVXOPT (last resort)",
        "CLARABEL": {
          "_description": "Interior-point solver optimized for 7-parameter laminar flow with large datasets",
          "max_iter": 400,
          "_max_iter_note": "Large dataset optimization: moderate iterations balancing performance and convergence for 7 parameters",
          "tol_gap_abs": 5e-05,
          "tol_gap_rel": 5e-05,
          "tol_feas": 5e-05,
          "tol_infeas_abs": 5e-05,
          "tol_infeas_rel": 5e-05,
          "tol_ktratio": 0.0005,
          "equilibrate_enable": true,
          "equilibrate_max_iter": 25,
          "_equilibrate_max_iter_note": "Large dataset optimization: moderate equilibration for 7-parameter stability",
          "equilibrate_min_scaling": 1e-08,
          "equilibrate_max_scaling": 100000000.0,
          "direct_kkt_solver": true,
          "static_regularization_enable": true,
          "static_regularization_constant": 1e-07,
          "dynamic_regularization_enable": true,
          "iterative_refinement_enable": true,
          "_iterative_refinement_note": "Large dataset optimization: enabled for 7-parameter precision",
          "presolve_enable": true,
          "verbose": false
        },
        "SCS": {
          "_description": "Conic solver optimized for 7-parameter large dataset laminar flow problems",
          "max_iters": 8000,
          "_max_iters_note": "Large dataset optimization: high iterations for 7-parameter convergence",
          "eps": 5e-05,
          "alpha": 1.6,
          "rho_x": 5e-06,
          "scale": 5.0,
          "normalize": true,
          "adaptive_scale": true,
          "acceleration_lookback": 15,
          "_acceleration_lookback_note": "Large dataset optimization: extended lookback for 7-parameter stability",
          "acceleration_interval": 10,
          "_acceleration_interval_note": "Large dataset optimization: moderate acceleration updates",
          "time_limit_secs": 300,
          "_time_limit_secs_note": "Large dataset optimization: extended time for complex optimization",
          "verbose": false
        },
        "CVXOPT": {
          "_description": "Stable fallback solver for 7-parameter large dataset laminar flow problems",
          "maxiters": 200,
          "_maxiters_note": "Large dataset optimization: increased iterations for 7-parameter complexity",
          "abstol": 5e-05,
          "reltol": 5e-05,
          "feastol": 5e-05,
          "refinement": 3,
          "_refinement_note": "Large dataset optimization: increased refinement for 7-parameter precision",
          "verbose": false
        },
        "GUROBI": {
          "_description": "Commercial solver optimized for 7-parameter large dataset laminar flow optimization",
          "_availability": "Requires Gurobi license",
          "Method": 2,
          "_Method_note": "Barrier method with enhanced settings",
          "CrossOver": -1,
          "_CrossOver_note": "Auto-decide crossover for stability",
          "BarHomogeneous": 1,
          "_BarHomogeneous_note": "Homogeneous barrier for complex problems",
          "BarIterLimit": 800,
          "_BarIterLimit_note": "Large dataset optimization: high barrier iterations for 7-parameter convergence",
          "TimeLimit": 600,
          "_TimeLimit_note": "Large dataset optimization: extended timeout for 7-parameter complexity",
          "MIPGap": 0.005,
          "NumericFocus": 2,
          "_NumericFocus_note": "Enhanced numerical focus for 7-parameter stability",
          "OutputFlag": 0,
          "_OutputFlag_note": "Suppress solver output",
          "ScaleFlag": 3,
          "BarConvTol": 5e-06,
          "_BarConvTol_note": "Large dataset optimization: enhanced convergence tolerance",
          "FeasibilityTol": 5e-05,
          "_FeasibilityTol_note": "Large dataset optimization: relaxed feasibility tolerance for efficiency",
          "OptimalityTol": 5e-05,
          "_OptimalityTol_note": "Large dataset optimization: relaxed optimality tolerance for efficiency",
          "MarkowitzTol": 0.1,
          "PerturbValue": 0.0001,
          "Presolve": 2
        }
      },
      "method_options": {
        "wasserstein": {
          "uncertainty_radius": 0.05,
          "_uncertainty_radius_note": "Large dataset optimization: moderate radius for 7-parameter robustness",
          "regularization_alpha": 0.01,
          "_regularization_alpha_note": "Large dataset optimization: moderate regularization"
        },
        "scenario": {
          "n_scenarios": 15,
          "_n_scenarios_note": "Large dataset optimization: moderate scenarios for 7-parameter efficiency",
          "bootstrap_method": "residual"
        },
        "ellipsoidal": {
          "gamma": 0.12,
          "_gamma_note": "Large dataset optimization: moderate ellipsoidal parameter for 7-parameter robustness",
          "regularization_alpha": 0.01,
          "_regularization_alpha_note": "Large dataset optimization: moderate regularization"
        }
      },
      "objective_function": {
        "type": "standard",
        "_type_note": "Objective function type: \"standard\" for min \u03c7\u00b2 or \"adaptive_target\" for min (\u03c7\u00b2 - \u03b1\u00b7DOF)\u00b2",
        "_type_options": {
          "standard": "Traditional chi-squared minimization (default)",
          "adaptive_target": "Adaptive target chi-squared to prevent overfitting"
        },
        "adaptive_target_alpha": 1.0,
        "_adaptive_target_alpha_note": "Target multiplier \u03b1 for adaptive chi-squared (recommended range: 0.8-1.2)",
        "_adaptive_target_description": "When type=\"adaptive_target\", minimizes (\u03c7\u00b2 - \u03b1\u00b7DOF)\u00b2 where DOF = N_data - N_params",
        "_adaptive_target_benefits": "Prevents overfitting by targeting statistically reasonable chi-squared values in robust optimization"
      }
    },
    "mcmc_sampling": {
      "_comment": "Isolated MCMC Backend Architecture - Large Dataset Laminar Flow Mode (7 parameters: D0, alpha, D_offset, gamma_dot_t0, beta, gamma_dot_t_offset, phi0) - Efficient sampling with large dataset optimizations",
      "_backend_architecture": {
        "isolation": "Complete separation of PyMC CPU and NumPyro GPU implementations",
        "cpu_implementation": "homodyne.optimization.mcmc_cpu_backend.py",
        "gpu_implementation": "homodyne.optimization.mcmc_gpu_backend.py",
        "conflict_prevention": "Eliminates PyTensor/JAX namespace conflicts through isolated execution",
        "backend_selection": "HOMODYNE_GPU_INTENT environment variable or command-based selection",
        "complexity_note": "7-parameter flow model with large datasets benefits significantly from GPU acceleration and optimized sampling"
      },
      "enabled": true,
      "sampler": "NUTS",
      "draws": 3000,
      "_draws_note": "Large dataset optimization: moderate draws balancing efficiency and 7-parameter exploration with statistical power",
      "tune": 1000,
      "_tune_note": "Large dataset optimization: moderate tuning for 7-parameter space with large dataset initialization",
      "thin": 2,
      "_thin_note": "Large dataset optimization: moderate thinning for memory efficiency with complex 7-parameter dynamics",
      "chains": 4,
      "cores": 4,
      "target_accept": 0.75,
      "_target_accept_note": "Large dataset optimization: balanced acceptance rate for 7-parameter exploration with statistical robustness",
      "max_treedepth": 9,
      "_max_treedepth_note": "Large dataset optimization: moderate depth balancing 7-parameter exploration and efficiency",
      "return_inferencedata": true,
      "backend_specific": {
        "cpu_backend": {
          "_implementation": "homodyne.optimization.mcmc_cpu_backend.py",
          "_description": "Isolated PyMC implementation - optimized for 7-parameter flow model with large datasets",
          "_command": "homodyne --method mcmc (or HOMODYNE_GPU_INTENT=false)",
          "_isolation": "Pure PyMC environment, complete separation from NumPyro/JAX",
          "_performance_note": "CPU backend handles complex 7-parameter spaces efficiently with large datasets",
          "init_strategy": "adapt_diag",
          "compute_convergence_checks": true,
          "progressbar": true,
          "pytensor_config": "Automatically configured for CPU-only operation"
        },
        "gpu_backend": {
          "_implementation": "homodyne.optimization.mcmc_gpu_backend.py",
          "_description": "Isolated NumPyro/JAX implementation - GPU-accelerated 7-parameter sampling for large datasets",
          "_command": "homodyne-gpu --method mcmc (or HOMODYNE_GPU_INTENT=true)",
          "_platform_support": "Linux with CUDA preferred for optimal 7-parameter performance with large datasets",
          "_isolation": "Pure NumPyro/JAX environment, complete separation from PyMC/PyTensor",
          "_performance_note": "GPU acceleration provides significant speedup for complex 7-parameter flow models with large datasets",
          "init_strategy": "init_to_value",
          "chain_method": "vectorized",
          "progress_bar": true,
          "jit_compile": true,
          "device_memory_fraction": 0.9,
          "_device_memory_fraction_note": "Large dataset optimization: aggressive GPU memory usage for 7-parameter complexity",
          "jax_config": "Automatically optimized for complex 7-parameter sampling with large datasets"
        }
      },
      "performance_features": {
        "auto_tune_performance": true,
        "use_progressive_sampling": true,
        "use_intelligent_subsampling": true,
        "_use_intelligent_subsampling_note": "Large dataset optimization: enabled for memory management with 7-parameter complexity",
        "enable_jit_compilation": true,
        "memory_optimization": true
      }
    },
    "scaling_parameters": {
      "_comment": "Physical scaling for c2_fitted = c2_theory * contrast + offset",
      "fitted_range": {
        "min": 1.0,
        "max": 2.0
      },
      "theory_range": {
        "min": 0.0,
        "max": 1.0
      },
      "contrast": {
        "min": 0.0001,
        "_min_note": "Large dataset optimization: broader lower bound leveraging statistical power",
        "max": 0.5,
        "prior_mu": 0.05,
        "_prior_mu_note": "Large dataset optimization: adjusted for typical large dataset characteristics",
        "prior_sigma": 0.02,
        "_prior_sigma_note": "Large dataset optimization: tighter prior leveraging precision",
        "type": "TruncatedNormal"
      },
      "offset": {
        "min": 1.0,
        "_min_note": "Large dataset optimization: tighter bound for efficiency",
        "max": 1.5,
        "_max_note": "Large dataset optimization: tighter bound for efficiency",
        "prior_mu": 1.3,
        "_prior_mu_note": "Large dataset optimization: adjusted for typical characteristics",
        "prior_sigma": 0.02,
        "_prior_sigma_note": "Large dataset optimization: tight prior for efficiency",
        "type": "TruncatedNormal"
      }
    }
  },
  "parameter_space": {
    "_comment": "Parameter bounds for 7-parameter laminar flow optimization with large dataset considerations",
    "bounds": [
      {
        "name": "D0",
        "min": 1.0,
        "max": 1000000.0,
        "type": "TruncatedNormal",
        "prior_mu": 10000.0,
        "prior_sigma": 2000.0,
        "_prior_sigma_note": "Large dataset optimization: broader prior leveraging statistical power",
        "unit": "\u00c5\u00b2/s"
      },
      {
        "name": "alpha",
        "min": -2.0,
        "max": 2.0,
        "type": "Normal",
        "prior_mu": -1.5,
        "prior_sigma": 0.2,
        "_prior_sigma_note": "Large dataset optimization: broader prior leveraging convergence robustness",
        "unit": "dimensionless"
      },
      {
        "name": "D_offset",
        "min": -100,
        "max": 100,
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 15.0,
        "_prior_sigma_note": "Large dataset optimization: broader prior for parameter exploration",
        "unit": "\u00c5\u00b2/s"
      },
      {
        "name": "gamma_dot_t0",
        "min": 1e-06,
        "max": 1.0,
        "type": "TruncatedNormal",
        "prior_mu": 0.001,
        "prior_sigma": 0.01,
        "unit": "s\u207b\u00b9"
      },
      {
        "name": "beta",
        "min": -2.0,
        "max": 2.0,
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 0.2,
        "_prior_sigma_note": "Large dataset optimization: broader prior for parameter exploration",
        "unit": "dimensionless"
      },
      {
        "name": "gamma_dot_t_offset",
        "min": -0.01,
        "max": 0.01,
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 0.001,
        "unit": "s\u207b\u00b9"
      },
      {
        "name": "phi0",
        "min": -10.0,
        "max": 10.0,
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 5.0,
        "unit": "degrees"
      }
    ]
  },
  "analysis_settings": {
    "_comment": "Laminar flow mode configuration for large datasets",
    "static_mode": false,
    "_static_mode_note": "False for laminar flow analysis (all 7 parameters)",
    "static_submode": null,
    "_submode_note": "Not applicable for laminar flow mode",
    "model_description": {
      "laminar_flow": "g\u2082 = g\u2081_diff \u00d7 g\u2081_shear with sinc\u00b2 term for full flow dynamics - large dataset performance"
    }
  },
  "advanced_settings": {
    "_comment": "Advanced computational settings for laminar flow with large dataset enhancements",
    "data_loading": {
      "use_diagonal_correction": true,
      "vectorized_diagonal_fix": true
    },
    "chi_squared_calculation": {
      "method": "standard",
      "_scaling_note": "Scaling optimization always enabled for proper chi-squared",
      "minimum_sigma": 1e-08,
      "_minimum_sigma_note": "Large dataset optimization: relaxed precision for efficiency",
      "moving_window_size": 31,
      "moving_window_edge_method": "reflect",
      "fast_computation": true,
      "_fast_computation_note": "Large dataset optimization: enabled for high-speed calculations",
      "uncertainty_calculation": {
        "enable_uncertainty": true,
        "report_uncertainty": true,
        "minimum_angles_for_uncertainty": 2
      },
      "validity_check": {
        "check_positive_D0": true,
        "check_positive_gamma_dot_t0": true,
        "check_positive_time_dependent": true,
        "check_parameter_bounds": true
      },
      "_adaptive_targeting_note": "Adaptive chi-squared targeting is configured separately in optimization_config.classical_optimization.objective_function and optimization_config.robust_optimization.objective_function",
      "variance_method": "irls_mad_robust",
      "_variance_method_note": "Options: irls_mad_robust (default), irls_optimized (50x faster), mad_robust, mad_optimized (10x faster)",
      "irls_config": {
        "max_iterations": 15,
        "damping_factor": 0.8,
        "convergence_tolerance": 0.003,
        "initial_sigma_squared": 0.001,
        "_algorithm_note": "IRLS with MAD: \u03c3\u00b2\u1d62 = (1.4826 \u00d7 MAD)\u00b2, damping: \u03c3\u00b2 = \u03b1\u00b7\u03c3\u00b2_prev - Optimized for large datasets: window=31, iterations=15, damping=0.8",
        "optimized_config": {
          "use_vectorized_mad": true,
          "use_quickselect_median": true,
          "enable_jit_compilation": true,
          "parallel_window_processing": true
        }
      },
      "performance_optimization": {
        "_comment": "Performance optimization settings for chi-squared and IRLS calculations",
        "enabled": true,
        "variance_estimator": "irls_optimized",
        "_variance_estimator_note": "irls_optimized provides 50-100x speedup via JIT compilation and vectorization",
        "chi_calculator": "vectorized_jit",
        "_chi_calculator_note": "vectorized_jit provides 20-50x speedup with memory pooling",
        "median_algorithm": "quickselect",
        "_median_algorithm_note": "quickselect provides 5-10x speedup over numpy median for small arrays",
        "jit_compilation": {
          "enabled": true,
          "warmup_on_init": true,
          "parallel_processing": true,
          "fastmath": true,
          "cache_kernels": true
        },
        "memory_optimization": {
          "use_memory_pool": true,
          "pool_size_mb": 1024,
          "adaptive_caching": true,
          "cache_strategy": "lru",
          "max_cache_items": 300
        },
        "parallel_threads": {
          "enabled": true,
          "thread_count": "auto",
          "chunk_size": "adaptive",
          "backend": "threading"
        }
      }
    },
    "numerical_integration": {
      "method": "simpson",
      "relative_tolerance": 1e-06,
      "_relative_tolerance_note": "Large dataset optimization: balanced precision for efficiency",
      "absolute_tolerance": 1e-10,
      "_absolute_tolerance_note": "Large dataset optimization: balanced precision tolerances"
    },
    "optimization_controls": {
      "convergence_tolerance": 1e-06,
      "_convergence_tolerance_note": "Large dataset optimization: relaxed from 1e-8 for performance",
      "max_function_evaluations": 5000,
      "_max_function_evaluations_note": "Large dataset optimization: moderate limit balancing efficiency and 7-parameter convergence",
      "parameter_scaling": "auto",
      "finite_difference_step": 1e-06,
      "_finite_difference_step_note": "Large dataset optimization: relaxed precision for performance"
    }
  },
  "performance_settings": {
    "_comment": "Performance settings optimized for 7-parameter laminar flow with large datasets",
    "caching": {
      "enable_memory_cache": true,
      "enable_disk_cache": true,
      "cache_size_limit_mb": 5000,
      "_cache_size_limit_mb_note": "Large dataset optimization: large cache for 7-parameter flow computations",
      "auto_cleanup": true,
      "_auto_cleanup_note": "Large dataset optimization: enabled for memory management"
    },
    "parallel_processing": {
      "enable_multiprocessing": true,
      "chunk_size": "auto",
      "backend": "threading"
    },
    "memory_management": {
      "low_memory_mode": true,
      "_low_memory_mode_note": "Large dataset optimization: enabled for memory efficiency with 7-parameter complexity",
      "garbage_collection_frequency": 2,
      "_garbage_collection_frequency_note": "Large dataset optimization: moderate GC for 7-parameter balance",
      "memory_monitoring": true,
      "_memory_monitoring_note": "Large dataset optimization: critical for resource management"
    },
    "numba_optimization": {
      "enable_numba": true,
      "warmup_numba": true,
      "parallel_numba": true,
      "cache_numba": true,
      "stability_enhancements": {
        "enable_kernel_warmup": true,
        "warmup_iterations": 3,
        "_warmup_iterations_note": "Large dataset optimization: moderate warmup for 7-parameter computational kernels",
        "optimize_memory_layout": true,
        "enable_nogil": true,
        "environment_optimization": {
          "auto_configure": true,
          "max_threads": 16,
          "_max_threads_note": "Large dataset optimization: enhanced threading for 7-parameter efficiency",
          "gc_optimization": true
        }
      },
      "performance_monitoring": {
        "enable_profiling": false,
        "_enable_profiling_note": "Large dataset optimization: disabled for performance",
        "stable_benchmarking": false,
        "adaptive_benchmarking": false,
        "performance_baselines": false,
        "target_cv": 0.15,
        "_target_cv_note": "Large dataset optimization: moderate CV for 7-parameter balance",
        "memory_monitoring": true,
        "smart_caching": {
          "enabled": true,
          "max_items": 500,
          "_max_items_note": "Large dataset optimization: large cache for 7-parameter flow computations",
          "max_memory_mb": 2000.0,
          "_max_memory_mb_note": "Large dataset optimization: large cache for flow efficiency"
        }
      }
    },
    "noise_model": {
      "use_simple_forward_model": false,
      "_note": "Large dataset optimization: false uses full forward model for 7-parameter accuracy",
      "sigma_prior": 0.1,
      "_sigma_prior_note": "Large dataset optimization: moderate sigma prior balancing efficiency and accuracy"
    }
  },
  "validation_rules": {
    "_comment": "Enhanced validation rules for laminar flow analysis with large datasets",
    "data_quality": {
      "check_data_range": true,
      "correlation_minimum": 0.0,
      "correlation_maximum": 10.0,
      "check_nan_values": true,
      "nan_handling": "raise"
    },
    "parameter_validation": {
      "check_bounds": true,
      "physics_constraints": true,
      "correlation_checks": true
    },
    "fit_quality": {
      "_comment": "Enhanced quality thresholds for 7-parameter optimization leveraging large dataset statistical power",
      "overall_chi_squared": {
        "excellent_threshold": 10.0,
        "_excellent_threshold_note": "Large dataset optimization: relaxed threshold for 7-parameter complexity",
        "acceptable_threshold": 20.0,
        "_acceptable_threshold_note": "Large dataset optimization: higher threshold for complex 7-parameter fits",
        "warning_threshold": 40.0,
        "_warning_threshold_note": "Large dataset optimization: higher threshold allowing for complexity",
        "critical_threshold": 80.0,
        "_critical_threshold_note": "Large dataset optimization: higher critical threshold for 7-parameter tolerance"
      },
      "per_angle_chi_squared": {
        "excellent_threshold": 10.0,
        "acceptable_threshold": 20.0,
        "warning_threshold": 40.0,
        "outlier_threshold_multiplier": 3.0,
        "_outlier_threshold_multiplier_note": "Large dataset optimization: relaxed outlier detection for complex fits",
        "max_outlier_fraction": 0.3,
        "_max_outlier_fraction_note": "Large dataset optimization: higher outlier tolerance for 7-parameter complexity",
        "min_good_angles": 3,
        "_min_good_angles_note": "Large dataset optimization: moderate minimum for flow directionality"
      }
    },
    "mcmc_convergence": {
      "_comment": "Enhanced MCMC convergence criteria for 7-parameter case with large datasets",
      "rhat_thresholds": {
        "excellent_threshold": 1.02,
        "good_threshold": 1.08,
        "acceptable_threshold": 1.15,
        "critical_threshold": 1.25,
        "_note": "Large dataset optimization: relaxed R-hat thresholds leveraging statistical power for 7-parameter complexity"
      },
      "ess_thresholds": {
        "excellent_threshold": 300,
        "_excellent_threshold_note": "Large dataset optimization: moderate ESS for 7-parameter balance",
        "good_threshold": 150,
        "_good_threshold_note": "Large dataset optimization: moderate good threshold",
        "acceptable_threshold": 75,
        "_acceptable_threshold_note": "Large dataset optimization: moderate acceptable threshold",
        "minimum_threshold": 40,
        "_minimum_threshold_note": "Large dataset optimization: moderate minimum for efficiency"
      },
      "divergence_thresholds": {
        "max_divergences_fraction": 0.08,
        "_max_divergences_fraction_note": "Large dataset optimization: moderate tolerance balancing convergence and efficiency",
        "warning_divergences_fraction": 0.03,
        "_warning_divergences_fraction_note": "Large dataset optimization: moderate warning threshold"
      }
    },
    "frame_range": {
      "minimum_frames": 100000,
      "_minimum_frames_note": "Large dataset optimization: high minimum for true large dataset analysis",
      "maximum_frames": 50000000,
      "_maximum_frames_note": "Large dataset optimization: very large dataset upper limit (50M)",
      "check_continuity": true
    }
  },
  "workflow_integration": {
    "_comment": "Analysis workflow settings optimized for large datasets",
    "analysis_workflow": {
      "auto_generate_plots": true,
      "plot_integration_enabled": true,
      "plot_experimental_data_on_load": false,
      "cache_plot_data": true,
      "save_intermediate_plots": true,
      "_save_intermediate_plots_note": "Large dataset optimization: enabled for comprehensive 7-parameter flow analysis tracking"
    },
    "mcmc_integration": {
      "auto_save_traces": true,
      "trace_file_format": "netcdf",
      "include_warmup_in_traces": false,
      "_include_warmup_in_traces_note": "Large dataset optimization: exclude warmup for storage efficiency",
      "convergence_diagnostics_auto": true,
      "plot_mcmc_results": true
    },
    "data_management": {
      "experimental_data_cache": true,
      "theoretical_data_cache": true,
      "cache_directory": "./cache",
      "auto_cleanup_cache": false,
      "_auto_cleanup_cache_note": "Large dataset optimization: preserve cache for 7-parameter flow reproducibility",
      "cache_retention_days": 30,
      "_cache_retention_days_note": "Large dataset optimization: extended retention for complex flow analysis"
    },
    "error_handling": {
      "continue_on_plot_errors": true,
      "log_plot_errors": true,
      "fallback_plotting": true,
      "validate_plot_data": true
    }
  },
  "output_settings": {
    "_comment": "Output and reporting configuration optimized for large dataset analysis",
    "_output_structure": "homodyne_analysis_results.json (main summary) saved to output directory root. Method-specific results saved to individual directories: classical/[method_name]/ and robust/[method_name]/ containing analysis_results_[method_name].json, parameters.json, fitted_data.npz (consolidated: c2_experimental, c2_fitted, residuals, parameters, uncertainties, chi_squared, phi_angles, t1, t2), and c2_heatmaps_[method_name].png. Summary files: all_classical_methods_summary.json and all_robust_methods_summary.json. MCMC: results saved to mcmc/ subdirectory with same fitted_data.npz structure.",
    "results_directory": "./homodyne_results_large_dataset",
    "_results_directory_note": "Large dataset optimization: dedicated directory for large dataset results",
    "file_formats": {
      "results_format": "json",
      "save_intermediate": true,
      "_save_intermediate_note": "Large dataset optimization: enabled for comprehensive 7-parameter analysis tracking",
      "compression": true,
      "_compression_note": "Large dataset optimization: enabled for storage optimization",
      "precision": "float32",
      "_precision_note": "Large dataset optimization: memory-efficient precision"
    },
    "file_naming": {
      "timestamp_format": "%Y%m%d_%H%M%S",
      "include_config_name": true,
      "include_chi_squared": true
    },
    "reporting": {
      "generate_plots": true,
      "plot_formats": [
        "png"
      ],
      "_plot_formats_note": "Large dataset optimization: single format for efficiency",
      "detailed_summary": true,
      "_detailed_summary_note": "Large dataset optimization: enabled for comprehensive 7-parameter analysis documentation",
      "convergence_diagnostics": true
    },
    "plotting": {
      "_comment": "Plotting configuration for laminar flow mode with large dataset enhancements",
      "general": {
        "create_plots": true,
        "plot_format": "png",
        "dpi": 150,
        "_dpi_note": "Large dataset optimization: reduced DPI for storage efficiency",
        "figure_size": [
          12,
          8
        ],
        "_figsize_note": "Large dataset optimization: larger figures for complex 7-parameter results",
        "style": "publication",
        "save_plots": true,
        "show_plots": false
      },
      "c2_heatmaps": {
        "enabled": true,
        "_method_specific_note": "When multiple optimization methods are used (e.g., Nelder-Mead + Gurobi), separate heatmaps are generated for each method with method names in filenames",
        "layout": "single_row",
        "include_experimental": true,
        "include_theoretical": true,
        "include_residuals": true,
        "colormap": "viridis",
        "colorbar_position": "right",
        "title_prefix": "C2 Correlation Function (Large Dataset Laminar Flow)",
        "figsize": [
          18,
          6
        ],
        "_figsize_note": "Large dataset optimization: large figure for comprehensive flow visualization"
      },
      "mcmc_plots": {
        "enabled": true,
        "corner_plots": {
          "enabled": true,
          "show_titles": true,
          "quantiles": [
            0.16,
            0.5,
            0.84
          ],
          "show_truths": false,
          "use_arviz": true,
          "figsize": [
            15,
            15
          ],
          "_figsize_note": "Large dataset optimization: large corner plot for 7 parameters"
        },
        "trace_plots": {
          "enabled": true,
          "show_chains": true,
          "show_warmup": false,
          "_show_warmup_note": "Large dataset optimization: exclude warmup for storage efficiency",
          "compact_layout": false,
          "_compact_layout_note": "Large dataset optimization: full layout for 7-parameter analysis",
          "figsize": [
            12,
            14
          ],
          "_figsize_note": "Large dataset optimization: tall figure for 7 parameter traces"
        },
        "convergence_diagnostics": {
          "enabled": true,
          "show_rhat": true,
          "show_ess": true,
          "show_mcse": true,
          "_show_mcse_note": "Large dataset optimization: enabled for 7-parameter convergence assessment",
          "show_energy": true,
          "rhat_threshold": 1.15,
          "_rhat_threshold_note": "Large dataset optimization: moderate threshold for 7-parameter balance",
          "ess_threshold": 75,
          "_ess_threshold_note": "Large dataset optimization: moderate threshold for efficiency"
        }
      },
      "diagnostic_plots": {
        "enabled": true,
        "chi_squared_summary": true,
        "parameter_correlations": true,
        "residual_analysis": true,
        "convergence_history": true
      },
      "output": {
        "base_directory": "./plots",
        "subdirectories": {
          "c2_heatmaps": "c2_correlation",
          "parameter_plots": "parameters",
          "mcmc_plots": "mcmc_analysis",
          "diagnostics": "diagnostics"
        },
        "filename_template": "large_dataset_{analysis_type}_{start_frame}_{end_frame}_{method}_{timestamp}",
        "_filename_template_note": "Large dataset optimization: enhanced naming for identification and efficiency",
        "include_timestamp": true,
        "overwrite_existing": true,
        "_overwrite_existing_note": "Large dataset optimization: enabled for storage management"
      }
    },
    "logging": {
      "log_level": "INFO",
      "log_to_file": true,
      "log_to_console": true,
      "log_filename": "homodyne_large_dataset_laminar_flow.log",
      "_log_filename_note": "Large dataset optimization: mode-specific log file for analysis tracking",
      "rotation": {
        "max_bytes": 20971520,
        "_max_bytes_note": "Large dataset optimization: larger log files for comprehensive 7-parameter analysis",
        "backup_count": 3,
        "_backup_count_note": "Large dataset optimization: additional backups for complex analysis tracking"
      }
    }
  }
}