{
  "_template_info": {
    "_comment": "LARGE DATASET HOMODYNE CONFIGURATION TEMPLATE - Optimized for 1-20M data points (centered on 5M)",
    "_creation_date": "2025-09-04",
    "_based_on_analysis": "Default comprehensive template v0.7.2 optimized for large datasets with aggressive performance settings",
    "_usage": "Copy this template and customize the analysis_mode, initial_parameters, and experimental_data sections for your 1-20M data point experiment",
    "_config_modes": {
      "static_isotropic": "3-parameter optimization [D0, alpha, D_offset] - no angle filtering - optimized for large datasets",
      "static_anisotropic": "3-parameter optimization [D0, alpha, D_offset] - with angle filtering - performance focused",
      "laminar_flow": "7-parameter optimization [D0, alpha, D_offset, gamma_dot_t0, beta, gamma_dot_t_offset, phi0] - aggressive optimization"
    },
    "_large_dataset_optimizations": "Aggressive performance, relaxed tolerances (5e-6 to 1e-5), memory optimization, intelligent subsampling"
  },
  "metadata": {
    "_comment": "Template metadata - Customize description and analysis_mode for your large dataset experiment",
    "config_version": "0.7.2",
    "description": "LARGE DATASET TEMPLATE: High-performance homodyne scattering analysis for 1-20M data points",
    "based_on": "He et al. PNAS 2024 - Transport coefficient approach with large dataset optimizations",
    "analysis_mode": "CHANGE_ME: static_isotropic | static_anisotropic | laminar_flow",
    "dataset_size": "1-20M data points (centered on 5M) - high-performance configuration",
    "plotting_features": {
      "experimental_data_plotting": "Use --plot-experimental-data or 'hexp' shortcut for validation and comparison",
      "simulated_data_plotting": "Use --plot-simulated-data or 'hsim' shortcut with --contrast and --offset parameters",
      "phi_angles_override": "Command-line --phi-angles overrides config file settings",
      "multi_method_support": "Separate plots generated for each optimization method (Nelder-Mead, Gurobi, etc.)",
      "large_dataset_efficiency": "Memory-efficient plotting with intelligent sampling for large datasets"
    },
    "parameters_optimized": "DEPENDS_ON_MODE: [D0,alpha,D_offset] for static modes, [D0,alpha,D_offset,gamma_dot_t0,beta,gamma_dot_t_offset,phi0] for laminar_flow",
    "shell_completion": "Interactive mode removed - comprehensive shell aliases available: hm, hc, hr, ha (methods), hconfig, hexp, hsim (utilities), hc-iso, hc-aniso, hc-flow (config shortcuts), hgm, hga (GPU)",
    "script_compatibility": "homodyne v0.7.2 with fast shell completion and large dataset optimization"
  },
  "experimental_data": {
    "_comment": "CUSTOMIZE: Update paths and filenames for your large dataset experimental data",
    "data_folder_path": "./data/YOUR_LARGE_DATASET_SAMPLE/",
    "data_file_name": "your_large_dataset_experimental_data.hdf",
    "phi_angles_path": "./data/phi_angles/",
    "phi_angles_file": "phi_list.txt",
    "exchange_key": "exchange",
    "cache_file_path": "./data/YOUR_LARGE_DATASET_SAMPLE/",
    "cache_filename_template": "cached_c2_frames_{start_frame}_{end_frame}_large.npz",
    "cache_compression": true,
    "data_type": "float32",
    "_data_type_note": "Memory-efficient float32 for large datasets - minimal precision loss",
    "file_format": "NPZ",
    "preprocessing": {
      "apply_diagonal_correction": true,
      "vectorized_correction": true,
      "cache_processed_data": true,
      "normalize_data": true,
      "normalization_method": "baseline",
      "large_dataset_enhancements": {
        "memory_optimization": true,
        "chunk_processing": true,
        "efficient_storage": true,
        "intelligent_subsampling": true
      }
    }
  },
  "analyzer_parameters": {
    "_comment": "CUSTOMIZE: Core physics parameters for your large dataset experiment - performance optimized",
    "temporal": {
      "dt": 0.1,
      "_dt_note": "Time step between frames in seconds - CUSTOMIZE for your acquisition",
      "dt_unit": "seconds",
      "start_frame": 100,
      "_start_frame_note": "CUSTOMIZE: Standard start for large datasets - skip initial equilibration",
      "end_frame": 5000100,
      "_end_frame_note": "CUSTOMIZE: Typical ~5M frame analysis window for large datasets",
      "frame_description": "Large dataset analysis time window (1-20M frames, centered on 5M)"
    },
    "scattering": {
      "wavevector_q": 0.001,
      "_q_note": "CUSTOMIZE: Scattering wavevector q = 4π sin(θ/2)/λ",
      "q_unit": "Å⁻¹",
      "typical_range": [0.001, 0.1]
    },
    "geometry": {
      "stator_rotor_gap": 2000000,
      "_gap_note": "CUSTOMIZE: Gap in Angstroms - critical for laminar_flow, less important for static modes",
      "gap_unit": "Å",
      "gap_in_microns": 200
    },
    "computational": {
      "num_threads": "auto",
      "auto_detect_cores": true,
      "max_threads_limit": 32,
      "_max_threads_note": "Aggressive threading for large dataset performance",
      "memory_limit_gb": 128,
      "_large_dataset_note": "High memory allocation for efficient large dataset processing"
    }
  },
  "initial_parameters": {
    "_comment": "CUSTOMIZE: Starting values - Good initialization helps large dataset convergence efficiency",
    "_mode_dependent_note": "Parameter count depends on analysis_mode: 3 for static modes, 7 for laminar_flow",
    "values": "MODE_DEPENDENT: [100.0,0.0,10.0] for static, [100.0,0.0,10.0,1.0,0.0,0.0,0.0] for laminar_flow",
    "parameter_names": "MODE_DEPENDENT: See _parameter_definitions below",
    "_parameter_definitions": {
      "static_modes": ["D0", "alpha", "D_offset"],
      "laminar_flow": [
        "D0",
        "alpha",
        "D_offset",
        "gamma_dot_t0",
        "beta",
        "gamma_dot_t_offset",
        "phi0"
      ]
    },
    "units": "MODE_DEPENDENT: [Å²/s,dimensionless,Å²/s] for static, [Å²/s,dimensionless,Å²/s,s⁻¹,dimensionless,s⁻¹,degrees] for laminar_flow",
    "physical_meaning": {
      "_common_to_all_modes": {
        "D0": "Reference diffusion coefficient",
        "alpha": "Power-law exponent for D(t) evolution",
        "D_offset": "Baseline diffusion coefficient"
      },
      "_laminar_flow_additional": {
        "gamma_dot_t0": "Reference shear rate",
        "beta": "Power-law exponent for shear rate evolution",
        "gamma_dot_t_offset": "Baseline shear rate",
        "phi0": "Angular offset between flow and scattering"
      }
    },
    "active_parameters": "MODE_DEPENDENT: Matches parameter_names above",
    "parameter_units": "MODE_DEPENDENT: Matches units above in dict format"
  },
  "optimization_config": {
    "_comment": "Large dataset optimization settings with aggressive performance and relaxed tolerances",
    "angle_filtering": {
      "_mode_dependent": "disabled for static_isotropic, enabled for static_anisotropic and laminar_flow",
      "enabled": "MODE_DEPENDENT: false for static_isotropic, true for others",
      "target_ranges": [
        {
          "min_angle": -10.0,
          "max_angle": 10.0
        },
        {
          "min_angle": 80.0,
          "max_angle": 100.0,
          "_note": "static_anisotropic only"
        },
        {
          "min_angle": 170.0,
          "max_angle": 190.0
        },
        {
          "min_angle": 260.0,
          "max_angle": 280.0,
          "_note": "static_anisotropic only"
        }
      ],
      "fallback_to_all_angles": true,
      "_performance_note": "Optimized filtering provides 5-10x speedup for large datasets"
    },
    "classical_optimization": {
      "methods": ["Nelder-Mead", "Gurobi"],
      "_methods_note": "Classical methods with aggressive performance settings for large datasets",
      "_method_flags": {
        "--method classical": "Runs ONLY classical methods: Nelder-Mead, Gurobi (if licensed) with large dataset optimizations",
        "--method robust": "Runs ONLY robust methods: Robust-Wasserstein, Robust-Scenario, Robust-Ellipsoidal with performance focus",
        "--method mcmc": "Runs ONLY Bayesian MCMC sampling with efficient settings for large datasets",
        "--method all": "Runs classical + robust + MCMC for comprehensive large dataset analysis"
      },
      "_gurobi_availability": "Requires Gurobi license (pip install gurobipy). Enhanced Trust Region SQP with large dataset performance.",
      "method_options": {
        "Nelder-Mead": {
          "maxiter": "MODE_DEPENDENT: 1500 for static, 3000 for laminar_flow",
          "_maxiter_note": "Reduced iterations for large dataset efficiency - good statistics compensate",
          "_large_dataset_scaling": "Aggressive iteration reduction leveraging superior statistics from large datasets",
          "xatol": 5e-6,
          "_xatol_note": "Relaxed parameter tolerance leveraging large dataset statistical power",
          "_large_dataset_xatol": "Performance-optimized: 5e-6 for fast convergence with excellent statistics",
          "fatol": 5e-6,
          "_fatol_note": "Relaxed chi-squared tolerance for efficient large dataset fitting",
          "_large_dataset_fatol": "Performance-optimized: 5e-6 balancing speed with large dataset accuracy",
          "adaptive": true,
          "_adaptive_note": "Adaptive step sizes essential for efficient large dataset convergence",
          "initial_simplex": null,
          "_initial_simplex_note": "Auto-generated based on parameter bounds with performance optimization",
          "return_all": false,
          "_return_all_note": "Return only final result for memory efficiency"
        },
        "Gurobi": {
          "_comment": "ENHANCED: Trust Region SQP with large dataset performance optimizations",
          "_algorithm": "Iterative trust region SQP optimization with aggressive performance for large datasets",
          "max_iterations": "MODE_DEPENDENT: 200 for static, 500 for laminar_flow",
          "_max_iterations_note": "Reduced iterations leveraging large dataset statistical power",
          "tolerance": 5e-6,
          "_tolerance_note": "Relaxed convergence tolerance for large dataset efficiency",
          "output_flag": 0,
          "_output_flag_note": "Gurobi verbosity (0=silent, 1=verbose)",
          "method": 2,
          "_method_note": "Barrier method optimized for large dataset trust region subproblems",
          "time_limit": "MODE_DEPENDENT: 120s for static, 300s for laminar_flow",
          "_time_limit_note": "Aggressive time limits for high-throughput large dataset processing",
          "_trust_region_settings": {
            "initial_radius": 10.0,
            "max_radius": 100.0,
            "eta1": 0.15,
            "eta2": 0.75,
            "gamma1": 0.8,
            "gamma2": 4.0,
            "max_trust_iterations": 100,
            "_note": "Aggressive trust region parameters for large dataset performance",
            "_rationale": "Larger radius and aggressive expansion leveraging large dataset robustness"
          },
          "_advantages": "High-speed convergence for large datasets with statistical robustness",
          "_requirements": "Gurobi license required for high-performance large dataset optimization"
        }
      },
      "selection_strategy": "best_chi_squared",
      "_selection_strategy_note": "best_chi_squared, consensus, or first_success when multiple methods used"
    },
    "robust_optimization": {
      "_comment": "ENHANCED: Robust optimization with large dataset performance settings",
      "_performance_upgrades": "v0.7.2+ optimizations with large dataset performance enhancements for high-volume data",
      "_usage_examples": [
        "python run_homodyne.py --method robust  # Run only robust methods with large dataset performance",
        "python run_homodyne.py --method classical  # Include robust in classical analysis with efficiency",
        "python run_homodyne.py --method all  # Comprehensive: classical + robust + MCMC for large datasets"
      ],
      "enabled": true,
      "uncertainty_model": "wasserstein",
      "_uncertainty_model_note": "Options: wasserstein (recommended), ellipsoidal, scenario - optimized for large datasets",
      "uncertainty_radius": "MODE_DEPENDENT: 0.02 for static, 0.03 for laminar_flow",
      "_uncertainty_radius_note": "Reduced uncertainty radius leveraging large dataset statistical power",
      "n_scenarios": 10,
      "_n_scenarios_note": "Reduced bootstrap scenarios for large dataset efficiency - reduced from 15",
      "regularization_alpha": "MODE_DEPENDENT: 0.005 for static, 0.01 for laminar_flow",
      "_regularization_alpha_note": "Reduced L2 regularization leveraging large dataset robustness",
      "regularization_beta": 0.0005,
      "_regularization_beta_note": "Reduced L1 sparsity parameter for large dataset efficiency",
      "jacobian_epsilon": 1e-5,
      "_jacobian_epsilon_note": "Relaxed finite difference step for large dataset performance",
      "enable_caching": true,
      "_enable_caching_note": "Aggressive caching provides major performance gains for large datasets",
      "preferred_solver": "CLARABEL",
      "_preferred_solver_note": "Optimized CVXPY solver: CLARABEL > SCS > CVXOPT with large dataset performance",
      "solver_settings": {
        "_comment": "Performance-optimized solver configuration for large dataset robust optimization",
        "_solver_hierarchy": "CLARABEL (default) -> SCS (fallback) -> CVXOPT (last resort) - all with large dataset performance",
        "CLARABEL": {
          "_description": "Modern interior-point solver, performance-optimized for large dataset scientific data fitting",
          "max_iter": 300,
          "tol_gap_abs": 1e-4,
          "tol_gap_rel": 1e-4,
          "tol_feas": 1e-5,
          "tol_infeas_abs": 1e-4,
          "tol_infeas_rel": 1e-4,
          "tol_ktratio": 1e-3,
          "reduced_tol_gap_abs": 1e-2,
          "reduced_tol_gap_rel": 1e-2,
          "reduced_tol_feas": 1e-2,
          "reduced_tol_infeas_abs": 1e-2,
          "reduced_tol_infeas_rel": 1e-2,
          "reduced_tol_ktratio": 1e-1,
          "equilibrate_enable": true,
          "equilibrate_max_iter": 20,
          "equilibrate_min_scaling": 1e-6,
          "equilibrate_max_scaling": 1e6,
          "direct_kkt_solver": true,
          "direct_solve_method": "qdldl",
          "static_regularization_enable": true,
          "static_regularization_constant": 1e-6,
          "static_regularization_proportional": 1e-4,
          "dynamic_regularization_enable": true,
          "dynamic_regularization_eps": 1e-11,
          "dynamic_regularization_delta": 1e-5,
          "iterative_refinement_enable": false,
          "_refinement_note": "Disabled for large dataset performance",
          "presolve_enable": true,
          "verbose": false,
          "_large_dataset_note": "Aggressive performance settings for large dataset efficiency"
        },
        "SCS": {
          "_description": "Splitting conic solver, performance fallback for large dataset fitting",
          "max_iters": 5000,
          "eps": 1e-3,
          "alpha": 1.8,
          "rho_x": 1e-5,
          "scale": 10.0,
          "normalize": true,
          "adaptive_scale": true,
          "use_indirect": false,
          "acceleration_lookback": 10,
          "acceleration_interval": 5,
          "write_data_filename": null,
          "log_csv_filename": null,
          "time_limit_secs": 180,
          "verbose": false,
          "_large_dataset_note": "Performance-optimized settings for large dataset efficiency"
        },
        "CVXOPT": {
          "_description": "Python-based solver, fast fallback for large dataset problems",
          "maxiters": 100,
          "abstol": 1e-4,
          "reltol": 1e-3,
          "feastol": 1e-4,
          "refinement": 1,
          "show_progress": false,
          "verbose": false,
          "_large_dataset_note": "Aggressive settings for high-speed large dataset optimization"
        },
        "GUROBI": {
          "_description": "Commercial solver optimized for large dataset scientific optimization",
          "_availability": "Requires Gurobi license",
          "Method": 2,
          "CrossOver": -1,
          "BarHomogeneous": 1,
          "BarIterLimit": 500,
          "TimeLimit": "MODE_DEPENDENT: 180s for static, 360s for laminar_flow",
          "MIPGap": 1e-2,
          "NumericFocus": 1,
          "OutputFlag": 0,
          "ScaleFlag": 3,
          "BarConvTol": 1e-5,
          "FeasibilityTol": 1e-4,
          "OptimalityTol": 1e-4,
          "MarkowitzTol": 0.2,
          "PerturbValue": 0.0005,
          "Aggregate": 1,
          "Presolve": 2,
          "PreSparsify": 1,
          "_large_dataset_note": "Performance-optimized tolerances for large dataset optimization"
        }
      },
      "method_options": {
        "wasserstein": {
          "uncertainty_radius": "MODE_DEPENDENT: 0.02 for static, 0.03 for laminar_flow",
          "regularization_alpha": "MODE_DEPENDENT: 0.005 for static, 0.01 for laminar_flow"
        },
        "scenario": {
          "n_scenarios": 10,
          "bootstrap_method": "residual"
        },
        "ellipsoidal": {
          "gamma": "MODE_DEPENDENT: 0.05 for static, 0.08 for laminar_flow",
          "regularization_alpha": "MODE_DEPENDENT: 0.005 for static, 0.01 for laminar_flow"
        }
      }
    },
    "mcmc_sampling": {
      "_comment": "Isolated MCMC Backend Architecture - Large dataset optimizations with efficient sampling",
      "_backend_info": {
        "architecture": "Completely isolated backends prevent PyTensor/JAX namespace conflicts",
        "cpu_backend": "Pure PyMC implementation (homodyne/optimization/mcmc_cpu_backend.py)",
        "gpu_backend": "Pure NumPyro/JAX implementation (homodyne/optimization/mcmc_gpu_backend.py)",
        "backend_selection": "Environment variable HOMODYNE_GPU_INTENT or command-based selection",
        "compatibility": "Identical API and configuration, separate execution environments",
        "large_dataset_enhancements": "Efficient sampling and intelligent subsampling for high-volume data"
      },
      "enabled": true,
      "sampler": "NUTS",
      "draws": "MODE_DEPENDENT: 2000 for static, 3000 for laminar_flow",
      "_draws_note": "Reduced sample count for large dataset efficiency - reduced from 3000/4000",
      "_large_dataset_draws": "Efficient sampling leveraging superior statistics from large datasets",
      "tune": "MODE_DEPENDENT: 600 for static, 1000 for laminar_flow",
      "_tune_note": "Reduced tuning for large dataset efficiency - reduced from 800/1200",
      "_large_dataset_tune": "Efficient tuning sufficient with good large dataset initialization",
      "thin": "MODE_DEPENDENT: 2 for static, 3 for laminar_flow",
      "_thin_note": "Increased thinning for large dataset memory efficiency",
      "_large_dataset_thin": "Aggressive thinning to manage memory with large dataset volumes",
      "chains": 4,
      "cores": 4,
      "target_accept": "MODE_DEPENDENT: 0.80 for static, 0.75 for laminar_flow",
      "_target_accept_note": "Reduced acceptance rate for large dataset speed - reduced from 0.85/0.80",
      "_large_dataset_accept": "Performance-optimized acceptance rate for efficient large dataset sampling",
      "max_treedepth": "MODE_DEPENDENT: 6 for static, 8 for laminar_flow",
      "_max_treedepth_note": "Reduced exploration for large dataset efficiency - reduced from 8/10",
      "_large_dataset_treedepth": "Efficient exploration sufficient with large dataset statistical power",
      "return_inferencedata": true,
      "backend_specific": {
        "cpu_backend": {
          "_implementation": "homodyne.optimization.mcmc_cpu_backend.py",
          "_description": "Isolated PyMC implementation with complete PyTensor isolation and large dataset optimizations",
          "_command": "homodyne --method mcmc (or HOMODYNE_GPU_INTENT=false)",
          "_performance": "Cross-platform compatibility, reliable convergence, no JAX conflicts, large dataset efficiency",
          "_isolation": "Complete separation from JAX/NumPyro dependencies",
          "init_strategy": "adapt_diag",
          "compute_convergence_checks": true,
          "progressbar": true,
          "pytensor_config": "Automatically configured for CPU-only mode with large dataset performance"
        },
        "gpu_backend": {
          "_implementation": "homodyne.optimization.mcmc_gpu_backend.py",
          "_description": "Isolated NumPyro/JAX implementation with complete PyMC separation and large dataset optimizations",
          "_command": "homodyne-gpu --method mcmc (or HOMODYNE_GPU_INTENT=true)",
          "_performance": "GPU acceleration with intelligent CPU fallback, no PyTensor conflicts, large dataset efficiency",
          "_platform_support": "Linux with CUDA preferred, auto-fallback to CPU on other platforms",
          "_isolation": "Complete separation from PyMC/PyTensor dependencies",
          "init_strategy": "init_to_value",
          "num_warmup": "Uses 'tune' parameter value",
          "num_samples": "Uses 'draws' parameter value",
          "chain_method": "vectorized",
          "progress_bar": true,
          "jit_compile": true,
          "device_memory_fraction": 0.9,
          "_large_dataset_memory": "Aggressive GPU memory usage for large dataset processing",
          "jax_config": "Automatically configured for optimal GPU usage with large dataset performance"
        }
      },
      "performance_features": {
        "auto_tune_performance": true,
        "use_progressive_sampling": true,
        "use_intelligent_subsampling": true,
        "_subsampling_note": "Enabled for large dataset memory management and speed",
        "enable_jit_compilation": true,
        "memory_optimization": true,
        "large_dataset_enhancements": {
          "aggressive_subsampling": true,
          "memory_efficient_sampling": true,
          "fast_convergence_detection": true,
          "intelligent_thinning": true
        }
      }
    },
    "scaling_parameters": {
      "_comment": "Physical scaling: c2_fitted = c2_theory * contrast + offset - large dataset efficiency",
      "fitted_range": {
        "min": 1.0,
        "max": 2.0
      },
      "theory_range": {
        "min": 0.0,
        "max": 1.0
      },
      "contrast": {
        "min": "MODE_DEPENDENT: 1e-4 for static, 0.05 for laminar_flow",
        "max": 0.5,
        "prior_mu": "MODE_DEPENDENT: 0.05 for static, 0.3 for laminar_flow",
        "prior_sigma": "MODE_DEPENDENT: 0.02 for static, 0.15 for laminar_flow",
        "type": "TruncatedNormal",
        "_large_dataset_note": "Broader priors leveraging large dataset statistical power"
      },
      "offset": {
        "min": "MODE_DEPENDENT: 1.0 for static, 0.05 for laminar_flow",
        "max": "MODE_DEPENDENT: 1.5 for static, 1.95 for laminar_flow",
        "prior_mu": "MODE_DEPENDENT: 1.3 for static, 1.0 for laminar_flow",
        "prior_sigma": "MODE_DEPENDENT: 0.02 for static, 0.3 for laminar_flow",
        "type": "TruncatedNormal",
        "_large_dataset_note": "Flexible priors for large dataset efficiency"
      }
    }
  },
  "parameter_space": {
    "_comment": "CUSTOMIZE: Parameter bounds and priors for large datasets - performance-optimized settings",
    "_bounds_note": "Parameter bounds depend on analysis_mode - leveraging large dataset statistical power",
    "bounds": [
      {
        "_common_parameter_1": "D0",
        "name": "D0",
        "min": 1.0,
        "max": 1000000.0,
        "_customize_note": "Adjust D0 bounds based on your expected diffusion rates - leveraging large dataset robustness",
        "type": "TruncatedNormal",
        "prior_mu": 10000.0,
        "prior_sigma": 2000.0,
        "unit": "Å²/s",
        "_large_dataset_note": "Broader prior leveraging large dataset statistical power"
      },
      {
        "_common_parameter_2": "alpha",
        "name": "alpha",
        "min": -2.0,
        "max": 2.0,
        "_customize_note": "Power-law exponent - typically [-2, 2] range is sufficient",
        "type": "Normal",
        "prior_mu": -1.5,
        "prior_sigma": 0.2,
        "unit": "dimensionless",
        "_large_dataset_note": "Broader prior leveraging large dataset convergence robustness"
      },
      {
        "_common_parameter_3": "D_offset",
        "name": "D_offset",
        "min": -100,
        "max": 100,
        "_customize_note": "Baseline diffusion - adjust based on system",
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 15.0,
        "unit": "Å²/s",
        "_large_dataset_note": "Broader prior for large dataset parameter exploration"
      },
      {
        "_laminar_flow_parameter_4": "gamma_dot_t0 (laminar_flow mode only)",
        "name": "gamma_dot_t0",
        "min": 1e-6,
        "max": 1.0,
        "_customize_note": "Reference shear rate - adjust for your flow conditions",
        "type": "TruncatedNormal",
        "prior_mu": 0.001,
        "prior_sigma": 0.02,
        "unit": "s⁻¹",
        "_large_dataset_note": "Flexible prior for large dataset laminar flow analysis"
      },
      {
        "_laminar_flow_parameter_5": "beta (laminar_flow mode only)",
        "name": "beta",
        "min": -2.0,
        "max": 2.0,
        "_customize_note": "Shear rate power-law exponent",
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 0.2,
        "unit": "dimensionless",
        "_large_dataset_note": "Broader prior leveraging large dataset statistical power"
      },
      {
        "_laminar_flow_parameter_6": "gamma_dot_t_offset (laminar_flow mode only)",
        "name": "gamma_dot_t_offset",
        "min": -0.01,
        "max": 0.01,
        "_customize_note": "Baseline shear rate offset",
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 0.002,
        "unit": "s⁻¹",
        "_large_dataset_note": "Flexible prior for large dataset efficiency"
      },
      {
        "_laminar_flow_parameter_7": "phi0 (laminar_flow mode only)",
        "name": "phi0",
        "min": -10.0,
        "max": 10.0,
        "_customize_note": "Angular offset - adjust based on geometry",
        "type": "Normal",
        "prior_mu": 0.0,
        "prior_sigma": 7.5,
        "unit": "degrees",
        "_large_dataset_note": "Broader prior for efficient large dataset convergence"
      }
    ]
  },
  "analysis_settings": {
    "_comment": "CUSTOMIZE: Set analysis_mode and corresponding static_mode/static_submode for large datasets",
    "static_mode": "MODE_DEPENDENT: true for static_isotropic/static_anisotropic, false for laminar_flow",
    "_static_mode_note": "Controls whether to use static (3-param) or dynamic (7-param) model",
    "static_submode": "MODE_DEPENDENT: isotropic/anisotropic for static modes, null for laminar_flow",
    "_submode_note": "Isotropic disables angle filtering, anisotropic enables it",
    "model_description": {
      "static_isotropic": "g₂(t₁,t₂) ~ [exp(-q² ∫ D(t)dt)]² with isotropic symmetry - large dataset performance",
      "static_anisotropic": "g₂(t₁,t₂) ~ [exp(-q² ∫ D(t)dt)]² with angular filtering - optimized for large datasets",
      "laminar_flow": "g₂ = g₁_diff × g₁_shear with sinc² term for full flow dynamics - aggressive large dataset settings"
    }
  },
  "advanced_settings": {
    "_comment": "Advanced computational and numerical settings optimized for large datasets",
    "data_loading": {
      "use_diagonal_correction": true,
      "vectorized_diagonal_fix": true
    },
    "chi_squared_calculation": {
      "method": "standard",
      "_scaling_note": "Scaling optimization always enabled for proper chi-squared calculation",
      "uncertainty_estimation_factor": 0.05,
      "_large_dataset_factor": "Reduced from 0.1 leveraging large dataset statistical power",
      "minimum_sigma": 1e-8,
      "_large_dataset_sigma": "Relaxed precision for large dataset efficiency",
      "fast_computation": true,
      "_large_dataset_computation": "Enabled for high-speed large dataset calculations",
      "uncertainty_calculation": {
        "enable_uncertainty": true,
        "report_uncertainty": true,
        "minimum_angles_for_uncertainty": "MODE_DEPENDENT: 1 for static_isotropic, 2+ for others",
        "efficient_large_dataset_uncertainty": true
      },
      "validity_check": {
        "check_positive_D0": true,
        "check_positive_gamma_dot_t0": "MODE_DEPENDENT: false for static modes, true for laminar_flow",
        "check_positive_time_dependent": true,
        "check_parameter_bounds": true,
        "efficient_large_dataset_validation": true
      }
    },
    "numerical_integration": {
      "method": "simpson",
      "relative_tolerance": 1e-6,
      "absolute_tolerance": 1e-10,
      "_large_dataset_note": "Balanced precision tolerances for large dataset efficiency"
    },
    "optimization_controls": {
      "convergence_tolerance": 1e-6,
      "_large_dataset_tolerance": "Relaxed from 1e-8 for large dataset performance",
      "max_function_evaluations": "MODE_DEPENDENT: 3000 for static, 8000 for laminar_flow",
      "_max_function_evaluations_note": "Reduced limits leveraging large dataset convergence efficiency",
      "parameter_scaling": "auto",
      "finite_difference_step": 1e-6,
      "_large_dataset_step": "Relaxed precision for large dataset performance"
    }
  },
  "performance_settings": {
    "_comment": "Performance optimization settings aggressively tuned for large dataset analysis",
    "caching": {
      "enable_memory_cache": true,
      "enable_disk_cache": true,
      "cache_size_limit_mb": "MODE_DEPENDENT: 2000-3000 for static, 4000 for laminar_flow",
      "_large_dataset_cache": "Aggressive caching for large dataset performance optimization",
      "auto_cleanup": true,
      "_cleanup_note": "Enabled for large dataset memory management"
    },
    "parallel_processing": {
      "enable_multiprocessing": true,
      "chunk_size": "auto",
      "backend": "threading"
    },
    "memory_management": {
      "low_memory_mode": true,
      "_large_dataset_memory": "Enabled for large dataset memory efficiency",
      "garbage_collection_frequency": 1,
      "_large_dataset_gc": "Aggressive GC for large dataset memory management",
      "memory_monitoring": true,
      "_monitoring_note": "Critical for large dataset resource management"
    },
    "numba_optimization": {
      "enable_numba": true,
      "warmup_numba": true,
      "parallel_numba": true,
      "cache_numba": true,
      "stability_enhancements": {
        "enable_kernel_warmup": true,
        "warmup_iterations": "MODE_DEPENDENT: 2 for static, 3 for laminar_flow",
        "_large_dataset_warmup": "Minimal warmup for large dataset performance",
        "optimize_memory_layout": true,
        "enable_nogil": true,
        "environment_optimization": {
          "auto_configure": true,
          "max_threads": "MODE_DEPENDENT: 8-12 for static, 16 for laminar_flow",
          "_large_dataset_threads": "Aggressive threading for large dataset performance",
          "gc_optimization": true
        }
      },
      "performance_monitoring": {
        "enable_profiling": false,
        "_large_dataset_profiling": "Disabled for large dataset performance",
        "stable_benchmarking": false,
        "adaptive_benchmarking": false,
        "performance_baselines": false,
        "target_cv": 0.2,
        "_large_dataset_cv": "Relaxed CV for large dataset performance",
        "memory_monitoring": true,
        "smart_caching": {
          "enabled": true,
          "max_items": "MODE_DEPENDENT: 200-300 for static, 400 for laminar_flow",
          "_large_dataset_items": "Aggressive caching for large dataset performance",
          "max_memory_mb": "MODE_DEPENDENT: 1000-1500 for static, 2000 for laminar_flow"
        }
      }
    },
    "noise_model": {
      "use_simple_forward_model": true,
      "_note": "True uses simplified model for large dataset performance optimization",
      "sigma_prior": 0.2,
      "_large_dataset_sigma": "Broader sigma prior for large dataset efficiency"
    }
  },
  "validation_rules": {
    "_comment": "Quality control and validation thresholds optimized for large datasets",
    "data_quality": {
      "check_data_range": true,
      "correlation_minimum": 0.0,
      "correlation_maximum": 10.0,
      "check_nan_values": true,
      "nan_handling": "raise",
      "large_dataset_enhancements": {
        "efficient_validation": true,
        "sampling_based_checks": true,
        "memory_efficient_processing": true
      }
    },
    "parameter_validation": {
      "check_bounds": true,
      "physics_constraints": true,
      "correlation_checks": true,
      "large_dataset_validation": {
        "efficient_bounds_checking": true,
        "statistical_physics_enforcement": true,
        "sampling_based_correlation_analysis": true
      }
    },
    "fit_quality": {
      "_comment": "Chi-squared quality thresholds - leveraging large dataset statistical power",
      "overall_chi_squared": {
        "excellent_threshold": 8.0,
        "acceptable_threshold": 15.0,
        "warning_threshold": 30.0,
        "critical_threshold": 60.0,
        "_large_dataset_note": "Relaxed thresholds leveraging large dataset statistical robustness"
      },
      "per_angle_chi_squared": {
        "excellent_threshold": 8.0,
        "acceptable_threshold": 15.0,
        "warning_threshold": 30.0,
        "outlier_threshold_multiplier": 3.0,
        "_large_dataset_multiplier": "Relaxed outlier detection leveraging large dataset robustness",
        "max_outlier_fraction": 0.35,
        "_large_dataset_fraction": "Higher outlier tolerance for large dataset efficiency",
        "min_good_angles": "MODE_DEPENDENT: 1 for static_isotropic, 2 for others",
        "_large_dataset_angles": "Relaxed angle requirements leveraging large dataset statistical power"
      }
    },
    "mcmc_convergence": {
      "_comment": "MCMC convergence diagnostics - leveraging large dataset statistical power",
      "rhat_thresholds": {
        "excellent_threshold": 1.02,
        "good_threshold": 1.08,
        "acceptable_threshold": 1.15,
        "critical_threshold": 1.25,
        "_large_dataset_note": "Relaxed R-hat thresholds leveraging large dataset convergence robustness"
      },
      "ess_thresholds": {
        "excellent_threshold": 200,
        "good_threshold": 100,
        "acceptable_threshold": 50,
        "minimum_threshold": 25,
        "_large_dataset_note": "Reduced ESS requirements leveraging large dataset statistical power"
      },
      "divergence_thresholds": {
        "max_divergences_fraction": 0.10,
        "warning_divergences_fraction": 0.02,
        "_large_dataset_note": "Higher divergence tolerance for large dataset efficiency"
      }
    },
    "frame_range": {
      "minimum_frames": 100000,
      "_large_dataset_minimum": "High minimum for true large dataset analysis",
      "maximum_frames": 50000000,
      "_large_dataset_maximum": "Very large dataset upper limit (50M)",
      "check_continuity": true
    }
  },
  "workflow_integration": {
    "_comment": "Analysis workflow and integration settings optimized for large datasets",
    "analysis_workflow": {
      "auto_generate_plots": true,
      "plot_integration_enabled": true,
      "plot_experimental_data_on_load": false,
      "cache_plot_data": true,
      "save_intermediate_plots": false,
      "_large_dataset_plots": "Streamlined plotting for large dataset memory efficiency"
    },
    "mcmc_integration": {
      "auto_save_traces": true,
      "trace_file_format": "netcdf",
      "include_warmup_in_traces": false,
      "_large_dataset_warmup": "Exclude warmup for large dataset storage efficiency",
      "convergence_diagnostics_auto": true,
      "plot_mcmc_results": true,
      "efficient_large_dataset_diagnostics": true
    },
    "data_management": {
      "experimental_data_cache": true,
      "theoretical_data_cache": true,
      "cache_directory": "./cache",
      "auto_cleanup_cache": true,
      "_large_dataset_cleanup": "Enabled for large dataset storage management",
      "cache_retention_days": 14,
      "_large_dataset_retention": "Reduced retention for large dataset storage efficiency"
    },
    "error_handling": {
      "continue_on_plot_errors": true,
      "log_plot_errors": true,
      "fallback_plotting": true,
      "validate_plot_data": true,
      "efficient_large_dataset_error_handling": true
    }
  },
  "output_settings": {
    "_comment": "Output and reporting configuration optimized for large datasets",
    "_output_structure": "homodyne_analysis_results.json (main summary) saved to output directory root. Method-specific results in subdirectories: classical/[method_name]/ and robust/[method_name]/ containing analysis_results_[method_name].json, parameters.json, fitted_data.npz (c2_experimental, c2_fitted, residuals, parameters, uncertainties, chi_squared, phi_angles, t1, t2), and c2_heatmaps_[method_name].png. Summary files: all_classical_methods_summary.json, all_robust_methods_summary.json. MCMC results in mcmc/ subdirectory. Memory-efficient output for large datasets.",
    "results_directory": "./homodyne_results_large_dataset",
    "_large_dataset_directory": "Dedicated directory for large dataset results",
    "file_formats": {
      "results_format": "json",
      "save_intermediate": false,
      "_large_dataset_intermediate": "Disabled for large dataset storage efficiency",
      "compression": true,
      "_large_dataset_compression": "Enabled for large dataset storage optimization",
      "precision": "float32",
      "_large_dataset_precision": "Memory-efficient precision for large datasets"
    },
    "file_naming": {
      "timestamp_format": "%Y%m%d_%H%M%S",
      "include_config_name": true,
      "include_chi_squared": true,
      "large_dataset_identifier": true
    },
    "reporting": {
      "generate_plots": true,
      "plot_formats": ["png"],
      "_large_dataset_formats": "Single format for large dataset efficiency",
      "detailed_summary": false,
      "_large_dataset_summary": "Streamlined summary for large dataset performance",
      "convergence_diagnostics": true,
      "efficient_large_dataset_reporting": true
    },
    "plotting": {
      "_comment": "Streamlined plotting configuration optimized for large dataset analysis",
      "general": {
        "create_plots": true,
        "plot_format": "png",
        "dpi": 150,
        "_large_dataset_dpi": "Reduced DPI for large dataset storage efficiency",
        "figure_size": "MODE_DEPENDENT: [10,8] for static, [12,8] for laminar_flow",
        "_figsize_note": "Standard figures for large dataset memory efficiency",
        "style": "publication",
        "save_plots": true,
        "show_plots": false
      },
      "c2_heatmaps": {
        "enabled": true,
        "_method_specific_note": "Separate heatmaps generated for each optimization method with large dataset efficiency",
        "layout": "single_row",
        "include_experimental": true,
        "include_theoretical": true,
        "include_residuals": true,
        "colormap": "viridis",
        "colorbar_position": "right",
        "title_prefix": "MODE_DEPENDENT: Large Dataset C2 Correlation Function ([analysis_mode])",
        "figsize": "MODE_DEPENDENT: [12,4] for static_isotropic, [15,5] for static_anisotropic, [18,6] for laminar_flow",
        "_large_dataset_figsize": "Standard figure sizes for large dataset memory efficiency"
      },
      "mcmc_plots": {
        "enabled": true,
        "corner_plots": {
          "enabled": true,
          "show_titles": true,
          "quantiles": [0.16, 0.5, 0.84],
          "_large_dataset_quantiles": "Standard quantiles for large dataset efficiency",
          "show_truths": false,
          "use_arviz": true,
          "figsize": "MODE_DEPENDENT: [9,9] for static, [15,15] for laminar_flow"
        },
        "trace_plots": {
          "enabled": true,
          "show_chains": true,
          "show_warmup": false,
          "_large_dataset_warmup": "Exclude warmup for large dataset efficiency",
          "compact_layout": true,
          "_large_dataset_layout": "Compact layout for large dataset memory efficiency",
          "figsize": "MODE_DEPENDENT: [10,6] for static, [12,14] for laminar_flow"
        },
        "convergence_diagnostics": {
          "enabled": true,
          "show_rhat": true,
          "show_ess": true,
          "show_mcse": false,
          "_large_dataset_mcse": "Disabled for large dataset efficiency",
          "show_energy": true,
          "rhat_threshold": 1.15,
          "ess_threshold": 50,
          "_large_dataset_thresholds": "Relaxed thresholds for large dataset efficiency"
        }
      },
      "diagnostic_plots": {
        "enabled": false,
        "_large_dataset_diagnostics": "Disabled for large dataset performance",
        "chi_squared_summary": true,
        "parameter_correlations": false,
        "residual_analysis": false,
        "convergence_history": true
      },
      "output": {
        "base_directory": "./plots_large_dataset",
        "_large_dataset_directory": "Dedicated plotting directory for large datasets",
        "subdirectories": {
          "c2_heatmaps": "c2_correlation",
          "parameter_plots": "parameters",
          "mcmc_plots": "mcmc_analysis",
          "diagnostics": "diagnostics"
        },
        "filename_template": "large_dataset_{analysis_type}_{start_frame}_{end_frame}_{method}_{timestamp}",
        "_filename_template_note": "Enhanced naming for large dataset identification and efficiency",
        "include_timestamp": true,
        "overwrite_existing": true,
        "_large_dataset_overwrite": "Enabled for large dataset storage management"
      }
    },
    "logging": {
      "log_level": "INFO",
      "_large_dataset_log_level": "Standard logging for large dataset performance",
      "log_to_file": true,
      "log_to_console": true,
      "log_filename": "MODE_DEPENDENT: homodyne_large_dataset_[analysis_mode].log",
      "rotation": {
        "max_bytes": 10485760,
        "_large_dataset_size": "Standard log files for large dataset efficiency",
        "backup_count": 2,
        "_large_dataset_backups": "Minimal backup files for large dataset storage efficiency"
      }
    }
  },
  "_customization_guide": {
    "_step_1": "Set analysis_mode in metadata section to: static_isotropic, static_anisotropic, or laminar_flow",
    "_step_2": "Update experimental_data section with your large dataset file paths and sample name",
    "_step_3": "Customize analyzer_parameters: dt (time step), q (wavevector), frame range (1-20M), gap size",
    "_step_4": "Adjust initial_parameters values based on your expected parameter ranges for large datasets",
    "_step_5": "Modify parameter_space bounds to match your physical system constraints with performance-optimized large dataset settings",
    "_step_6": "Update analysis_settings: set static_mode and static_submode consistently with analysis_mode",
    "_step_7": "Adjust performance_settings based on your computational resources - aggressively optimized for large datasets",
    "_step_8": "Customize validation_rules thresholds based on large dataset statistical power - relaxed for efficiency",
    "_step_9": "Update output_settings paths and logging configuration with large dataset identifiers and efficiency settings",
    "_mode_dependent_values": "Search for 'MODE_DEPENDENT' throughout config to see values that need mode-specific customization",
    "_large_dataset_specific": "Look for '_large_dataset_note' annotations for large dataset optimization explanations"
  },
  "_large_dataset_enhancements": {
    "_performance_improvements": "Relaxed tolerances: 5e-6 to 1e-5 for convergence, 1e-3 to 1e-4 for solver settings",
    "_sampling_optimizations": "Reduced MCMC draws: 2000-3000 vs 3000-4000, tune: 600-1000 vs 800-1200, aggressive thinning",
    "_validation_relaxations": "Relaxed chi-squared thresholds, reduced R-hat requirements, efficient diagnostics",
    "_caching_strategy": "Aggressive caching for performance, enabled auto-cleanup, reduced retention",
    "_solver_optimizations": "Performance-optimized solver settings, reduced iterations, aggressive trust region settings",
    "_output_optimizations": "Streamlined output, reduced precision, compressed storage, minimal diagnostics"
  }
}